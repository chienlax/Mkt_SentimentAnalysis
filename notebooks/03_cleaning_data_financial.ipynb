{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d936df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import contractions\n",
    "from bs4 import BeautifulSoup\n",
    "import emoji # Even if less common, good to have\n",
    "\n",
    "# Initialize lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# --- Customize Stopwords for Finance ---\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# CRITICAL: Remove negations and potentially sentiment-bearing words\n",
    "words_to_keep = {\n",
    "    \"no\", \"not\", \"nor\", \"up\", \"down\", \"above\", \"below\", \"over\", \"under\",\n",
    "    \"more\", \"less\", \"increase\", \"decrease\", \"positive\", \"negative\", \"profit\", \"loss\",\n",
    "    \"gain\", \"fall\", \"rise\", \"against\", \"don't\", \"doesn't\", \"didn't\", \"shouldn't\",\n",
    "    \"couldn't\", \"won't\", \"wouldn't\", \"isn't\", \"aren't\", \"wasn't\", \"weren't\",\n",
    "    \"buy\", \"sell\", \"hold\"\n",
    "}\n",
    "stop_words = stop_words - words_to_keep\n",
    "\n",
    "# Add common financial filler words IF they prove uninformative in your specific task\n",
    "# (Do this based on analysis, not preemptively)\n",
    "# financial_fillers = {\"company\", \"market\", \"stock\", \"share\", \"quarter\", \"report\", \"million\", \"billion\"}\n",
    "# stop_words.update(financial_fillers)\n",
    "\n",
    "print(f\"Using {len(stop_words)} stop words.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836b6086",
   "metadata": {},
   "source": [
    "Removing stop words, stemming, and lemmatization simplifies the data but can sometimes remove important nuances, especially for sophisticated DL models. It's often best to start with minimal processing **(cleaning, lowercasing, tokenizing)** and add steps like stop word removal or lemmatization only if needed based on initial model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beeaa457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Standard Cleaning (reuse from previous example) ---\n",
    "def remove_html_tags(text):\n",
    "    if isinstance(text, str): return BeautifulSoup(text, \"html.parser\").get_text()\n",
    "    return text\n",
    "\n",
    "def remove_urls(text):\n",
    "    if isinstance(text, str): return re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "    return text\n",
    "\n",
    "def lowercase_text(text):\n",
    "    if isinstance(text, str): return text.lower()\n",
    "    return text\n",
    "\n",
    "def expand_contractions(text):\n",
    "    if isinstance(text, str): return contractions.fix(text)\n",
    "    return text\n",
    "\n",
    "def handle_emojis(text): # Keep this in case emojis appear\n",
    "    if isinstance(text, str): return emoji.demojize(text, delimiters=(\" _EMOJI_\", \"_ \"))\n",
    "    return text\n",
    "\n",
    "# --- Financial Jargon/Abbreviations (Requires Custom Dictionary) ---\n",
    "# You need to build this dictionary based on your specific data!\n",
    "financial_jargon_map = {\n",
    "    \"qoq\": \"quarter over quarter\",\n",
    "    \"yoy\": \"year over year\",\n",
    "    \"eps\": \"earnings per share\",\n",
    "    \"p/e\": \"price to earnings ratio\",\n",
    "    \"roi\": \"return on investment\",\n",
    "    \"ipo\": \"initial public offering\",\n",
    "    \"fed\": \"federal reserve\",\n",
    "    # Add more financial abbreviations/jargon specific to your data\n",
    "}\n",
    "def handle_financial_jargon(text, mapping_dict):\n",
    "    \"\"\"Replaces known financial jargon/abbreviations.\"\"\"\n",
    "    if isinstance(text, str):\n",
    "        # Use regex to handle variations (e.g., case-insensitivity, word boundaries)\n",
    "        for abbr, full_form in mapping_dict.items():\n",
    "             # Simple boundary match, case insensitive\n",
    "            pattern = r'\\b' + re.escape(abbr) + r'\\b'\n",
    "            text = re.sub(pattern, full_form, text, flags=re.IGNORECASE)\n",
    "        return text\n",
    "    return text\n",
    "\n",
    "# --- Normalization of Financial Terms (Requires Custom Rules/Dictionary) ---\n",
    "# Example: Standardize company names or metrics\n",
    "term_normalization_map = {\n",
    "    \"q1\": \"first quarter\",\n",
    "    \"q2\": \"second quarter\",\n",
    "    # ...\n",
    "    \"alphabet inc.\": \"google\", # Example\n",
    "    \"google parent\": \"google\"\n",
    "}\n",
    "def normalize_financial_terms(text, mapping_dict):\n",
    "    \"\"\"Standardizes specific financial terms.\"\"\"\n",
    "    # Similar implementation to handle_financial_jargon\n",
    "    if isinstance(text, str):\n",
    "        for term, normalized_term in mapping_dict.items():\n",
    "            pattern = r'\\b' + re.escape(term) + r'\\b'\n",
    "            text = re.sub(pattern, normalized_term, text, flags=re.IGNORECASE)\n",
    "        return text\n",
    "    return text\n",
    "\n",
    "\n",
    "# --- Handling Financial Indicators & Punctuation ---\n",
    "def clean_financial_punctuation_and_symbols(text, keep_numbers=True):\n",
    "    \"\"\"Removes punctuation but keeps essential financial symbols and optionally numbers.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "\n",
    "    # Define characters to KEEP\n",
    "    financial_chars_to_keep = \".$%-\" # Keep period (decimals), dollar, percent, hyphen\n",
    "    allowed_chars = string.ascii_letters + string.digits + string.whitespace + financial_chars_to_keep\n",
    "\n",
    "    # Remove characters NOT in the allowed set\n",
    "    cleaned_text = ''.join(filter(lambda x: x in allowed_chars, text))\n",
    "\n",
    "    # Optional: Replace specific symbols with tokens if preferred over keeping them directly\n",
    "    # cleaned_text = cleaned_text.replace('$', ' _DOLLAR_ ')\n",
    "    # cleaned_text = cleaned_text.replace('%', ' _PERCENT_ ')\n",
    "\n",
    "    # Handle numbers (keep by default, or replace/remove)\n",
    "    if not keep_numbers:\n",
    "        cleaned_text = re.sub(r'\\d+(\\.\\d+)?', '', cleaned_text) # Remove integers and decimals\n",
    "    # else: # Optional: replace numbers with a token\n",
    "        # cleaned_text = re.sub(r'\\d+(\\.\\d+)?', '_NUMBER_', cleaned_text)\n",
    "\n",
    "    # Handle stock tickers (example: $AAPL, $TSLA). Replace with a token or remove.\n",
    "    # Option 1: Replace with generic token\n",
    "    cleaned_text = re.sub(r'\\$[A-Z]{1,5}\\b', '_TICKER_', cleaned_text)\n",
    "    # Option 2: Remove tickers (if replacing, do it before removing '$')\n",
    "    # cleaned_text = re.sub(r'\\$[A-Z]{1,5}\\b', '', cleaned_text)\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "\n",
    "# --- Tokenization (NLTK) ---\n",
    "def tokenize_text_nltk(text):\n",
    "    if isinstance(text, str): return word_tokenize(text)\n",
    "    return []\n",
    "\n",
    "# --- Removing Stop Words (Using customized list) ---\n",
    "def remove_stopwords(tokens):\n",
    "    \"\"\"Removes stop words using the finance-customized list.\"\"\"\n",
    "    return [word for word in tokens if word not in stop_words and len(word) > 1]\n",
    "\n",
    "# --- Lemmatization (NLTK) ---\n",
    "def lemmatize_tokens(tokens):\n",
    "    \"\"\"Applies WordNet lemmatization.\"\"\"\n",
    "    return [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "# --- Negation Handling (Basic - covered by keeping 'not' etc. in stop words) ---\n",
    "# Advanced negation handling (e.g., marking scope) often requires dedicated libraries\n",
    "# like NegEx or relies on contextual models (Transformers) to understand implicitly.\n",
    "# For ML/basic DL, ensuring negations AREN'T removed by stop words is the first step.\n",
    "\n",
    "# --- Domain Adaptation ---\n",
    "# This is a MODELING technique, not a text preprocessing step.\n",
    "# It involves using a model pre-trained on general data and fine-tuning it\n",
    "# on your specific (potentially smaller) financial dataset.\n",
    "# Example concept: Fine-tune a general BERT model on financial news."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84633948",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_financial_text_pipeline(text,\n",
    "                                       remove_html=True,\n",
    "                                       remove_url=True,\n",
    "                                       handle_emoji=False, # Less likely needed\n",
    "                                       expand_contract=True,\n",
    "                                       do_lowercase=True,\n",
    "                                       handle_jargon=True, # Enable if you build the map\n",
    "                                       jargon_map=financial_jargon_map,\n",
    "                                       normalize_terms=False, # Enable if you build the map\n",
    "                                       norm_map=term_normalization_map,\n",
    "                                       clean_punct_symbols=True,\n",
    "                                       keep_numbers=True, # Keep numbers by default for finance\n",
    "                                       do_tokenize=True,\n",
    "                                       remove_stop=True,\n",
    "                                       do_lemmatize=True):\n",
    "    \"\"\"Applies a sequence of preprocessing steps tailored for financial text.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\" if not do_tokenize else []\n",
    "\n",
    "    # 1. Basic Cleaning\n",
    "    if remove_html: text = remove_html_tags(text)\n",
    "    if remove_url: text = remove_urls(text)\n",
    "    if handle_emoji: text = handle_emojis(text) # Optional\n",
    "\n",
    "    # 2. Normalization\n",
    "    if expand_contract: text = expand_contractions(text)\n",
    "    if do_lowercase: text = lowercase_text(text)\n",
    "\n",
    "    # 3. Domain Specific Handling (BEFORE punctuation/number removal if they affect patterns)\n",
    "    if handle_jargon: text = handle_financial_jargon(text, jargon_map)\n",
    "    if normalize_terms: text = normalize_financial_terms(text, norm_map)\n",
    "\n",
    "    # 4. Handle Punctuation, Symbols, Numbers\n",
    "    if clean_punct_symbols: text = clean_financial_punctuation_and_symbols(text, keep_numbers=keep_numbers)\n",
    "\n",
    "    # --- Tokenization ---\n",
    "    if not do_tokenize:\n",
    "        return ' '.join(text.split()) # Clean whitespace\n",
    "    else:\n",
    "        tokens = tokenize_text_nltk(text)\n",
    "\n",
    "        # 5. Remove Stopwords (custom list)\n",
    "        if remove_stop:\n",
    "            tokens = remove_stopwords(tokens)\n",
    "\n",
    "        # 6. Lemmatize (preferred over stemming)\n",
    "        if do_lemmatize:\n",
    "            tokens = lemmatize_tokens(tokens)\n",
    "\n",
    "        # Remove any empty tokens that might result from cleaning\n",
    "        tokens = [token for token in tokens if token]\n",
    "\n",
    "        return tokens # Or ' '.join(tokens) for string output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888d88ea",
   "metadata": {},
   "source": [
    "### For financial text:\n",
    "- Handling Financial Jargon and Abbreviations: Financial texts contain specific terminology and abbreviations that might need to be handled appropriately, possibly through expansion or standardization.   \n",
    "- Normalization of Financial Terms: Ensuring consistent representation of financial entities and concepts.\n",
    "- Removal of Financial Indicators: Depending on the task, symbols like '$', '€', or stock tickers might be removed or treated specially.\n",
    "- Domain-Specific Stop Word Lists: Using stop word lists tailored to the financial domain, as some common words might carry sentiment in a financial context.   \n",
    "- Handling Numerical Data: Deciding how to treat numerical values, which can be significant in financial texts.\n",
    "- Negation Handling: Crucial in finance as negations can significantly alter the sentiment (e.g., \"not profitable\"). Specific negation handling algorithms might be employed.   \n",
    "- Domain Adaptation: When labeled financial data is scarce, techniques like domain adaptation might be used to leverage sentiment knowledge from other domains.  \n",
    "\n",
    "These shit will be handle later, now I have to build a simple pre-processing pipeline to run and test the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ac4264",
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_news = pd.read_csv('../data/processed/financial_news/financial_news_train.csv', encoding='latin-1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
