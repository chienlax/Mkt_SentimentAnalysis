{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aff2def3",
   "metadata": {},
   "source": [
    "# 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b155b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoModel, # For feature extraction\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "from peft import get_peft_model, LoraConfig, TaskType # For LoRA\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    classification_report,\n",
    "    confusion_matrix\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import evaluate \n",
    "import time\n",
    "import os\n",
    "import joblib \n",
    "import logging\n",
    "import warnings\n",
    "import gc\n",
    "import psutil\n",
    "\n",
    "# --- Basic Configuration ---\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "# --- Limit CPU Usage ---\n",
    "p = psutil.Process()\n",
    "p.cpu_affinity([1, 2, 3, 4, 5, 6, 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78372810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Project Directory Structure ---\n",
    "BASE_DIR = \"..\" # Assuming the notebook is in a 'notebooks' or similar folder\n",
    "DATA_DIR = os.path.join(BASE_DIR, \"data\", \"processed\")\n",
    "# Models and results saved within dataset-specific folders\n",
    "MODEL_OUTPUT_BASE_DIR = os.path.join(BASE_DIR, \"models\", \"llm\")\n",
    "RESULT_DIR = os.path.join(BASE_DIR, \"result\")\n",
    "\n",
    "# --- Specific Dataset Paths ---\n",
    "BOOK_REVIEW_DATA_DIR = os.path.join(DATA_DIR, \"book_reviews\")\n",
    "FINANCIAL_NEWS_DATA_DIR = os.path.join(DATA_DIR, \"financial_news\")\n",
    "\n",
    "# --- Model/Result Output Dirs (Ensure they exist) ---\n",
    "BOOK_REVIEW_MODEL_DIR = os.path.join(MODEL_OUTPUT_BASE_DIR, \"book_reviews\")\n",
    "FINANCIAL_NEWS_MODEL_DIR = os.path.join(MODEL_OUTPUT_BASE_DIR, \"financial_news\")\n",
    "BOOK_REVIEW_RESULT_DIR = os.path.join(RESULT_DIR, \"book_reviews\")\n",
    "FINANCIAL_NEWS_RESULT_DIR = os.path.join(RESULT_DIR, \"financial_news\")\n",
    "\n",
    "os.makedirs(BOOK_REVIEW_MODEL_DIR, exist_ok=True)\n",
    "os.makedirs(FINANCIAL_NEWS_MODEL_DIR, exist_ok=True)\n",
    "os.makedirs(BOOK_REVIEW_RESULT_DIR, exist_ok=True)\n",
    "os.makedirs(FINANCIAL_NEWS_RESULT_DIR, exist_ok=True)\n",
    "\n",
    "# --- File Names ---\n",
    "TRAIN_FN = \"train.csv\"\n",
    "VAL_FN = \"val.csv\"\n",
    "TEST_FN = \"test.csv\"\n",
    "\n",
    "# --- Column Names ---\n",
    "TEXT_COLUMN = \"text\"\n",
    "TARGET_COLUMN = \"score\" # Assumes string labels like 'positive', 'negative', 'neutral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7398b37d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-01 22:48:08,826 - INFO - Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# --- Model & Training Hyperparameters ---\n",
    "RANDOM_STATE = 42\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logging.info(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# Tokenizer params\n",
    "MAX_LENGTH = 256 # Max sequence length for transformers\n",
    "\n",
    "# Feature Extractor Params\n",
    "FEATURE_EXTRACTOR_BATCH_SIZE = 16 # Batch size for extracting features\n",
    "LOGREG_MAX_ITER = 1000 # Max iterations for Logistic Regression on features\n",
    "\n",
    "# Fine-tuning params (adjust based on resources and dataset size)\n",
    "LEARNING_RATE = 2e-5 # Common starting point for transformers\n",
    "WEIGHT_DECAY = 0.01\n",
    "TRAIN_BATCH_SIZE = 16 # Adjust based on GPU memory\n",
    "EVAL_BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 3 # Usually fewer epochs needed for fine-tuning\n",
    "FP16 = torch.cuda.is_available() # Enable mixed precision if GPU available\n",
    "\n",
    "# PEFT (LoRA) params\n",
    "USE_LORA = True # Flag to control if LoRA runs are included\n",
    "LORA_R = 8 # LoRA rank (dimension)\n",
    "LORA_ALPHA = 16 # LoRA alpha scaling\n",
    "LORA_DROPOUT = 0.1\n",
    "# Target modules vary by model, common ones for BERT/RoBERTa:\n",
    "LORA_TARGET_MODULES = [\"query\", \"value\"] # Common target layers for attention\n",
    "\n",
    "# --- Label Mapping (Essential for Transformers) ---\n",
    "LABEL_LIST = ['negative', 'neutral', 'positive'] # Define explicit order\n",
    "LABEL2ID = {label: i for i, label in enumerate(LABEL_LIST)}\n",
    "ID2LABEL = {i: label for i, label in enumerate(LABEL_LIST)}\n",
    "NUM_CLASSES = len(LABEL_LIST)\n",
    "\n",
    "# --- Evaluation Metrics ---\n",
    "METRICS_TO_CALCULATE = [\n",
    "    \"Accuracy\",\n",
    "    \"F1 (Macro)\", \"Precision (Macro)\", \"Recall (Macro)\",\n",
    "    \"F1 (Weighted)\", \"Precision (Weighted)\", \"Recall (Weighted)\",\n",
    "    \"Train Time (s)\", \"Eval Time (s)\"\n",
    "]\n",
    "METRIC_FOR_BEST_MODEL = \"f1_macro\" # Metric to monitor for early stopping/best model saving\n",
    "\n",
    "# --- Datasets Configuration ---\n",
    "DATASETS_TO_PROCESS = {\n",
    "    \"Book Review\": {\n",
    "        \"train_path\": os.path.join(BOOK_REVIEW_DATA_DIR, f'book_reviews_{TRAIN_FN}'),\n",
    "        \"val_path\": os.path.join(BOOK_REVIEW_DATA_DIR, f'book_reviews_{VAL_FN}'),\n",
    "        \"test_path\": os.path.join(BOOK_REVIEW_DATA_DIR, f'book_reviews_{TEST_FN}'),\n",
    "        \"model_dir\": BOOK_REVIEW_MODEL_DIR,\n",
    "        \"result_dir\": BOOK_REVIEW_RESULT_DIR,\n",
    "    },\n",
    "    \"Financial News\": {\n",
    "        \"train_path\": os.path.join(FINANCIAL_NEWS_DATA_DIR, f'financial_news_{TRAIN_FN}'),\n",
    "        \"val_path\": os.path.join(FINANCIAL_NEWS_DATA_DIR, f'financial_news_{VAL_FN}'),\n",
    "        \"test_path\": os.path.join(FINANCIAL_NEWS_DATA_DIR, f'financial_news_{TEST_FN}'),\n",
    "        \"model_dir\": FINANCIAL_NEWS_MODEL_DIR,\n",
    "        \"result_dir\": FINANCIAL_NEWS_RESULT_DIR,\n",
    "    }\n",
    "}\n",
    "\n",
    "# --- Model Configurations to Run ---\n",
    "# Define the models and settings for the experiment loop\n",
    "# Format: ('Experiment Name', 'HuggingFace Model ID', use_lora_flag, is_feature_extractor_run)\n",
    "MODEL_CONFIGURATIONS = [\n",
    "    # Feature Extractors\n",
    "    ('DistilBERT Feature Extractor + LR', 'distilbert-base-uncased', False, True),\n",
    "    ('BERT Feature Extractor + LR',       'bert-base-uncased',       False, True),\n",
    "\n",
    "    # Full Fine-tuning\n",
    "    ('DistilBERT Full FT', 'distilbert-base-uncased', False, False),\n",
    "    ('BERT Full FT',       'bert-base-uncased',       False, False),\n",
    "    ('RoBERTa Full FT',    'roberta-base',            False, False),\n",
    "    ('FinBERT Full FT',    'ProsusAI/finbert',        False, False), # Domain-specific\n",
    "\n",
    "    # LoRA Fine-tuning (only run if USE_LORA is True)\n",
    "    ('BERT LoRA FT',       'bert-base-uncased',       True, False),\n",
    "    ('RoBERTa LoRA FT',    'roberta-base',            True, False),\n",
    "    # ('FinBERT LoRA FT',    'ProsusAI/finbert',        True, False), # Can also apply LoRA to FinBERT\n",
    "] if USE_LORA else [ # Exclude LoRA runs if USE_LORA is False\n",
    "    ('DistilBERT Feature Extractor + LR', 'distilbert-base-uncased', False, True),\n",
    "    ('BERT Feature Extractor + LR',       'bert-base-uncased',       False, True),\n",
    "    ('DistilBERT Full FT', 'distilbert-base-uncased', False, False),\n",
    "    ('BERT Full FT',       'bert-base-uncased',       False, False),\n",
    "    ('RoBERTa Full FT',    'roberta-base',            False, False),\n",
    "    ('FinBERT Full FT',    'ProsusAI/finbert',        False, False),\n",
    "]\n",
    "\n",
    "# Check if FinBERT model ID needs adjustment (sometimes name changes)\n",
    "# Example alternative: 'yiyanghkust/finbert-tone'\n",
    "FINBERT_MODEL_ID = 'ProsusAI/finbert'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e209c0",
   "metadata": {},
   "source": [
    "# 2. Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28006188",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_hf(path):\n",
    "    \"\"\"Loads a single CSV into a Hugging Face Dataset.\"\"\"\n",
    "    try:\n",
    "        # Load directly using datasets library\n",
    "        dataset = load_dataset('csv', data_files=path, split='train')\n",
    "        # Rename target column to 'label' (expected by Trainer) and map string labels to integers\n",
    "        if TARGET_COLUMN != 'label':\n",
    "            dataset = dataset.rename_column(TARGET_COLUMN, 'label')\n",
    "        dataset = dataset.map(lambda examples: {'label': LABEL2ID.get(str(examples['label']), -1)}, # Handle potential non-string labels robustly\n",
    "                              desc=\"Mapping labels to IDs\")\n",
    "        # Filter out examples where label mapping failed (label == -1)\n",
    "        original_size = len(dataset)\n",
    "        dataset = dataset.filter(lambda example: example['label'] != -1, desc=\"Filtering invalid labels\")\n",
    "        if len(dataset) < original_size:\n",
    "            logging.warning(f\"Filtered out {original_size - len(dataset)} examples with invalid labels from {path}.\")\n",
    "        return dataset\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error loading dataset from {path}: {e}\", exc_info=True)\n",
    "        return None\n",
    "\n",
    "def create_dataset_dict(train_path, val_path, test_path):\n",
    "    \"\"\"Loads train, validation, and test CSVs into a DatasetDict.\"\"\"\n",
    "    train_ds = load_data_hf(train_path)\n",
    "    val_ds = load_data_hf(val_path)\n",
    "    test_ds = load_data_hf(test_path)\n",
    "    if train_ds and val_ds and test_ds:\n",
    "        logging.info(f\"Loaded Train data: {len(train_ds)} examples\")\n",
    "        logging.info(f\"Loaded Validation data: {len(val_ds)} examples\")\n",
    "        logging.info(f\"Loaded Test data: {len(test_ds)} examples\")\n",
    "        return DatasetDict({\n",
    "            'train': train_ds,\n",
    "            'validation': val_ds,\n",
    "            'test': test_ds\n",
    "        })\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def preprocess_function(examples, tokenizer):\n",
    "    \"\"\"Tokenizes text data.\"\"\"\n",
    "    # Ensure text is string, handle potential None values\n",
    "    texts = [str(text) if text is not None else \"\" for text in examples[TEXT_COLUMN]]\n",
    "    return tokenizer(texts, truncation=True, padding=False, max_length=MAX_LENGTH) # Padding handled by DataCollator\n",
    "\n",
    "# Define metric computation function for Trainer\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    preds = np.argmax(predictions, axis=1)\n",
    "\n",
    "    f1_macro = f1_score(labels, preds, average='macro', zero_division=0)\n",
    "    prec_macro = precision_score(labels, preds, average='macro', zero_division=0)\n",
    "    rec_macro = recall_score(labels, preds, average='macro', zero_division=0)\n",
    "    f1_weighted = f1_score(labels, preds, average='weighted', zero_division=0)\n",
    "    prec_weighted = precision_score(labels, preds, average='weighted', zero_division=0)\n",
    "    rec_weighted = recall_score(labels, preds, average='weighted', zero_division=0)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1_macro': f1_macro,\n",
    "        'precision_macro': prec_macro,\n",
    "        'recall_macro': rec_macro,\n",
    "        'f1_weighted': f1_weighted,\n",
    "        'precision_weighted': prec_weighted,\n",
    "        'recall_weighted': rec_weighted,\n",
    "    }\n",
    "\n",
    "def calculate_metrics_from_preds(y_true, y_pred):\n",
    "    \"\"\"Calculates evaluation metrics from direct predictions.\"\"\"\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    f1_macro = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    precision_macro = precision_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    recall_macro = recall_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    f1_weighted = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    precision_weighted = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    recall_weighted = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    # Print the classification report for detailed metrics\n",
    "    \n",
    "\n",
    "    return {\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"F1 (Macro)\": f1_macro,\n",
    "        \"Precision (Macro)\": precision_macro,\n",
    "        \"Recall (Macro)\": recall_macro,\n",
    "        \"F1 (Weighted)\": f1_weighted,\n",
    "        \"Precision (Weighted)\": precision_weighted,\n",
    "        \"Recall (Weighted)\": recall_weighted,\n",
    "    }\n",
    "\n",
    "# Function to extract features (CLS token)\n",
    "def extract_hidden_states(batch, model, tokenizer, device):\n",
    "    # Ensure input_ids and attention_mask are tensors on the correct device\n",
    "    inputs = {k: v.to(device) for k, v in batch.items()\n",
    "              if k in tokenizer.model_input_names}\n",
    "    with torch.no_grad():\n",
    "        last_hidden_state = model(**inputs).last_hidden_state\n",
    "    # Return the representation of the [CLS] token (first token)\n",
    "    # Move back to CPU to accumulate results if needed outside GPU loop\n",
    "    return last_hidden_state[:, 0].cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65ba404",
   "metadata": {},
   "source": [
    "# 3. Run Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c8404b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "982b5b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-01 22:48:08,874 - INFO - Processing Dataset: Book Review\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================= Processing Dataset: Book Review =========================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6315879c4db42ee995f7adb6378153c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f75b31d86ee142daa9b0edf0d0ba0d28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Mapping labels to IDs:   0%|          | 0/210000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "badbfd63f8624c82bc9bd909af8d096e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filtering invalid labels:   0%|          | 0/210000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8b26e9e258c4d5fb8e91e0b14dcf8de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2048ca0495b140f18dc56d20e169fe4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Mapping labels to IDs:   0%|          | 0/45000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b59300997b8c432dbc38ee963c6b5c9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filtering invalid labels:   0%|          | 0/45000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b34137f4636e4fe090ce0e7198db8598",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dfdad015cb74488bbf072edb80aeeb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Mapping labels to IDs:   0%|          | 0/45000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03c573b16df44968b425db37ebfcd078",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filtering invalid labels:   0%|          | 0/45000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-01 22:48:19,542 - INFO - Loaded Train data: 210000 examples\n",
      "2025-05-01 22:48:19,543 - INFO - Loaded Validation data: 45000 examples\n",
      "2025-05-01 22:48:19,543 - INFO - Loaded Test data: 45000 examples\n",
      "2025-05-01 22:48:19,543 - INFO - Starting run for DistilBERT Feature Extractor + LR on Book Review\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing Model: DistilBERT Feature Extractor + LR ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-01 22:48:19,943 - INFO - Tokenizing data using distilbert-base-uncased tokenizer...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7313983f51b4b42b8d31682c5104d21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/210000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a921774c9b93451b81ea0247f8d6c6c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/45000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da2e6a22eb904d108b904c5942f2400d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/45000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-01 22:48:51,687 - INFO - Tokenization complete.\n",
      "2025-05-01 22:48:51,687 - INFO - Running in Feature Extraction mode.\n",
      "2025-05-01 22:48:52,532 - INFO - Extracting features from datasets...\n",
      "2025-05-01 23:09:13,878 - INFO - Feature extraction took 1221.34s\n",
      "2025-05-01 23:09:13,880 - INFO - Train features shape: (210000, 768)\n",
      "2025-05-01 23:09:13,880 - INFO - Training Logistic Regression classifier...\n",
      "2025-05-01 23:25:17,987 - INFO - Classifier training took 964.11s\n",
      "2025-05-01 23:25:18,197 - INFO - Feature Extractor + LR - Test Set Performance:\n",
      "2025-05-01 23:25:18,228 - INFO - Confusion matrix saved to ..\\result\\book_reviews\\Book_Review_DistilBERT_Feature_Extractor__LR_confusion_matrix.csv\n",
      "2025-05-01 23:25:18,230 - INFO - Logistic Regression classifier saved to ..\\models\\llm\\book_reviews\\DistilBERT_Feature_Extractor__LR\\Book_Review_DistilBERT_Feature_Extractor_+_LR_LR_classifier.joblib\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.51      0.74      0.61      5292\n",
      "     neutral       0.22      0.57      0.32      3814\n",
      "    positive       0.96      0.74      0.84     35894\n",
      "\n",
      "    accuracy                           0.73     45000\n",
      "   macro avg       0.57      0.68      0.59     45000\n",
      "weighted avg       0.85      0.73      0.77     45000\n",
      "\n",
      "Confusion Matrix (Test Set):\n",
      "          negative  neutral  positive\n",
      "negative      3891     1041       360\n",
      "neutral        892     2166       756\n",
      "positive      2777     6455     26662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-01 23:25:18,505 - INFO - Starting run for BERT Feature Extractor + LR on Book Review\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing Model: BERT Feature Extractor + LR ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-01 23:25:18,882 - INFO - Tokenizing data using bert-base-uncased tokenizer...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ba5b7cc348544b7b421708f653aa7e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/210000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ca738cbb1ae462cb9ef0f6f9769cb02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/45000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "068918dc8f464d2ba2d7366a5664f3ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/45000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-01 23:25:54,104 - INFO - Tokenization complete.\n",
      "2025-05-01 23:25:54,104 - INFO - Running in Feature Extraction mode.\n",
      "2025-05-01 23:25:55,160 - INFO - Extracting features from datasets...\n",
      "2025-05-02 00:05:55,867 - INFO - Feature extraction took 2400.71s\n",
      "2025-05-02 00:05:55,867 - INFO - Train features shape: (210000, 768)\n",
      "2025-05-02 00:05:55,868 - INFO - Training Logistic Regression classifier...\n",
      "2025-05-02 00:15:02,122 - INFO - Classifier training took 546.25s\n",
      "2025-05-02 00:15:02,331 - INFO - Feature Extractor + LR - Test Set Performance:\n",
      "2025-05-02 00:15:02,361 - INFO - Confusion matrix saved to ..\\result\\book_reviews\\Book_Review_BERT_Feature_Extractor__LR_confusion_matrix.csv\n",
      "2025-05-02 00:15:02,363 - INFO - Logistic Regression classifier saved to ..\\models\\llm\\book_reviews\\BERT_Feature_Extractor__LR\\Book_Review_BERT_Feature_Extractor_+_LR_LR_classifier.joblib\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.71      0.59      5292\n",
      "     neutral       0.22      0.54      0.31      3814\n",
      "    positive       0.96      0.74      0.84     35894\n",
      "\n",
      "    accuracy                           0.72     45000\n",
      "   macro avg       0.56      0.66      0.58     45000\n",
      "weighted avg       0.84      0.72      0.76     45000\n",
      "\n",
      "Confusion Matrix (Test Set):\n",
      "          negative  neutral  positive\n",
      "negative      3773     1149       370\n",
      "neutral        924     2055       835\n",
      "positive      2871     6347     26676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 00:15:02,609 - INFO - Starting run for DistilBERT Full FT on Book Review\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing Model: DistilBERT Full FT ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 00:15:02,972 - INFO - Tokenizing data using distilbert-base-uncased tokenizer...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dda91424c69427a98d23da8cd3cc0a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/45000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 00:15:07,497 - INFO - Tokenization complete.\n",
      "2025-05-02 00:15:07,498 - INFO - Running in Fine-tuning mode (LoRA: False).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2025-05-02 00:15:08,266 - INFO - Starting fine-tuning...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using evaluation_strategy: IntervalStrategy.EPOCH\n",
      "Using save_strategy: SaveStrategy.EPOCH\n",
      "Using load_best_model_at_end: True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39375' max='39375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39375/39375 1:11:20, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>Precision Macro</th>\n",
       "      <th>Recall Macro</th>\n",
       "      <th>F1 Weighted</th>\n",
       "      <th>Precision Weighted</th>\n",
       "      <th>Recall Weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>0.305599</td>\n",
       "      <td>0.894244</td>\n",
       "      <td>0.673707</td>\n",
       "      <td>0.777665</td>\n",
       "      <td>0.655781</td>\n",
       "      <td>0.874733</td>\n",
       "      <td>0.878653</td>\n",
       "      <td>0.894244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.249300</td>\n",
       "      <td>0.311123</td>\n",
       "      <td>0.899956</td>\n",
       "      <td>0.736509</td>\n",
       "      <td>0.757797</td>\n",
       "      <td>0.722791</td>\n",
       "      <td>0.894618</td>\n",
       "      <td>0.891421</td>\n",
       "      <td>0.899956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>0.357838</td>\n",
       "      <td>0.899289</td>\n",
       "      <td>0.744280</td>\n",
       "      <td>0.761130</td>\n",
       "      <td>0.729603</td>\n",
       "      <td>0.896114</td>\n",
       "      <td>0.893703</td>\n",
       "      <td>0.899289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 01:26:29,636 - INFO - Fine-tuning completed in 4281.37s\n",
      "2025-05-02 01:26:29,637 - INFO - Evaluating model on the test set...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 01:28:53,537 - INFO - Fine-tuning - Test Set Performance:\n",
      "2025-05-02 01:28:53,537 - INFO - {'eval_loss': 0.35942190885543823, 'eval_accuracy': 0.8997555555555555, 'eval_f1_macro': 0.745369681444788, 'eval_precision_macro': 0.7617655517570192, 'eval_recall_macro': 0.7312301620847061, 'eval_f1_weighted': 0.8965515704112923, 'eval_precision_weighted': 0.8941068533411948, 'eval_recall_weighted': 0.8997555555555555, 'eval_runtime': 71.1588, 'eval_samples_per_second': 632.389, 'eval_steps_per_second': 19.773, 'epoch': 3.0}\n",
      "2025-05-02 01:28:53,538 - INFO - Fine-tuning - Test Set Confusion Matrix:\n",
      "2025-05-02 01:28:53,542 - INFO - Confusion matrix saved to ..\\result\\book_reviews\\Book_Review_DistilBERT_Full_FT_confusion_matrix.csv\n",
      "2025-05-02 01:28:53,542 - INFO - Best model loaded by Trainer. Checkpoint saved in ..\\models\\llm\\book_reviews\\DistilBERT_Full_FT\\checkpoints\n",
      "2025-05-02 01:28:53,551 - INFO - Tokenizer saved to ..\\models\\llm\\book_reviews\\DistilBERT_Full_FT\\final_model\n",
      "2025-05-02 01:28:53,714 - INFO - Starting run for BERT Full FT on Book Review\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          negative  neutral  positive\n",
      "negative      4065      668       559\n",
      "neutral        618     1753      1443\n",
      "positive       366      857     34671\n",
      "\n",
      "--- Processing Model: BERT Full FT ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 01:28:54,079 - INFO - Tokenizing data using bert-base-uncased tokenizer...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae252d11437b48978dfb75d20451e129",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/45000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 01:28:59,119 - INFO - Tokenization complete.\n",
      "2025-05-02 01:28:59,119 - INFO - Running in Fine-tuning mode (LoRA: False).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2025-05-02 01:28:59,758 - INFO - Starting fine-tuning...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using evaluation_strategy: IntervalStrategy.EPOCH\n",
      "Using save_strategy: SaveStrategy.EPOCH\n",
      "Using load_best_model_at_end: True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39375' max='39375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39375/39375 2:15:53, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>Precision Macro</th>\n",
       "      <th>Recall Macro</th>\n",
       "      <th>F1 Weighted</th>\n",
       "      <th>Precision Weighted</th>\n",
       "      <th>Recall Weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.321800</td>\n",
       "      <td>0.295800</td>\n",
       "      <td>0.898756</td>\n",
       "      <td>0.680368</td>\n",
       "      <td>0.806721</td>\n",
       "      <td>0.661056</td>\n",
       "      <td>0.878278</td>\n",
       "      <td>0.886741</td>\n",
       "      <td>0.898756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.231800</td>\n",
       "      <td>0.313083</td>\n",
       "      <td>0.904800</td>\n",
       "      <td>0.742960</td>\n",
       "      <td>0.768450</td>\n",
       "      <td>0.730481</td>\n",
       "      <td>0.898599</td>\n",
       "      <td>0.895970</td>\n",
       "      <td>0.904800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.169200</td>\n",
       "      <td>0.365307</td>\n",
       "      <td>0.905067</td>\n",
       "      <td>0.759235</td>\n",
       "      <td>0.772842</td>\n",
       "      <td>0.746940</td>\n",
       "      <td>0.902772</td>\n",
       "      <td>0.900955</td>\n",
       "      <td>0.905067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 03:44:54,243 - INFO - Fine-tuning completed in 8154.48s\n",
      "2025-05-02 03:44:54,244 - INFO - Evaluating model on the test set...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 03:49:32,035 - INFO - Fine-tuning - Test Set Performance:\n",
      "2025-05-02 03:49:32,036 - INFO - {'eval_loss': 0.3702978193759918, 'eval_accuracy': 0.9046888888888889, 'eval_f1_macro': 0.7564766966548792, 'eval_precision_macro': 0.7710917206735477, 'eval_recall_macro': 0.7434999096948102, 'eval_f1_weighted': 0.9020696812985897, 'eval_precision_weighted': 0.9000194929634077, 'eval_recall_weighted': 0.9046888888888889, 'eval_runtime': 137.9553, 'eval_samples_per_second': 326.193, 'eval_steps_per_second': 10.199, 'epoch': 3.0}\n",
      "2025-05-02 03:49:32,037 - INFO - Fine-tuning - Test Set Confusion Matrix:\n",
      "2025-05-02 03:49:32,041 - INFO - Confusion matrix saved to ..\\result\\book_reviews\\Book_Review_BERT_Full_FT_confusion_matrix.csv\n",
      "2025-05-02 03:49:32,042 - INFO - Best model loaded by Trainer. Checkpoint saved in ..\\models\\llm\\book_reviews\\BERT_Full_FT\\checkpoints\n",
      "2025-05-02 03:49:32,051 - INFO - Tokenizer saved to ..\\models\\llm\\book_reviews\\BERT_Full_FT\\final_model\n",
      "2025-05-02 03:49:32,228 - INFO - Starting run for RoBERTa Full FT on Book Review\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          negative  neutral  positive\n",
      "negative      4130      679       483\n",
      "neutral        620     1839      1355\n",
      "positive       295      857     34742\n",
      "\n",
      "--- Processing Model: RoBERTa Full FT ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 03:49:32,698 - INFO - Tokenizing data using roberta-base tokenizer...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2294df668fc24a0a99ece776377897c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/210000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c02d8a8b17b14dc681200efc7b7654e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/45000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ddf58b667f748b6b709cbcb745b6d9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/45000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 03:50:01,689 - INFO - Tokenization complete.\n",
      "2025-05-02 03:50:01,690 - INFO - Running in Fine-tuning mode (LoRA: False).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2025-05-02 03:50:02,842 - INFO - Starting fine-tuning...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using evaluation_strategy: IntervalStrategy.EPOCH\n",
      "Using save_strategy: SaveStrategy.EPOCH\n",
      "Using load_best_model_at_end: True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39375' max='39375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39375/39375 2:18:50, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>Precision Macro</th>\n",
       "      <th>Recall Macro</th>\n",
       "      <th>F1 Weighted</th>\n",
       "      <th>Precision Weighted</th>\n",
       "      <th>Recall Weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.313300</td>\n",
       "      <td>0.276434</td>\n",
       "      <td>0.905289</td>\n",
       "      <td>0.712384</td>\n",
       "      <td>0.792399</td>\n",
       "      <td>0.694928</td>\n",
       "      <td>0.890691</td>\n",
       "      <td>0.892989</td>\n",
       "      <td>0.905289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.242600</td>\n",
       "      <td>0.296790</td>\n",
       "      <td>0.910711</td>\n",
       "      <td>0.758270</td>\n",
       "      <td>0.785430</td>\n",
       "      <td>0.741912</td>\n",
       "      <td>0.905009</td>\n",
       "      <td>0.902320</td>\n",
       "      <td>0.910711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.199700</td>\n",
       "      <td>0.329621</td>\n",
       "      <td>0.910733</td>\n",
       "      <td>0.766440</td>\n",
       "      <td>0.783063</td>\n",
       "      <td>0.752890</td>\n",
       "      <td>0.907401</td>\n",
       "      <td>0.904995</td>\n",
       "      <td>0.910733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 06:08:54,284 - INFO - Fine-tuning completed in 8331.44s\n",
      "2025-05-02 06:08:54,285 - INFO - Evaluating model on the test set...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 06:13:28,926 - INFO - Fine-tuning - Test Set Performance:\n",
      "2025-05-02 06:13:28,927 - INFO - {'eval_loss': 0.3335813283920288, 'eval_accuracy': 0.9101333333333333, 'eval_f1_macro': 0.7641207689206952, 'eval_precision_macro': 0.7811966277037125, 'eval_recall_macro': 0.7504179059829492, 'eval_f1_weighted': 0.9066477422094331, 'eval_precision_weighted': 0.9041685072460681, 'eval_recall_weighted': 0.9101333333333333, 'eval_runtime': 136.5746, 'eval_samples_per_second': 329.49, 'eval_steps_per_second': 10.302, 'epoch': 3.0}\n",
      "2025-05-02 06:13:28,927 - INFO - Fine-tuning - Test Set Confusion Matrix:\n",
      "2025-05-02 06:13:28,931 - INFO - Confusion matrix saved to ..\\result\\book_reviews\\Book_Review_RoBERTa_Full_FT_confusion_matrix.csv\n",
      "2025-05-02 06:13:28,931 - INFO - Best model loaded by Trainer. Checkpoint saved in ..\\models\\llm\\book_reviews\\RoBERTa_Full_FT\\checkpoints\n",
      "2025-05-02 06:13:28,967 - INFO - Tokenizer saved to ..\\models\\llm\\book_reviews\\RoBERTa_Full_FT\\final_model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          negative  neutral  positive\n",
      "negative      4295      611       386\n",
      "neutral        648     1785      1381\n",
      "positive       277      741     34876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 06:13:29,152 - INFO - Skipping FinBERT Full FT for Book Review (Model is domain-specific).\n",
      "2025-05-02 06:13:29,152 - INFO - Starting run for BERT LoRA FT on Book Review\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing Model: BERT LoRA FT ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 06:13:29,553 - INFO - Tokenizing data using bert-base-uncased tokenizer...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52d1d6565e804999a784246ed984c0b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/45000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 06:13:34,535 - INFO - Tokenization complete.\n",
      "2025-05-02 06:13:34,536 - INFO - Running in Fine-tuning mode (LoRA: True).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2025-05-02 06:13:34,866 - INFO - Applying LoRA configuration...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 297,219 || all params: 109,781,766 || trainable%: 0.2707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "2025-05-02 06:13:35,205 - INFO - Starting fine-tuning...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using evaluation_strategy: IntervalStrategy.EPOCH\n",
      "Using save_strategy: SaveStrategy.EPOCH\n",
      "Using load_best_model_at_end: True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39375' max='39375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39375/39375 1:42:44, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>Precision Macro</th>\n",
       "      <th>Recall Macro</th>\n",
       "      <th>F1 Weighted</th>\n",
       "      <th>Precision Weighted</th>\n",
       "      <th>Recall Weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.415300</td>\n",
       "      <td>0.349596</td>\n",
       "      <td>0.870600</td>\n",
       "      <td>0.638505</td>\n",
       "      <td>0.688276</td>\n",
       "      <td>0.616487</td>\n",
       "      <td>0.854782</td>\n",
       "      <td>0.847475</td>\n",
       "      <td>0.870600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.352900</td>\n",
       "      <td>0.336474</td>\n",
       "      <td>0.876133</td>\n",
       "      <td>0.659953</td>\n",
       "      <td>0.704863</td>\n",
       "      <td>0.638770</td>\n",
       "      <td>0.863008</td>\n",
       "      <td>0.856953</td>\n",
       "      <td>0.876133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.343600</td>\n",
       "      <td>0.333177</td>\n",
       "      <td>0.875933</td>\n",
       "      <td>0.664420</td>\n",
       "      <td>0.702842</td>\n",
       "      <td>0.643693</td>\n",
       "      <td>0.864383</td>\n",
       "      <td>0.858214</td>\n",
       "      <td>0.875933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 07:56:19,903 - INFO - Fine-tuning completed in 6164.70s\n",
      "2025-05-02 07:56:19,903 - INFO - Evaluating model on the test set...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 08:01:25,096 - INFO - Fine-tuning - Test Set Performance:\n",
      "2025-05-02 08:01:25,096 - INFO - {'eval_loss': 0.3368000388145447, 'eval_accuracy': 0.8787777777777778, 'eval_f1_macro': 0.6715997397846097, 'eval_precision_macro': 0.7174696168092218, 'eval_recall_macro': 0.6482436466612698, 'eval_f1_weighted': 0.8667640116706523, 'eval_precision_weighted': 0.8614690282078064, 'eval_recall_weighted': 0.8787777777777778, 'eval_runtime': 151.8622, 'eval_samples_per_second': 296.321, 'eval_steps_per_second': 9.265, 'epoch': 3.0}\n",
      "2025-05-02 08:01:25,097 - INFO - Fine-tuning - Test Set Confusion Matrix:\n",
      "2025-05-02 08:01:25,101 - INFO - Confusion matrix saved to ..\\result\\book_reviews\\Book_Review_BERT_LoRA_FT_confusion_matrix.csv\n",
      "2025-05-02 08:01:25,101 - INFO - Saving LoRA adapter model to ..\\models\\llm\\book_reviews\\BERT_LoRA_FT\\final_model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          negative  neutral  positive\n",
      "negative      3736      526      1030\n",
      "neutral        724     1029      2061\n",
      "positive       582      532     34780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 08:01:26,627 - INFO - Tokenizer saved to ..\\models\\llm\\book_reviews\\BERT_LoRA_FT\\final_model\n",
      "2025-05-02 08:01:26,804 - INFO - Starting run for RoBERTa LoRA FT on Book Review\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing Model: RoBERTa LoRA FT ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 08:01:27,400 - INFO - Tokenizing data using roberta-base tokenizer...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "527ab18e2c8c4198b2a218618de79594",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/45000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 08:01:31,855 - INFO - Tokenization complete.\n",
      "2025-05-02 08:01:31,855 - INFO - Running in Fine-tuning mode (LoRA: True).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2025-05-02 08:01:32,169 - INFO - Applying LoRA configuration...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 887,811 || all params: 125,535,750 || trainable%: 0.7072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "2025-05-02 08:01:32,539 - INFO - Starting fine-tuning...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using evaluation_strategy: IntervalStrategy.EPOCH\n",
      "Using save_strategy: SaveStrategy.EPOCH\n",
      "Using load_best_model_at_end: True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39375' max='39375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39375/39375 1:42:29, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>Precision Macro</th>\n",
       "      <th>Recall Macro</th>\n",
       "      <th>F1 Weighted</th>\n",
       "      <th>Precision Weighted</th>\n",
       "      <th>Recall Weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.333200</td>\n",
       "      <td>0.289400</td>\n",
       "      <td>0.894911</td>\n",
       "      <td>0.696182</td>\n",
       "      <td>0.742490</td>\n",
       "      <td>0.689228</td>\n",
       "      <td>0.882855</td>\n",
       "      <td>0.881458</td>\n",
       "      <td>0.894911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.297300</td>\n",
       "      <td>0.284263</td>\n",
       "      <td>0.898067</td>\n",
       "      <td>0.717739</td>\n",
       "      <td>0.749934</td>\n",
       "      <td>0.705000</td>\n",
       "      <td>0.889508</td>\n",
       "      <td>0.886298</td>\n",
       "      <td>0.898067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.290600</td>\n",
       "      <td>0.282006</td>\n",
       "      <td>0.898556</td>\n",
       "      <td>0.721433</td>\n",
       "      <td>0.751624</td>\n",
       "      <td>0.705719</td>\n",
       "      <td>0.890698</td>\n",
       "      <td>0.886906</td>\n",
       "      <td>0.898556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 09:44:02,944 - INFO - Fine-tuning completed in 6150.40s\n",
      "2025-05-02 09:44:02,945 - INFO - Evaluating model on the test set...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 09:49:02,399 - INFO - Fine-tuning - Test Set Performance:\n",
      "2025-05-02 09:49:02,399 - INFO - {'eval_loss': 0.2877999544143677, 'eval_accuracy': 0.8984222222222222, 'eval_f1_macro': 0.719141877540694, 'eval_precision_macro': 0.7526124651662789, 'eval_recall_macro': 0.7037834429886437, 'eval_f1_weighted': 0.8899143076637963, 'eval_precision_weighted': 0.8864349284837768, 'eval_recall_weighted': 0.8984222222222222, 'eval_runtime': 149.1208, 'eval_samples_per_second': 301.769, 'eval_steps_per_second': 9.435, 'epoch': 3.0}\n",
      "2025-05-02 09:49:02,400 - INFO - Fine-tuning - Test Set Confusion Matrix:\n",
      "2025-05-02 09:49:02,404 - INFO - Confusion matrix saved to ..\\result\\book_reviews\\Book_Review_RoBERTa_LoRA_FT_confusion_matrix.csv\n",
      "2025-05-02 09:49:02,405 - INFO - Saving LoRA adapter model to ..\\models\\llm\\book_reviews\\RoBERTa_LoRA_FT\\final_model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          negative  neutral  positive\n",
      "negative      4261      454       577\n",
      "neutral        875     1274      1665\n",
      "positive       413      587     34894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 09:49:03,054 - INFO - Tokenizer saved to ..\\models\\llm\\book_reviews\\RoBERTa_LoRA_FT\\final_model\n",
      "2025-05-02 09:49:03,240 - INFO - Processing Dataset: Financial News\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================= Processing Dataset: Financial News =========================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e14cc8617a34f1d8a5285476ec789d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34b8379b2d284b2ead88ec40ea925f56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Mapping labels to IDs:   0%|          | 0/3392 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dee6773dd5db44358a15b0a584f03ff1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filtering invalid labels:   0%|          | 0/3392 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a4086375cef4eaeb023494e08c2e61e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a9e934022e64a0998077a937b70f2cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Mapping labels to IDs:   0%|          | 0/727 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d8eae36eb9d4c629ff60646f42ec5e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filtering invalid labels:   0%|          | 0/727 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07af17717ecc4b588070dc2f19d1d1da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58d86cf1febb4901888fb1147e14d28c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Mapping labels to IDs:   0%|          | 0/727 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4debe24516d9446ebb0a76151ca34721",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filtering invalid labels:   0%|          | 0/727 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 09:49:04,992 - INFO - Loaded Train data: 3392 examples\n",
      "2025-05-02 09:49:04,993 - INFO - Loaded Validation data: 727 examples\n",
      "2025-05-02 09:49:04,993 - INFO - Loaded Test data: 727 examples\n",
      "2025-05-02 09:49:05,035 - INFO - Starting run for DistilBERT Feature Extractor + LR on Financial News\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing Model: DistilBERT Feature Extractor + LR ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 09:49:05,344 - INFO - Tokenizing data using distilbert-base-uncased tokenizer...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "386a8425d8e04771930969accb2f6cc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/3392 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e20e8d8a11574c9e8e32bc573b9559c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/727 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80eb6d6493c94b04ad8bb02831f904fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/727 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 09:49:05,557 - INFO - Tokenization complete.\n",
      "2025-05-02 09:49:05,558 - INFO - Running in Feature Extraction mode.\n",
      "2025-05-02 09:49:05,969 - INFO - Extracting features from datasets...\n",
      "2025-05-02 09:49:11,258 - INFO - Feature extraction took 5.29s\n",
      "2025-05-02 09:49:11,259 - INFO - Train features shape: (3392, 768)\n",
      "2025-05-02 09:49:11,259 - INFO - Training Logistic Regression classifier...\n",
      "2025-05-02 09:49:20,539 - INFO - Classifier training took 9.28s\n",
      "2025-05-02 09:49:20,550 - INFO - Feature Extractor + LR - Test Set Performance:\n",
      "2025-05-02 09:49:20,556 - INFO - Confusion matrix saved to ..\\result\\financial_news\\Financial_News_DistilBERT_Feature_Extractor__LR_confusion_matrix.csv\n",
      "2025-05-02 09:49:20,558 - INFO - Logistic Regression classifier saved to ..\\models\\llm\\financial_news\\DistilBERT_Feature_Extractor__LR\\Financial_News_DistilBERT_Feature_Extractor_+_LR_LR_classifier.joblib\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.59      0.85      0.69        91\n",
      "     neutral       0.87      0.76      0.81       432\n",
      "    positive       0.63      0.68      0.65       204\n",
      "\n",
      "    accuracy                           0.75       727\n",
      "   macro avg       0.70      0.76      0.72       727\n",
      "weighted avg       0.77      0.75      0.75       727\n",
      "\n",
      "Confusion Matrix (Test Set):\n",
      "          negative  neutral  positive\n",
      "negative        77        7         7\n",
      "neutral         32      327        73\n",
      "positive        22       44       138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 09:49:20,816 - INFO - Starting run for BERT Feature Extractor + LR on Financial News\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing Model: BERT Feature Extractor + LR ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 09:49:21,098 - INFO - Tokenizing data using bert-base-uncased tokenizer...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "988217ee9f7743ce9e04a490d5781aca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/3392 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bb134b372164839ba4bca10c48f95dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/727 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e844b17b0421489898d2a48f1bb619b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/727 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 09:49:21,312 - INFO - Tokenization complete.\n",
      "2025-05-02 09:49:21,312 - INFO - Running in Feature Extraction mode.\n",
      "2025-05-02 09:49:21,895 - INFO - Extracting features from datasets...\n",
      "2025-05-02 09:49:31,490 - INFO - Feature extraction took 9.60s\n",
      "2025-05-02 09:49:31,490 - INFO - Train features shape: (3392, 768)\n",
      "2025-05-02 09:49:31,491 - INFO - Training Logistic Regression classifier...\n",
      "2025-05-02 09:49:34,188 - INFO - Classifier training took 2.70s\n",
      "2025-05-02 09:49:34,197 - INFO - Feature Extractor + LR - Test Set Performance:\n",
      "2025-05-02 09:49:34,205 - INFO - Confusion matrix saved to ..\\result\\financial_news\\Financial_News_BERT_Feature_Extractor__LR_confusion_matrix.csv\n",
      "2025-05-02 09:49:34,206 - INFO - Logistic Regression classifier saved to ..\\models\\llm\\financial_news\\BERT_Feature_Extractor__LR\\Financial_News_BERT_Feature_Extractor_+_LR_LR_classifier.joblib\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.57      0.80      0.66        91\n",
      "     neutral       0.88      0.75      0.81       432\n",
      "    positive       0.63      0.71      0.67       204\n",
      "\n",
      "    accuracy                           0.74       727\n",
      "   macro avg       0.69      0.75      0.71       727\n",
      "weighted avg       0.77      0.74      0.75       727\n",
      "\n",
      "Confusion Matrix (Test Set):\n",
      "          negative  neutral  positive\n",
      "negative        73        7        11\n",
      "neutral         35      323        74\n",
      "positive        21       38       145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 09:49:34,507 - INFO - Starting run for DistilBERT Full FT on Financial News\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing Model: DistilBERT Full FT ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 09:49:34,791 - INFO - Tokenizing data using distilbert-base-uncased tokenizer...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd3ec588008140f38554e3d1f2b0beb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/727 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 09:49:34,849 - INFO - Tokenization complete.\n",
      "2025-05-02 09:49:34,850 - INFO - Running in Fine-tuning mode (LoRA: False).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2025-05-02 09:49:35,322 - INFO - Starting fine-tuning...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using evaluation_strategy: IntervalStrategy.EPOCH\n",
      "Using save_strategy: SaveStrategy.EPOCH\n",
      "Using load_best_model_at_end: True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='636' max='636' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [636/636 00:33, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>Precision Macro</th>\n",
       "      <th>Recall Macro</th>\n",
       "      <th>F1 Weighted</th>\n",
       "      <th>Precision Weighted</th>\n",
       "      <th>Recall Weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.618500</td>\n",
       "      <td>0.473743</td>\n",
       "      <td>0.814305</td>\n",
       "      <td>0.766330</td>\n",
       "      <td>0.786861</td>\n",
       "      <td>0.782528</td>\n",
       "      <td>0.808538</td>\n",
       "      <td>0.829345</td>\n",
       "      <td>0.814305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.304800</td>\n",
       "      <td>0.419204</td>\n",
       "      <td>0.834938</td>\n",
       "      <td>0.812727</td>\n",
       "      <td>0.802980</td>\n",
       "      <td>0.823754</td>\n",
       "      <td>0.835882</td>\n",
       "      <td>0.837628</td>\n",
       "      <td>0.834938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.203900</td>\n",
       "      <td>0.452261</td>\n",
       "      <td>0.837689</td>\n",
       "      <td>0.811669</td>\n",
       "      <td>0.799239</td>\n",
       "      <td>0.827744</td>\n",
       "      <td>0.838490</td>\n",
       "      <td>0.840820</td>\n",
       "      <td>0.837689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 09:50:09,106 - INFO - Fine-tuning completed in 33.78s\n",
      "2025-05-02 09:50:09,106 - INFO - Evaluating model on the test set...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 09:50:09,907 - INFO - Fine-tuning - Test Set Performance:\n",
      "2025-05-02 09:50:09,907 - INFO - {'eval_loss': 0.41072723269462585, 'eval_accuracy': 0.8404401650618982, 'eval_f1_macro': 0.8235341655157988, 'eval_precision_macro': 0.8062278440633666, 'eval_recall_macro': 0.8465264310852546, 'eval_f1_weighted': 0.8413002255133367, 'eval_precision_weighted': 0.8447563226746198, 'eval_recall_weighted': 0.8404401650618982, 'eval_runtime': 0.3951, 'eval_samples_per_second': 1840.263, 'eval_steps_per_second': 58.22, 'epoch': 3.0}\n",
      "2025-05-02 09:50:09,908 - INFO - Fine-tuning - Test Set Confusion Matrix:\n",
      "2025-05-02 09:50:09,911 - INFO - Confusion matrix saved to ..\\result\\financial_news\\Financial_News_DistilBERT_Full_FT_confusion_matrix.csv\n",
      "2025-05-02 09:50:09,912 - INFO - Best model loaded by Trainer. Checkpoint saved in ..\\models\\llm\\financial_news\\DistilBERT_Full_FT\\checkpoints\n",
      "2025-05-02 09:50:09,924 - INFO - Tokenizer saved to ..\\models\\llm\\financial_news\\DistilBERT_Full_FT\\final_model\n",
      "2025-05-02 09:50:10,068 - INFO - Starting run for BERT Full FT on Financial News\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          negative  neutral  positive\n",
      "negative        82        5         4\n",
      "neutral         23      369        40\n",
      "positive         6       38       160\n",
      "\n",
      "--- Processing Model: BERT Full FT ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 09:50:10,349 - INFO - Tokenizing data using bert-base-uncased tokenizer...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0defa436a074c36bd439b521b2514a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/727 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 09:50:10,415 - INFO - Tokenization complete.\n",
      "2025-05-02 09:50:10,416 - INFO - Running in Fine-tuning mode (LoRA: False).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2025-05-02 09:50:10,992 - INFO - Starting fine-tuning...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using evaluation_strategy: IntervalStrategy.EPOCH\n",
      "Using save_strategy: SaveStrategy.EPOCH\n",
      "Using load_best_model_at_end: True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='636' max='636' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [636/636 00:58, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>Precision Macro</th>\n",
       "      <th>Recall Macro</th>\n",
       "      <th>F1 Weighted</th>\n",
       "      <th>Precision Weighted</th>\n",
       "      <th>Recall Weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.666800</td>\n",
       "      <td>0.451912</td>\n",
       "      <td>0.832187</td>\n",
       "      <td>0.797065</td>\n",
       "      <td>0.797914</td>\n",
       "      <td>0.807200</td>\n",
       "      <td>0.830745</td>\n",
       "      <td>0.836454</td>\n",
       "      <td>0.832187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.308100</td>\n",
       "      <td>0.400538</td>\n",
       "      <td>0.852820</td>\n",
       "      <td>0.829387</td>\n",
       "      <td>0.820130</td>\n",
       "      <td>0.839766</td>\n",
       "      <td>0.853723</td>\n",
       "      <td>0.855397</td>\n",
       "      <td>0.852820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.179400</td>\n",
       "      <td>0.455921</td>\n",
       "      <td>0.844567</td>\n",
       "      <td>0.820974</td>\n",
       "      <td>0.803300</td>\n",
       "      <td>0.843933</td>\n",
       "      <td>0.846357</td>\n",
       "      <td>0.851185</td>\n",
       "      <td>0.844567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 09:51:09,956 - INFO - Fine-tuning completed in 58.96s\n",
      "2025-05-02 09:51:09,956 - INFO - Evaluating model on the test set...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 09:51:11,357 - INFO - Fine-tuning - Test Set Performance:\n",
      "2025-05-02 09:51:11,357 - INFO - {'eval_loss': 0.4168113172054291, 'eval_accuracy': 0.8514442916093535, 'eval_f1_macro': 0.8353445165945166, 'eval_precision_macro': 0.8233709649729319, 'eval_recall_macro': 0.8491993663562291, 'eval_f1_weighted': 0.8522584734156261, 'eval_precision_weighted': 0.8541837561826048, 'eval_recall_weighted': 0.8514442916093535, 'eval_runtime': 0.682, 'eval_samples_per_second': 1065.987, 'eval_steps_per_second': 33.724, 'epoch': 3.0}\n",
      "2025-05-02 09:51:11,357 - INFO - Fine-tuning - Test Set Confusion Matrix:\n",
      "2025-05-02 09:51:11,360 - INFO - Confusion matrix saved to ..\\result\\financial_news\\Financial_News_BERT_Full_FT_confusion_matrix.csv\n",
      "2025-05-02 09:51:11,360 - INFO - Best model loaded by Trainer. Checkpoint saved in ..\\models\\llm\\financial_news\\BERT_Full_FT\\checkpoints\n",
      "2025-05-02 09:51:11,369 - INFO - Tokenizer saved to ..\\models\\llm\\financial_news\\BERT_Full_FT\\final_model\n",
      "2025-05-02 09:51:11,521 - INFO - Starting run for RoBERTa Full FT on Financial News\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          negative  neutral  positive\n",
      "negative        79        7         5\n",
      "neutral         18      374        40\n",
      "positive         4       34       166\n",
      "\n",
      "--- Processing Model: RoBERTa Full FT ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 09:51:11,864 - INFO - Tokenizing data using roberta-base tokenizer...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae6e5ee16b40467294afe88e96cc909f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/3392 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdc8be465cc94353af3a37ba6a3783a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/727 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6223224874e47d98c98800efad7798d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/727 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 09:51:12,124 - INFO - Tokenization complete.\n",
      "2025-05-02 09:51:12,125 - INFO - Running in Fine-tuning mode (LoRA: False).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2025-05-02 09:51:12,708 - INFO - Starting fine-tuning...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using evaluation_strategy: IntervalStrategy.EPOCH\n",
      "Using save_strategy: SaveStrategy.EPOCH\n",
      "Using load_best_model_at_end: True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='636' max='636' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [636/636 01:02, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>Precision Macro</th>\n",
       "      <th>Recall Macro</th>\n",
       "      <th>F1 Weighted</th>\n",
       "      <th>Precision Weighted</th>\n",
       "      <th>Recall Weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.591300</td>\n",
       "      <td>0.410667</td>\n",
       "      <td>0.854195</td>\n",
       "      <td>0.833312</td>\n",
       "      <td>0.820603</td>\n",
       "      <td>0.859120</td>\n",
       "      <td>0.854057</td>\n",
       "      <td>0.859955</td>\n",
       "      <td>0.854195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.294500</td>\n",
       "      <td>0.391283</td>\n",
       "      <td>0.852820</td>\n",
       "      <td>0.842024</td>\n",
       "      <td>0.827030</td>\n",
       "      <td>0.861262</td>\n",
       "      <td>0.854265</td>\n",
       "      <td>0.859679</td>\n",
       "      <td>0.852820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.196200</td>\n",
       "      <td>0.479494</td>\n",
       "      <td>0.851444</td>\n",
       "      <td>0.841589</td>\n",
       "      <td>0.826037</td>\n",
       "      <td>0.860373</td>\n",
       "      <td>0.852377</td>\n",
       "      <td>0.855485</td>\n",
       "      <td>0.851444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 09:52:15,605 - INFO - Fine-tuning completed in 62.90s\n",
      "2025-05-02 09:52:15,606 - INFO - Evaluating model on the test set...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 09:52:17,045 - INFO - Fine-tuning - Test Set Performance:\n",
      "2025-05-02 09:52:17,046 - INFO - {'eval_loss': 0.3728979825973511, 'eval_accuracy': 0.859697386519945, 'eval_f1_macro': 0.8553361473716953, 'eval_precision_macro': 0.8376828151850101, 'eval_recall_macro': 0.8772140622630819, 'eval_f1_weighted': 0.8605430153813676, 'eval_precision_weighted': 0.864450299028611, 'eval_recall_weighted': 0.859697386519945, 'eval_runtime': 0.697, 'eval_samples_per_second': 1043.046, 'eval_steps_per_second': 32.999, 'epoch': 3.0}\n",
      "2025-05-02 09:52:17,046 - INFO - Fine-tuning - Test Set Confusion Matrix:\n",
      "2025-05-02 09:52:17,049 - INFO - Confusion matrix saved to ..\\result\\financial_news\\Financial_News_RoBERTa_Full_FT_confusion_matrix.csv\n",
      "2025-05-02 09:52:17,049 - INFO - Best model loaded by Trainer. Checkpoint saved in ..\\models\\llm\\financial_news\\RoBERTa_Full_FT\\checkpoints\n",
      "2025-05-02 09:52:17,080 - INFO - Tokenizer saved to ..\\models\\llm\\financial_news\\RoBERTa_Full_FT\\final_model\n",
      "2025-05-02 09:52:17,236 - INFO - Starting run for FinBERT Full FT on Financial News\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          negative  neutral  positive\n",
      "negative        85        5         1\n",
      "neutral         18      367        47\n",
      "positive         1       30       173\n",
      "\n",
      "--- Processing Model: FinBERT Full FT ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 09:52:17,553 - INFO - Tokenizing data using ProsusAI/finbert tokenizer...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e74cf11d59ae48fda7cf33a9e6f027d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/3392 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32f43c96e2f44a199239884c40d6afdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/727 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa223d7dc1f540f69fe5ffcef3197b54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/727 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 09:52:17,772 - INFO - Tokenization complete.\n",
      "2025-05-02 09:52:17,773 - INFO - Running in Fine-tuning mode (LoRA: False).\n",
      "2025-05-02 09:52:19,015 - INFO - Starting fine-tuning...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using evaluation_strategy: IntervalStrategy.EPOCH\n",
      "Using save_strategy: SaveStrategy.EPOCH\n",
      "Using load_best_model_at_end: True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='636' max='636' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [636/636 00:58, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>Precision Macro</th>\n",
       "      <th>Recall Macro</th>\n",
       "      <th>F1 Weighted</th>\n",
       "      <th>Precision Weighted</th>\n",
       "      <th>Recall Weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.627500</td>\n",
       "      <td>0.372209</td>\n",
       "      <td>0.859697</td>\n",
       "      <td>0.840124</td>\n",
       "      <td>0.819596</td>\n",
       "      <td>0.874906</td>\n",
       "      <td>0.860752</td>\n",
       "      <td>0.867856</td>\n",
       "      <td>0.859697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.208200</td>\n",
       "      <td>0.369647</td>\n",
       "      <td>0.877579</td>\n",
       "      <td>0.870019</td>\n",
       "      <td>0.855398</td>\n",
       "      <td>0.887733</td>\n",
       "      <td>0.878667</td>\n",
       "      <td>0.882373</td>\n",
       "      <td>0.877579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.102600</td>\n",
       "      <td>0.440914</td>\n",
       "      <td>0.877579</td>\n",
       "      <td>0.866078</td>\n",
       "      <td>0.849126</td>\n",
       "      <td>0.886879</td>\n",
       "      <td>0.878622</td>\n",
       "      <td>0.882269</td>\n",
       "      <td>0.877579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 09:53:17,362 - INFO - Fine-tuning completed in 58.35s\n",
      "2025-05-02 09:53:17,362 - INFO - Evaluating model on the test set...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 09:53:18,760 - INFO - Fine-tuning - Test Set Performance:\n",
      "2025-05-02 09:53:18,760 - INFO - {'eval_loss': 0.36533597111701965, 'eval_accuracy': 0.8707015130674003, 'eval_f1_macro': 0.8574163395911162, 'eval_precision_macro': 0.8447316300257476, 'eval_recall_macro': 0.8723794361049263, 'eval_f1_weighted': 0.8716577590195416, 'eval_precision_weighted': 0.8745258230006187, 'eval_recall_weighted': 0.8707015130674003, 'eval_runtime': 0.68, 'eval_samples_per_second': 1069.119, 'eval_steps_per_second': 33.824, 'epoch': 3.0}\n",
      "2025-05-02 09:53:18,761 - INFO - Fine-tuning - Test Set Confusion Matrix:\n",
      "2025-05-02 09:53:18,764 - INFO - Confusion matrix saved to ..\\result\\financial_news\\Financial_News_FinBERT_Full_FT_confusion_matrix.csv\n",
      "2025-05-02 09:53:18,764 - INFO - Best model loaded by Trainer. Checkpoint saved in ..\\models\\llm\\financial_news\\FinBERT_Full_FT\\checkpoints\n",
      "2025-05-02 09:53:18,773 - INFO - Tokenizer saved to ..\\models\\llm\\financial_news\\FinBERT_Full_FT\\final_model\n",
      "2025-05-02 09:53:18,922 - INFO - Starting run for BERT LoRA FT on Financial News\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          negative  neutral  positive\n",
      "negative        80        8         3\n",
      "neutral         16      376        40\n",
      "positive         3       24       177\n",
      "\n",
      "--- Processing Model: BERT LoRA FT ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 09:53:19,199 - INFO - Tokenizing data using bert-base-uncased tokenizer...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a827d4821354a7fb6be666ac21d1655",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/727 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 09:53:19,258 - INFO - Tokenization complete.\n",
      "2025-05-02 09:53:19,258 - INFO - Running in Fine-tuning mode (LoRA: True).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2025-05-02 09:53:19,585 - INFO - Applying LoRA configuration...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 297,219 || all params: 109,781,766 || trainable%: 0.2707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "2025-05-02 09:53:19,871 - INFO - Starting fine-tuning...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using evaluation_strategy: IntervalStrategy.EPOCH\n",
      "Using save_strategy: SaveStrategy.EPOCH\n",
      "Using load_best_model_at_end: True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='636' max='636' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [636/636 00:32, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>Precision Macro</th>\n",
       "      <th>Recall Macro</th>\n",
       "      <th>F1 Weighted</th>\n",
       "      <th>Precision Weighted</th>\n",
       "      <th>Recall Weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.062800</td>\n",
       "      <td>0.933600</td>\n",
       "      <td>0.594223</td>\n",
       "      <td>0.248490</td>\n",
       "      <td>0.198074</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.442975</td>\n",
       "      <td>0.353101</td>\n",
       "      <td>0.594223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.929400</td>\n",
       "      <td>0.922395</td>\n",
       "      <td>0.594223</td>\n",
       "      <td>0.248490</td>\n",
       "      <td>0.198074</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.442975</td>\n",
       "      <td>0.353101</td>\n",
       "      <td>0.594223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.919400</td>\n",
       "      <td>0.918918</td>\n",
       "      <td>0.594223</td>\n",
       "      <td>0.248490</td>\n",
       "      <td>0.198074</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.442975</td>\n",
       "      <td>0.353101</td>\n",
       "      <td>0.594223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 09:53:53,077 - INFO - Fine-tuning completed in 33.21s\n",
      "2025-05-02 09:53:53,077 - INFO - Evaluating model on the test set...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 09:53:54,584 - INFO - Fine-tuning - Test Set Performance:\n",
      "2025-05-02 09:53:54,584 - INFO - {'eval_loss': 0.935846745967865, 'eval_accuracy': 0.5914718019257221, 'eval_f1_macro': 0.24776721405934887, 'eval_precision_macro': 0.19770114942528735, 'eval_recall_macro': 0.3317901234567901, 'eval_f1_weighted': 0.44168680800676224, 'eval_precision_weighted': 0.3524356116302234, 'eval_recall_weighted': 0.5914718019257221, 'eval_runtime': 0.742, 'eval_samples_per_second': 979.785, 'eval_steps_per_second': 30.997, 'epoch': 3.0}\n",
      "2025-05-02 09:53:54,584 - INFO - Fine-tuning - Test Set Confusion Matrix:\n",
      "2025-05-02 09:53:54,587 - INFO - Confusion matrix saved to ..\\result\\financial_news\\Financial_News_BERT_LoRA_FT_confusion_matrix.csv\n",
      "2025-05-02 09:53:54,587 - INFO - Saving LoRA adapter model to ..\\models\\llm\\financial_news\\BERT_LoRA_FT\\final_model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          negative  neutral  positive\n",
      "negative         0       91         0\n",
      "neutral          1      430         1\n",
      "positive         0      204         0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 09:53:55,110 - INFO - Tokenizer saved to ..\\models\\llm\\financial_news\\BERT_LoRA_FT\\final_model\n",
      "2025-05-02 09:53:55,276 - INFO - Starting run for RoBERTa LoRA FT on Financial News\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing Model: RoBERTa LoRA FT ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 09:53:55,606 - INFO - Tokenizing data using roberta-base tokenizer...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bea0209942f4f50a32a5f425eb4cd1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/727 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 09:53:55,707 - INFO - Tokenization complete.\n",
      "2025-05-02 09:53:55,708 - INFO - Running in Fine-tuning mode (LoRA: True).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2025-05-02 09:53:56,010 - INFO - Applying LoRA configuration...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 887,811 || all params: 125,535,750 || trainable%: 0.7072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "2025-05-02 09:53:56,318 - INFO - Starting fine-tuning...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using evaluation_strategy: IntervalStrategy.EPOCH\n",
      "Using save_strategy: SaveStrategy.EPOCH\n",
      "Using load_best_model_at_end: True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='636' max='636' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [636/636 00:34, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>Precision Macro</th>\n",
       "      <th>Recall Macro</th>\n",
       "      <th>F1 Weighted</th>\n",
       "      <th>Precision Weighted</th>\n",
       "      <th>Recall Weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.967300</td>\n",
       "      <td>0.921489</td>\n",
       "      <td>0.594223</td>\n",
       "      <td>0.248490</td>\n",
       "      <td>0.198074</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.442975</td>\n",
       "      <td>0.353101</td>\n",
       "      <td>0.594223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.929500</td>\n",
       "      <td>0.907223</td>\n",
       "      <td>0.594223</td>\n",
       "      <td>0.248490</td>\n",
       "      <td>0.198074</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.442975</td>\n",
       "      <td>0.353101</td>\n",
       "      <td>0.594223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.911100</td>\n",
       "      <td>0.895944</td>\n",
       "      <td>0.594223</td>\n",
       "      <td>0.248490</td>\n",
       "      <td>0.198074</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.442975</td>\n",
       "      <td>0.353101</td>\n",
       "      <td>0.594223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 09:54:30,788 - INFO - Fine-tuning completed in 34.47s\n",
      "2025-05-02 09:54:30,789 - INFO - Evaluating model on the test set...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 09:54:32,373 - INFO - Fine-tuning - Test Set Performance:\n",
      "2025-05-02 09:54:32,374 - INFO - {'eval_loss': 0.9231343269348145, 'eval_accuracy': 0.594222833562586, 'eval_f1_macro': 0.24849007765314926, 'eval_precision_macro': 0.19807427785419532, 'eval_recall_macro': 0.3333333333333333, 'eval_f1_weighted': 0.44297543416572416, 'eval_precision_weighted': 0.3531007759271487, 'eval_recall_weighted': 0.594222833562586, 'eval_runtime': 0.7895, 'eval_samples_per_second': 920.792, 'eval_steps_per_second': 29.131, 'epoch': 3.0}\n",
      "2025-05-02 09:54:32,374 - INFO - Fine-tuning - Test Set Confusion Matrix:\n",
      "2025-05-02 09:54:32,377 - INFO - Confusion matrix saved to ..\\result\\financial_news\\Financial_News_RoBERTa_LoRA_FT_confusion_matrix.csv\n",
      "2025-05-02 09:54:32,378 - INFO - Saving LoRA adapter model to ..\\models\\llm\\financial_news\\RoBERTa_LoRA_FT\\final_model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          negative  neutral  positive\n",
      "negative         0       91         0\n",
      "neutral          0      432         0\n",
      "positive         0      204         0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 09:54:32,926 - INFO - Tokenizer saved to ..\\models\\llm\\financial_news\\RoBERTa_LoRA_FT\\final_model\n"
     ]
    }
   ],
   "source": [
    "# --- Loop through each dataset defined in the configuration ---\n",
    "for dataset_name, config in DATASETS_TO_PROCESS.items():\n",
    "    print(f\"\\n{'='*25} Processing Dataset: {dataset_name} {'='*25}\")\n",
    "    logging.info(f\"Processing Dataset: {dataset_name}\")\n",
    "\n",
    "    # 1. Load Data using Hugging Face Datasets\n",
    "    raw_datasets = create_dataset_dict(config['train_path'], config['val_path'], config['test_path'])\n",
    "    if not raw_datasets:\n",
    "        logging.error(f\"Could not load data for {dataset_name}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # --- Loop through each model configuration ---\n",
    "    for model_label, model_id, use_lora, is_feature_extractor in MODEL_CONFIGURATIONS:\n",
    "\n",
    "        # --- Skip FinBERT for non-financial data ---\n",
    "        if model_id == FINBERT_MODEL_ID and dataset_name != \"Financial News\":\n",
    "            logging.info(f\"Skipping {model_label} for {dataset_name} (Model is domain-specific).\")\n",
    "            continue\n",
    "\n",
    "        # --- Skip LoRA runs if flag is off ---\n",
    "        if use_lora and not USE_LORA:\n",
    "            logging.info(f\"Skipping LoRA run {model_label} as USE_LORA is False.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\n--- Processing Model: {model_label} ---\")\n",
    "        logging.info(f\"Starting run for {model_label} on {dataset_name}\")\n",
    "        run_results = {\"Dataset\": dataset_name, \"Model\": model_label}\n",
    "        train_time = 0.0\n",
    "        eval_time = 0.0\n",
    "\n",
    "        # Create specific output dirs for this run's checkpoints/models\n",
    "        run_model_dir = os.path.join(config['model_dir'], model_label.replace(' ', '_').replace('+', ''))\n",
    "        os.makedirs(run_model_dir, exist_ok=True)\n",
    "\n",
    "        try:\n",
    "            # 2. Load Tokenizer\n",
    "            tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "            # 3. Tokenize Datasets\n",
    "            logging.info(f\"Tokenizing data using {model_id} tokenizer...\")\n",
    "            # Apply tokenization in batches\n",
    "            tokenized_datasets = raw_datasets.map(\n",
    "                lambda batch: preprocess_function(batch, tokenizer),\n",
    "                batched=True,\n",
    "                remove_columns=[TEXT_COLUMN], # Remove original text column\n",
    "                desc=\"Running tokenizer on dataset\"\n",
    "            )\n",
    "            # Data collator handles dynamic padding\n",
    "            data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "            logging.info(\"Tokenization complete.\")\n",
    "\n",
    "            # ===========================================\n",
    "            # === 4.A Feature Extraction + Classifier ===\n",
    "            # ===========================================\n",
    "            if is_feature_extractor:\n",
    "                logging.info(\"Running in Feature Extraction mode.\")\n",
    "                # Load base model (no classification head)\n",
    "                model = AutoModel.from_pretrained(model_id).to(DEVICE)\n",
    "                model.eval() # Set to evaluation mode\n",
    "\n",
    "                # --- Extract Features ---\n",
    "                logging.info(\"Extracting features from datasets...\")\n",
    "                start_extract_time = time.time()\n",
    "\n",
    "                # Need dataloaders for batching feature extraction\n",
    "                tokenized_datasets.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "                train_dataloader = DataLoader(tokenized_datasets['train'], batch_size=FEATURE_EXTRACTOR_BATCH_SIZE, collate_fn=data_collator)\n",
    "                val_dataloader = DataLoader(tokenized_datasets['validation'], batch_size=FEATURE_EXTRACTOR_BATCH_SIZE, collate_fn=data_collator)\n",
    "                test_dataloader = DataLoader(tokenized_datasets['test'], batch_size=FEATURE_EXTRACTOR_BATCH_SIZE, collate_fn=data_collator)\n",
    "\n",
    "                X_train_features = []\n",
    "                y_train_labels = []\n",
    "                for batch in train_dataloader:\n",
    "                    y_train_labels.extend(batch['labels'].tolist())\n",
    "                    batch_features = extract_hidden_states(batch, model, tokenizer, DEVICE)\n",
    "                    X_train_features.append(batch_features)\n",
    "\n",
    "                X_val_features = []\n",
    "                y_val_labels = []\n",
    "                for batch in val_dataloader:\n",
    "                    y_val_labels.extend(batch['labels'].tolist())\n",
    "                    batch_features = extract_hidden_states(batch, model, tokenizer, DEVICE)\n",
    "                    X_val_features.append(batch_features)\n",
    "\n",
    "                X_test_features = []\n",
    "                y_test_labels = []\n",
    "                for batch in test_dataloader:\n",
    "                    y_test_labels.extend(batch['labels'].tolist())\n",
    "                    batch_features = extract_hidden_states(batch, model, tokenizer, DEVICE)\n",
    "                    X_test_features.append(batch_features)\n",
    "\n",
    "                X_train_features = np.concatenate(X_train_features)\n",
    "                X_val_features = np.concatenate(X_val_features)\n",
    "                X_test_features = np.concatenate(X_test_features)\n",
    "                end_extract_time = time.time()\n",
    "                logging.info(f\"Feature extraction took {end_extract_time - start_extract_time:.2f}s\")\n",
    "                logging.info(f\"Train features shape: {X_train_features.shape}\")\n",
    "\n",
    "                # --- Train Classifier ---\n",
    "                logging.info(\"Training Logistic Regression classifier...\")\n",
    "                classifier = LogisticRegression(max_iter=LOGREG_MAX_ITER, random_state=RANDOM_STATE, class_weight='balanced', n_jobs=-1)\n",
    "                start_train_time = time.time()\n",
    "                # Combine train + val features for final classifier training? Or tune on val? Simpler: train on train, eval on test.\n",
    "                classifier.fit(X_train_features, y_train_labels)\n",
    "                end_train_time = time.time()\n",
    "                train_time = end_train_time - start_train_time\n",
    "                logging.info(f\"Classifier training took {train_time:.2f}s\")\n",
    "\n",
    "                # --- Evaluate Classifier ---\n",
    "                start_eval_time = time.time()\n",
    "                y_pred_test = classifier.predict(X_test_features)\n",
    "                end_eval_time = time.time()\n",
    "                eval_time = end_eval_time - start_eval_time\n",
    "\n",
    "                test_metrics = calculate_metrics_from_preds(y_test_labels, y_pred_test)\n",
    "                run_results.update(test_metrics)\n",
    "\n",
    "                logging.info(\"Feature Extractor + LR - Test Set Performance:\")\n",
    "                report_str = classification_report(y_test_labels, y_pred_test, target_names=LABEL_LIST, zero_division=0)\n",
    "                print(report_str)\n",
    "\n",
    "                cm = confusion_matrix(y_test_labels, y_pred_test, labels=list(range(NUM_CLASSES))) # Ensure labels are ordered\n",
    "                cm_df = pd.DataFrame(cm, index=LABEL_LIST, columns=LABEL_LIST)\n",
    "                print(\"Confusion Matrix (Test Set):\")\n",
    "                print(cm_df)\n",
    "\n",
    "                cm_filename = f\"{dataset_name.replace(' ', '_')}_{model_label.replace(' ', '_').replace('+','')}_confusion_matrix.csv\"\n",
    "                cm_save_path = os.path.join(config['result_dir'], cm_filename)\n",
    "                try:\n",
    "                    cm_df.to_csv(cm_save_path)\n",
    "                    logging.info(f\"Confusion matrix saved to {cm_save_path}\")\n",
    "                except Exception as cm_e:\n",
    "                    logging.error(f\"Failed to save confusion matrix to {cm_save_path}: {cm_e}\")\n",
    "\n",
    "\n",
    "                # Save the classifier\n",
    "                clf_save_path = os.path.join(run_model_dir, f\"{dataset_name.replace(' ', '_')}_{model_label.replace(' ', '_')}_LR_classifier.joblib\")\n",
    "                joblib.dump(classifier, clf_save_path)\n",
    "                logging.info(f\"Logistic Regression classifier saved to {clf_save_path}\")\n",
    "\n",
    "                # Cleanup GPU memory used by the base model\n",
    "                del model\n",
    "                gc.collect()\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "            # ===========================================\n",
    "            # === 4.B Fine-tuning (Full or LoRA)     ====\n",
    "            # ===========================================\n",
    "            else:\n",
    "                logging.info(f\"Running in Fine-tuning mode (LoRA: {use_lora}).\")\n",
    "                # Load model with sequence classification head\n",
    "                model = AutoModelForSequenceClassification.from_pretrained(\n",
    "                    model_id,\n",
    "                    num_labels=NUM_CLASSES,\n",
    "                    id2label=ID2LABEL,\n",
    "                    label2id=LABEL2ID\n",
    "                )\n",
    "\n",
    "                # --- Apply LoRA if specified ---\n",
    "                if use_lora:\n",
    "                    logging.info(\"Applying LoRA configuration...\")\n",
    "                    peft_config = LoraConfig(\n",
    "                        task_type=TaskType.SEQ_CLS, # Specify task type\n",
    "                        r=LORA_R,\n",
    "                        lora_alpha=LORA_ALPHA,\n",
    "                        lora_dropout=LORA_DROPOUT,\n",
    "                        target_modules=LORA_TARGET_MODULES,\n",
    "                        bias=\"none\" # Usually set bias to 'none' or 'all'\n",
    "                    )\n",
    "                    model = get_peft_model(model, peft_config)\n",
    "                    model.print_trainable_parameters() # Verify LoRA application\n",
    "\n",
    "                model.to(DEVICE) # Move model to GPU before Trainer\n",
    "\n",
    "                # --- Define Training Arguments ---\n",
    "                training_args = TrainingArguments(\n",
    "                    output_dir=os.path.join(run_model_dir, \"checkpoints\"),\n",
    "                    logging_dir=os.path.join(run_model_dir, \"logs\"),\n",
    "                    report_to=\"none\", # Disable wandb/tensorboard reporting unless configured\n",
    "                    num_train_epochs=NUM_EPOCHS,\n",
    "                    learning_rate=LEARNING_RATE,\n",
    "                    weight_decay=WEIGHT_DECAY,\n",
    "                    per_device_train_batch_size=TRAIN_BATCH_SIZE,\n",
    "                    per_device_eval_batch_size=EVAL_BATCH_SIZE,\n",
    "\n",
    "                    # --- Strategies ---\n",
    "                    eval_strategy=\"epoch\",  # Evaluate at the end of each epoch\n",
    "                    save_strategy=\"epoch\",        # Save a checkpoint at the end of each epoch\n",
    "                    logging_strategy=\"epoch\",     # Log metrics at the end of each epoch (consistent)\n",
    "\n",
    "                    # --- Explicitly disable step-based intervals when using epoch strategy ---\n",
    "                    eval_steps=None,              # Do not evaluate every N steps\n",
    "                    save_steps=None,              # Do not save every N steps\n",
    "                    logging_steps=None,           # Do not log every N steps (use logging_strategy=\"epoch\")\n",
    "                    # Note: If you WANT step-based logging while using epoch eval/save, you can set\n",
    "                    # logging_strategy=\"steps\" and provide a value for logging_steps, but keep\n",
    "                    # eval_steps=None and save_steps=None.\n",
    "\n",
    "                    # --- Best model loading ---\n",
    "                    load_best_model_at_end=True, # Load the best model based on metric_for_best_model\n",
    "                    metric_for_best_model=METRIC_FOR_BEST_MODEL, # e.g., \"f1_macro\"\n",
    "                    greater_is_better=True,      # F1 score is better when higher\n",
    "                    save_total_limit=2,          # Only keep the best and the latest checkpoint\n",
    "\n",
    "                    # --- Other settings ---\n",
    "                    fp16=FP16,                   # Enable mixed precision training if GPU supports it\n",
    "                    # logging_steps=50,          # Remove or comment out if using logging_strategy=\"epoch\"\n",
    "                    # dataloader_num_workers=2,  # Optional\n",
    "                    gradient_accumulation_steps=1,\n",
    "                    seed=RANDOM_STATE,\n",
    "                    remove_unused_columns=True, # Default is True, good practice\n",
    "                )\n",
    "\n",
    "                print(f\"Using evaluation_strategy: {training_args.eval_strategy}\") # Add this print statement\n",
    "                print(f\"Using save_strategy: {training_args.save_strategy}\")\n",
    "                print(f\"Using load_best_model_at_end: {training_args.load_best_model_at_end}\")\n",
    "\n",
    "                # --- Define Trainer ---\n",
    "                trainer = Trainer(\n",
    "                    model=model,\n",
    "                    args=training_args,\n",
    "                    train_dataset=tokenized_datasets[\"train\"],\n",
    "                    eval_dataset=tokenized_datasets[\"validation\"], # Use validation set for evaluation during training\n",
    "                    tokenizer=tokenizer,\n",
    "                    data_collator=data_collator,\n",
    "                    compute_metrics=compute_metrics,\n",
    "                    callbacks=[EarlyStoppingCallback(early_stopping_patience=2, early_stopping_threshold=0.001)] # Stop if metric doesn't improve enough\n",
    "                )\n",
    "\n",
    "                # --- Train the Model ---\n",
    "                logging.info(\"Starting fine-tuning...\")\n",
    "                start_train_time = time.time()\n",
    "                train_result = trainer.train()\n",
    "                end_train_time = time.time()\n",
    "                train_time = end_train_time - start_train_time\n",
    "                logging.info(f\"Fine-tuning completed in {train_time:.2f}s\")\n",
    "\n",
    "                # --- Evaluate on Test Set ---\n",
    "                logging.info(\"Evaluating model on the test set...\")\n",
    "                start_eval_time = time.time()\n",
    "                # Evaluate first to get metrics like loss\n",
    "                test_results = trainer.evaluate(eval_dataset=tokenized_datasets[\"test\"])\n",
    "                # Then predict to get raw predictions for confusion matrix\n",
    "                predictions = trainer.predict(tokenized_datasets[\"test\"])\n",
    "                end_eval_time = time.time()\n",
    "                eval_time = end_eval_time - start_eval_time\n",
    "\n",
    "                # Extract predictions and labels\n",
    "                y_pred_test = np.argmax(predictions.predictions, axis=1)\n",
    "                y_true_test = predictions.label_ids\n",
    "\n",
    "                # Map trainer metric names (e.g., 'eval_f1_macro') to our standard names\n",
    "                run_results[\"Accuracy\"] = test_results.get('eval_accuracy', np.nan)\n",
    "                run_results[\"F1 (Macro)\"] = test_results.get('eval_f1_macro', np.nan)\n",
    "                run_results[\"Precision (Macro)\"] = test_results.get('eval_precision_macro', np.nan)\n",
    "                run_results[\"Recall (Macro)\"] = test_results.get('eval_recall_macro', np.nan)\n",
    "                run_results[\"F1 (Weighted)\"] = test_results.get('eval_f1_weighted', np.nan)\n",
    "                run_results[\"Precision (Weighted)\"] = test_results.get('eval_precision_weighted', np.nan)\n",
    "                run_results[\"Recall (Weighted)\"] = test_results.get('eval_recall_weighted', np.nan)\n",
    "\n",
    "                logging.info(\"Fine-tuning - Test Set Performance:\")\n",
    "                logging.info(test_results) # Log the full results dict from trainer\n",
    "\n",
    "                # Generate, print, and save the confusion matrix using predictions\n",
    "                logging.info(\"Fine-tuning - Test Set Confusion Matrix:\")\n",
    "                cm = confusion_matrix(y_true_test, y_pred_test, labels=list(range(NUM_CLASSES))) # Ensure labels are ordered\n",
    "                cm_df = pd.DataFrame(cm, index=LABEL_LIST, columns=LABEL_LIST)\n",
    "                print(cm_df)\n",
    "\n",
    "                # Save the confusion matrix\n",
    "                cm_filename = f\"{dataset_name.replace(' ', '_')}_{model_label.replace(' ', '_').replace('+','')}_confusion_matrix.csv\"\n",
    "                cm_save_path = os.path.join(config['result_dir'], cm_filename)\n",
    "                try:\n",
    "                    cm_df.to_csv(cm_save_path, mode='w+')\n",
    "                    logging.info(f\"Confusion matrix saved to {cm_save_path}\")\n",
    "                except Exception as cm_e:\n",
    "                    logging.error(f\"Failed to save confusion matrix to {cm_save_path}: {cm_e}\")\n",
    "\n",
    "                # --- Save the Final Model & Tokenizer ---\n",
    "                # Trainer already saved the best checkpoint based on validation set.\n",
    "                # For LoRA, the main model is saved by Trainer, adapters need separate save\n",
    "                final_model_save_path = os.path.join(run_model_dir, \"final_model\")\n",
    "                if use_lora:\n",
    "                    logging.info(f\"Saving LoRA adapter model to {final_model_save_path}\")\n",
    "                    model.save_pretrained(final_model_save_path) # Saves only the adapter\n",
    "                else:\n",
    "                    # If not LoRA, trainer saved the full best model, we can optionally save it again here\n",
    "                    # under a consistent name if needed, but load_best_model_at_end handles loading it.\n",
    "                    # Saving explicitly:\n",
    "                    # trainer.save_model(final_model_save_path)\n",
    "                    logging.info(f\"Best model loaded by Trainer. Checkpoint saved in {training_args.output_dir}\")\n",
    "\n",
    "\n",
    "                tokenizer.save_pretrained(final_model_save_path) # Save tokenizer with the model/adapter\n",
    "                logging.info(f\"Tokenizer saved to {final_model_save_path}\")\n",
    "\n",
    "            # --- Store Timings and Finalize Results ---\n",
    "            run_results[\"Train Time (s)\"] = round(train_time, 3)\n",
    "            run_results[\"Eval Time (s)\"] = round(eval_time, 3)\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"!!! An error occurred while processing {model_label} for {dataset_name}: {e}\", exc_info=True)\n",
    "            # Record partial results if possible\n",
    "            run_results[\"Accuracy\"] = np.nan\n",
    "            run_results[\"F1 (Macro)\"] = np.nan\n",
    "            # Fill other metrics with NaN or error messages\n",
    "            for metric in METRICS_TO_CALCULATE:\n",
    "                if metric not in run_results:\n",
    "                    run_results[metric] = np.nan if metric not in [\"Train Time (s)\", \"Eval Time (s)\"] else 0.0\n",
    "        finally:\n",
    "            all_results.append(run_results)\n",
    "            # Clean up memory aggressively after each run\n",
    "            del tokenizer\n",
    "            if 'model' in locals(): del model\n",
    "            if 'trainer' in locals(): del trainer\n",
    "            if 'classifier' in locals(): del classifier\n",
    "            if 'tokenized_datasets' in locals(): del tokenized_datasets\n",
    "            # if 'raw_datasets' in locals(): del raw_datasets\n",
    "            gc.collect()\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "# --- Combine results into a DataFrame ---\n",
    "results_df = pd.DataFrame(all_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f17493",
   "metadata": {},
   "source": [
    "# 4. Results Summary and Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "870708ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "===== Overall LLM Results Summary =====\n",
      "           Dataset                              Model  Accuracy  F1 (Macro)  Precision (Macro)  Recall (Macro)  F1 (Weighted)  Precision (Weighted)  Recall (Weighted)  Train Time (s)  Eval Time (s)\n",
      "0      Book Review  DistilBERT Feature Extractor + LR    0.7271      0.5881             0.5662          0.6820         0.7665                0.8451             0.7271        964.1050         0.1320\n",
      "1      Book Review        BERT Feature Extractor + LR    0.7223      0.5770             0.5568          0.6650         0.7624                0.8400             0.7223        546.2540         0.1310\n",
      "2      Book Review                 DistilBERT Full FT    0.8998      0.7454             0.7618          0.7312         0.8966                0.8941             0.8998       4281.3700       143.8980\n",
      "3      Book Review                       BERT Full FT    0.9047      0.7565             0.7711          0.7435         0.9021                0.9000             0.9047       8154.4850       277.7890\n",
      "4      Book Review                    RoBERTa Full FT    0.9101      0.7641             0.7812          0.7504         0.9066                0.9042             0.9101       8331.4420       274.6400\n",
      "5      Book Review                       BERT LoRA FT    0.8788      0.6716             0.7175          0.6482         0.8668                0.8615             0.8788       6164.6970       305.1920\n",
      "6      Book Review                    RoBERTa LoRA FT    0.8984      0.7191             0.7526          0.7038         0.8899                0.8864             0.8984       6150.4050       299.4530\n",
      "7   Financial News  DistilBERT Feature Extractor + LR    0.7455      0.7184             0.6953          0.7599         0.7501                0.7653             0.7455          9.2800         0.0030\n",
      "8   Financial News        BERT Feature Extractor + LR    0.7442      0.7131             0.6913          0.7536         0.7504                0.7693             0.7442          2.6970         0.0020\n",
      "9   Financial News                 DistilBERT Full FT    0.8404      0.8235             0.8062          0.8465         0.8413                0.8448             0.8404         33.7820         0.8010\n",
      "10  Financial News                       BERT Full FT    0.8514      0.8353             0.8234          0.8492         0.8523                0.8542             0.8514         58.9640         1.3990\n",
      "11  Financial News                    RoBERTa Full FT    0.8597      0.8553             0.8377          0.8772         0.8605                0.8645             0.8597         62.8960         1.4390\n",
      "12  Financial News                    FinBERT Full FT    0.8707      0.8574             0.8447          0.8724         0.8717                0.8745             0.8707         58.3470         1.3970\n",
      "13  Financial News                       BERT LoRA FT    0.5915      0.2478             0.1977          0.3318         0.4417                0.3524             0.5915         33.2060         1.5060\n",
      "14  Financial News                    RoBERTa LoRA FT    0.5942      0.2485             0.1981          0.3333         0.4430                0.3531             0.5942         34.4690         1.5850\n",
      "\n",
      "Results for Book Review saved to ..\\result\\book_reviews\\Book_Review_llm_transformers_results.csv\n",
      "\n",
      "Results for Financial News saved to ..\\result\\financial_news\\Financial_News_llm_transformers_results.csv\n",
      "\n",
      "Combined results saved to ..\\result\\combined_llm_transformers_results.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n===== Overall LLM Results Summary =====\")\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1400) # Wider display\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)\n",
    "\n",
    "# Ensure all expected columns exist, fill with NaN if necessary\n",
    "for col in METRICS_TO_CALCULATE:\n",
    "    if col not in results_df.columns:\n",
    "        results_df[col] = np.nan\n",
    "\n",
    "# Reorder columns for clarity\n",
    "column_order = [\"Dataset\", \"Model\"] + METRICS_TO_CALCULATE\n",
    "# Filter out columns not present if something went wrong during creation\n",
    "column_order = [col for col in column_order if col in results_df.columns]\n",
    "results_df = results_df[column_order]\n",
    "\n",
    "\n",
    "print(results_df)\n",
    "\n",
    "# --- Save results to CSV for each dataset ---\n",
    "for dataset_name, config in DATASETS_TO_PROCESS.items():\n",
    "    dataset_results_df = results_df[results_df['Dataset'] == dataset_name]\n",
    "    if not dataset_results_df.empty:\n",
    "        results_filename = f\"{dataset_name.replace(' ', '_')}_llm_transformers_results.csv\"\n",
    "        results_save_path = os.path.join(config['result_dir'], results_filename)\n",
    "        try:\n",
    "            dataset_results_df.to_csv(results_save_path, index=False, mode='w+')\n",
    "            print(f\"\\nResults for {dataset_name} saved to {results_save_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError saving results for {dataset_name} to {results_save_path}: {e}\")\n",
    "\n",
    "# --- Save combined results ---\n",
    "combined_results_path = os.path.join(RESULT_DIR, \"combined_llm_transformers_results.csv\")\n",
    "try:\n",
    "    results_df.to_csv(combined_results_path, index=False, mode='w+')\n",
    "    print(f\"\\nCombined results saved to {combined_results_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nError saving combined results to {combined_results_path}: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
