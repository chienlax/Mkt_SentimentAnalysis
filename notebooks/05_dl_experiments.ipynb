{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7965e536",
   "metadata": {},
   "source": [
    "# 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddddf146",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    classification_report,\n",
    "    confusion_matrix\n",
    "    \n",
    ")\n",
    "import time\n",
    "import os\n",
    "import joblib\n",
    "import logging\n",
    "import warnings\n",
    "import gc\n",
    "import psutil\n",
    "\n",
    "# --- Basic Configuration ---\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "# --- Limit CPU Usage ---\n",
    "p = psutil.Process()\n",
    "p.cpu_affinity([1, 2, 3, 4, 5, 6, 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac006e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Project Directory Structure ---\n",
    "BASE_DIR = \"..\" \n",
    "DATA_DIR = os.path.join(BASE_DIR, \"data\", \"processed\")\n",
    "\n",
    "MODEL_OUTPUT_BASE_DIR = os.path.join(BASE_DIR, \"models\", \"dl\")\n",
    "RESULT_DIR = os.path.join(BASE_DIR, \"result\")\n",
    "\n",
    "# --- Specific Dataset Paths ---\n",
    "BOOK_REVIEW_DATA_DIR = os.path.join(DATA_DIR, \"book_reviews\")\n",
    "FINANCIAL_NEWS_DATA_DIR = os.path.join(DATA_DIR, \"financial_news\")\n",
    "\n",
    "# --- Model/Result Output Dirs (Ensure they exist) ---\n",
    "BOOK_REVIEW_MODEL_DIR = os.path.join(MODEL_OUTPUT_BASE_DIR, \"book_reviews\")\n",
    "FINANCIAL_NEWS_MODEL_DIR = os.path.join(MODEL_OUTPUT_BASE_DIR, \"financial_news\")\n",
    "BOOK_REVIEW_RESULT_DIR = os.path.join(RESULT_DIR, \"book_reviews\")\n",
    "FINANCIAL_NEWS_RESULT_DIR = os.path.join(RESULT_DIR, \"financial_news\")\n",
    "\n",
    "os.makedirs(BOOK_REVIEW_MODEL_DIR, exist_ok=True)\n",
    "os.makedirs(FINANCIAL_NEWS_MODEL_DIR, exist_ok=True)\n",
    "os.makedirs(BOOK_REVIEW_RESULT_DIR, exist_ok=True)\n",
    "os.makedirs(FINANCIAL_NEWS_RESULT_DIR, exist_ok=True)\n",
    "\n",
    "# --- GloVe Path ---\n",
    "GLOVE_PATH = os.path.join(BASE_DIR, \"data\", \"embeddings\", \"glove.6B.100d.txt\")\n",
    "\n",
    "# --- File Names ---\n",
    "TRAIN_FN = \"train.csv\"\n",
    "VAL_FN = \"val.csv\"\n",
    "TEST_FN = \"test.csv\"\n",
    "\n",
    "# --- Column Names ---\n",
    "TEXT_COLUMN = \"text\"\n",
    "TARGET_COLUMN = \"score\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27800f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Model & Training Hyperparameters ---\n",
    "RANDOM_STATE = 42\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logging.info(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# Vocabulary params\n",
    "MIN_WORD_FREQ = 3 # Minimum frequency for a word to be included in the vocabulary\n",
    "\n",
    "# Embedding params\n",
    "EMBEDDING_DIM = 100 # Must match GloVe dimension if using pre-trained GloVe\n",
    "LEARNED_EMBEDDING_DIM = 100 # Dimension for embeddings learned from scratch\n",
    "\n",
    "# Model Arch params (can be tuned)\n",
    "HIDDEN_DIM_RNN_LSTM = 128\n",
    "N_LAYERS_RNN_LSTM = 2\n",
    "DROPOUT = 0.3\n",
    "N_FILTERS_CNN = 100\n",
    "FILTER_SIZES_CNN = [3, 4, 5] # Kernel sizes for CNN\n",
    "\n",
    "# Training params\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 1024\n",
    "NUM_EPOCHS = 50 # Increase for better performance, but takes longer\n",
    "GRADIENT_CLIP = 1.0 # Helps prevent exploding gradients in RNNs/LSTMs\n",
    "\n",
    "# --- Evaluation Metrics ---\n",
    "METRICS_TO_CALCULATE = [\n",
    "    \"Accuracy\",\n",
    "    \"F1 (Macro)\", \"Precision (Macro)\", \"Recall (Macro)\",\n",
    "    \"F1 (Weighted)\", \"Precision (Weighted)\", \"Recall (Weighted)\",\n",
    "    \"Train Time (Epoch, s)\", \"Eval Time (s)\" # Train time per epoch is more practical for DL\n",
    "]\n",
    "\n",
    "# --- Label Mapping (For PyTorch CrossEntropyLoss) ---\n",
    "LABEL_MAP = {'negative': 0, 'neutral': 1, 'positive': 2} # Example mapping\n",
    "NUM_CLASSES = len(LABEL_MAP)\n",
    "\n",
    "# --- Datasets Configuration ---\n",
    "DATASETS_TO_PROCESS = {\n",
    "    \"Book Review\": {\n",
    "        \"train_path\": os.path.join(BOOK_REVIEW_DATA_DIR, f'book_reviews_{TRAIN_FN}'),\n",
    "        \"val_path\": os.path.join(BOOK_REVIEW_DATA_DIR, f'book_reviews_{VAL_FN}'),\n",
    "        \"test_path\": os.path.join(BOOK_REVIEW_DATA_DIR, f'book_reviews_{TEST_FN}'),\n",
    "        \"model_dir\": BOOK_REVIEW_MODEL_DIR,\n",
    "        \"result_dir\": BOOK_REVIEW_RESULT_DIR,\n",
    "        \"vocab_path\": os.path.join(BOOK_REVIEW_MODEL_DIR, \"vocab.pt\"), # Save vocab per dataset\n",
    "    },\n",
    "    \"Financial News\": {\n",
    "        \"train_path\": os.path.join(FINANCIAL_NEWS_DATA_DIR, f'financial_news_{TRAIN_FN}'),\n",
    "        \"val_path\": os.path.join(FINANCIAL_NEWS_DATA_DIR, f'financial_news_{VAL_FN}'),\n",
    "        \"test_path\": os.path.join(FINANCIAL_NEWS_DATA_DIR, f'financial_news_{TEST_FN}'),\n",
    "        \"model_dir\": FINANCIAL_NEWS_MODEL_DIR,\n",
    "        \"result_dir\": FINANCIAL_NEWS_RESULT_DIR,\n",
    "         \"vocab_path\": os.path.join(FINANCIAL_NEWS_MODEL_DIR, \"vocab.pt\"),\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db1ae5b",
   "metadata": {},
   "source": [
    "# 2. Utility Functions and Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508fdae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    \"\"\"Loads data from CSV and handles basic cleaning.\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(path)\n",
    "        df = df.dropna(subset=[TEXT_COLUMN, TARGET_COLUMN]) # Drop rows with NaNs in critical columns\n",
    "        df[TEXT_COLUMN] = df[TEXT_COLUMN].astype(str) # Ensure text is string\n",
    "        df[TARGET_COLUMN] = df[TARGET_COLUMN].astype(str) # Ensure labels are string before mapping\n",
    "        # Map labels to integers\n",
    "        df[TARGET_COLUMN] = df[TARGET_COLUMN].map(LABEL_MAP)\n",
    "        # Verify mapping worked - check for NaNs introduced if a label wasn't in LABEL_MAP\n",
    "        if df[TARGET_COLUMN].isnull().any():\n",
    "            logging.warning(f\"NaNs found in target column after mapping for {path}. Check LABEL_MAP and data labels.\")\n",
    "            # Option: Drop rows with unmapped labels\n",
    "            original_count = len(df)\n",
    "            df = df.dropna(subset=[TARGET_COLUMN])\n",
    "            logging.warning(f\"Dropped {original_count - len(df)} rows with unmappable labels.\")\n",
    "        df[TARGET_COLUMN] = df[TARGET_COLUMN].astype(int) # Convert to int after mapping\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        logging.error(f\"File not found: {path}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error loading data from {path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def tokenize(text):\n",
    "    \"\"\"Simple whitespace tokenizer.\"\"\"\n",
    "    return text.lower().split()\n",
    "\n",
    "def build_vocab(texts, min_freq=MIN_WORD_FREQ):\n",
    "    \"\"\"Builds a vocabulary from a list of texts.\"\"\"\n",
    "    word_counts = Counter()\n",
    "    for text in texts:\n",
    "        word_counts.update(tokenize(text))\n",
    "\n",
    "    # Create vocab mapping: word -> index\n",
    "    # Add special tokens: <pad> for padding, <unk> for unknown words\n",
    "    vocab = {\"<pad>\": 0, \"<unk>\": 1}\n",
    "    idx = 2\n",
    "    for word, count in word_counts.items():\n",
    "        if count >= min_freq:\n",
    "            vocab[word] = idx\n",
    "            idx += 1\n",
    "    logging.info(f\"Built vocabulary with {len(vocab)} words (min freq: {min_freq}).\")\n",
    "    return vocab\n",
    "\n",
    "class SentimentDataset(Dataset):\n",
    "    \"\"\"PyTorch Dataset for sentiment analysis.\"\"\"\n",
    "    def __init__(self, texts, labels, vocab, max_len=None): # max_len can be added for truncation\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.vocab = vocab\n",
    "        self.vocab_stoi = vocab # word -> index\n",
    "        self.vocab_itos = {i: w for w, i in vocab.items()} # index -> word\n",
    "        self.unk_idx = vocab.get(\"<unk>\", 1)\n",
    "        # self.max_len = max_len # Optional: truncate sequences\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        tokens = tokenize(text)\n",
    "        # Convert tokens to indices\n",
    "        token_ids = [self.vocab_stoi.get(token, self.unk_idx) for token in tokens]\n",
    "\n",
    "        # Optional Truncation:\n",
    "        # if self.max_len:\n",
    "        #     token_ids = token_ids[:self.max_len]\n",
    "\n",
    "        return torch.tensor(token_ids, dtype=torch.long), torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "def collate_batch(batch):\n",
    "    \"\"\"Collates data samples into batches with padding.\"\"\"\n",
    "    label_list, text_list, lengths = [], [], []\n",
    "    for (_text, _label) in batch:\n",
    "        label_list.append(_label)\n",
    "        processed_text = torch.tensor(_text, dtype=torch.long)\n",
    "        text_list.append(processed_text)\n",
    "        lengths.append(len(processed_text)) # Store original lengths\n",
    "\n",
    "    # Pad sequences to the max length in this batch\n",
    "    # batch_first=True means output shape is (batch_size, seq_len)\n",
    "    text_list_padded = pad_sequence(text_list, batch_first=True, padding_value=0) # Use PAD index 0\n",
    "\n",
    "    label_list = torch.tensor(label_list, dtype=torch.long)\n",
    "    lengths = torch.tensor(lengths, dtype=torch.long) # Useful for packed sequences later if needed\n",
    "\n",
    "    return text_list_padded, label_list, lengths\n",
    "\n",
    "\n",
    "def load_glove_embeddings(glove_path, vocab_stoi, embedding_dim):\n",
    "    \"\"\"Loads GloVe embeddings for words in the vocabulary.\"\"\"\n",
    "    if not os.path.exists(glove_path):\n",
    "        logging.error(f\"GloVe file not found at: {glove_path}\")\n",
    "        return None\n",
    "\n",
    "    logging.info(f\"Loading GloVe embeddings from {glove_path}\")\n",
    "    embeddings_index = {}\n",
    "    try:\n",
    "        with open(glove_path, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                values = line.split()\n",
    "                word = values[0]\n",
    "                try:\n",
    "                    vector = np.asarray(values[1:], dtype='float32')\n",
    "                    embeddings_index[word] = vector\n",
    "                except ValueError:\n",
    "                    logging.debug(f\"Skipping line in GloVe file (could not parse vector): {line[:50]}...\")\n",
    "                    continue # Skip lines that might not parse correctly\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error reading GloVe file: {e}\")\n",
    "        return None\n",
    "\n",
    "    logging.info(f\"Found {len(embeddings_index)} word vectors in GloVe file.\")\n",
    "\n",
    "    vocab_size = len(vocab_stoi)\n",
    "    # Initialize embedding matrix with zeros or small random values\n",
    "    # np.random.seed(RANDOM_STATE)\n",
    "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "    # Or random init: embedding_matrix = np.random.rand(vocab_size, embedding_dim) * 0.02 - 0.01\n",
    "\n",
    "    found_count = 0\n",
    "    for word, i in vocab_stoi.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            # Words not found in embedding index will remain zeros (or random).\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "            found_count += 1\n",
    "        else:\n",
    "            # Handle <unk> and <pad> specifically\n",
    "            if word == \"<unk>\": # Initialize <unk> token vector (e.g., average or random)\n",
    "                embedding_matrix[i] = np.random.rand(embedding_dim) * 0.02 - 0.01 # Small random\n",
    "                # pass\n",
    "            elif word == \"<pad>\":\n",
    "                embedding_matrix[i] = np.zeros(embedding_dim) # Ensure PAD is zeros\n",
    "\n",
    "    logging.info(f\"Initialized embedding matrix. Shape: {embedding_matrix.shape}\")\n",
    "    logging.info(f\"Found pre-trained vectors for {found_count}/{vocab_size} words in vocabulary.\")\n",
    "    return torch.tensor(embedding_matrix, dtype=torch.float)\n",
    "\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    \"\"\"Calculates evaluation metrics.\"\"\"\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    f1_macro = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    precision_macro = precision_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    recall_macro = recall_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    f1_weighted = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    precision_weighted = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    recall_weighted = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    return {\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"F1 (Macro)\": f1_macro,\n",
    "        \"Precision (Macro)\": precision_macro,\n",
    "        \"Recall (Macro)\": recall_macro,\n",
    "        \"F1 (Weighted)\": f1_weighted,\n",
    "        \"Precision (Weighted)\": precision_weighted,\n",
    "        \"Recall (Weighted)\": recall_weighted,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcd3dc4",
   "metadata": {},
   "source": [
    "# 3. Model Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65319ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Base Model with Embedding Handling ---\n",
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, output_dim, pad_idx, pretrained_embeddings=None, freeze_embeddings=False):\n",
    "        super().__init__()\n",
    "        if pretrained_embeddings is not None:\n",
    "            self.embedding = nn.Embedding.from_pretrained(\n",
    "                pretrained_embeddings,\n",
    "                freeze=freeze_embeddings,\n",
    "                padding_idx=pad_idx\n",
    "            )\n",
    "            logging.info(f\"Using pre-trained embeddings. Freeze: {freeze_embeddings}\")\n",
    "        else:\n",
    "            self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
    "            logging.info(\"Using learned embeddings.\")\n",
    "        self.output_dim = output_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58f4bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. MLP on Averaged Embeddings ---\n",
    "# Note: This averages embeddings before passing to MLP, simpler than sequence processing.\n",
    "class MLPAveraged(BaseModel):\n",
    "     def __init__(self, vocab_size, embedding_dim, output_dim, pad_idx, hidden_dim1=64, hidden_dim2=32, dropout=DROPOUT, pretrained_embeddings=None, freeze_embeddings=False):\n",
    "         # embedding_dim is input_dim for MLP part\n",
    "         super().__init__(vocab_size, embedding_dim, output_dim, pad_idx, pretrained_embeddings, freeze_embeddings)\n",
    "         self.fc1 = nn.Linear(embedding_dim, hidden_dim1)\n",
    "         self.fc2 = nn.Linear(hidden_dim1, hidden_dim2)\n",
    "         self.fc3 = nn.Linear(hidden_dim2, output_dim)\n",
    "         self.dropout = nn.Dropout(dropout)\n",
    "         self.relu = nn.ReLU()\n",
    "\n",
    "     def forward(self, text, text_lengths=None): # text_lengths unused here but kept for consistency\n",
    "         # text shape: (batch_size, seq_len)\n",
    "         embedded = self.embedding(text)\n",
    "         # embedded shape: (batch_size, seq_len, embedding_dim)\n",
    "\n",
    "         # Average embeddings across sequence length dimension\n",
    "         # Need to handle padding: Mask out pad tokens before averaging\n",
    "         pad_mask = (text != self.embedding.padding_idx).float().unsqueeze(-1) # (batch_size, seq_len, 1)\n",
    "         embedded = embedded * pad_mask # Zero out embeddings for pad tokens\n",
    "         # Sum embeddings and divide by actual lengths (excluding pad tokens)\n",
    "         # Calculate actual lengths (sum of non-pad tokens)\n",
    "         actual_lengths = pad_mask.sum(dim=1)\n",
    "         actual_lengths = torch.max(actual_lengths, torch.ones_like(actual_lengths)) # Avoid division by zero for empty sequences\n",
    "\n",
    "         pooled = embedded.sum(dim=1) / actual_lengths # Shape: (batch_size, embedding_dim)\n",
    "\n",
    "         x = self.dropout(self.relu(self.fc1(pooled)))\n",
    "         x = self.dropout(self.relu(self.fc2(x)))\n",
    "         output = self.fc3(x) # Shape: (batch_size, output_dim)\n",
    "         return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53c8b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Basic RNN ---\n",
    "class RNNModel(BaseModel):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, dropout, pad_idx, bidirectional=False, pretrained_embeddings=None, freeze_embeddings=False):\n",
    "        super().__init__(vocab_size, embedding_dim, output_dim, pad_idx, pretrained_embeddings, freeze_embeddings)\n",
    "        self.rnn = nn.RNN(embedding_dim,\n",
    "                          hidden_dim,\n",
    "                          num_layers=n_layers,\n",
    "                          bidirectional=bidirectional,\n",
    "                          batch_first=True, # Input shape: (batch_size, seq_len, embed_dim)\n",
    "                          dropout=dropout if n_layers > 1 else 0) # Dropout only between layers\n",
    "        # Adjust linear layer input size for bidirectional\n",
    "        fc_in_dim = hidden_dim * 2 if bidirectional else hidden_dim\n",
    "        self.fc = nn.Linear(fc_in_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, text, text_lengths): # text_lengths useful for PackedSequence but not used here\n",
    "        # text shape: (batch_size, seq_len)\n",
    "        embedded = self.dropout(self.embedding(text))\n",
    "        # embedded shape: (batch_size, seq_len, embedding_dim)\n",
    "\n",
    "        # No packing used here for simplicity, RNN processes padded sequences\n",
    "        # Output shape: (batch_size, seq_len, num_directions * hidden_dim)\n",
    "        # Hidden shape: (n_layers * num_directions, batch_size, hidden_dim)\n",
    "        rnn_output, hidden = self.rnn(embedded)\n",
    "\n",
    "        # Get output from the last time step (or concatenate final forward/backward hidden states)\n",
    "        # hidden[-1] is the hidden state of the last layer (forward)\n",
    "        # hidden[-2] would be the last backward state if bidirectional\n",
    "        if self.rnn.bidirectional:\n",
    "            # Concatenate the final hidden states of the last layer from both directions\n",
    "            # hidden shape: (n_layers * 2, batch, hidden_dim)\n",
    "            # hidden[-2,:,:] is last layer's forward, hidden[-1,:,:] is last layer's backward\n",
    "            hidden_fwd = hidden[-2,:,:]\n",
    "            hidden_bwd = hidden[-1,:,:]\n",
    "            hidden_cat = torch.cat((hidden_fwd, hidden_bwd), dim=1)\n",
    "        else:\n",
    "            # hidden shape: (n_layers * 1, batch, hidden_dim)\n",
    "            hidden_cat = hidden[-1,:,:]\n",
    "\n",
    "        # Apply dropout and final linear layer\n",
    "        output = self.fc(self.dropout(hidden_cat)) # Shape: (batch_size, output_dim)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c697fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. LSTM Model ---\n",
    "class LSTMModel(BaseModel):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, dropout, pad_idx, bidirectional=True, pretrained_embeddings=None, freeze_embeddings=False):\n",
    "        super().__init__(vocab_size, embedding_dim, output_dim, pad_idx, pretrained_embeddings, freeze_embeddings)\n",
    "        self.lstm = nn.LSTM(embedding_dim,\n",
    "                            hidden_dim,\n",
    "                            num_layers=n_layers,\n",
    "                            bidirectional=bidirectional,\n",
    "                            batch_first=True,\n",
    "                            dropout=dropout if n_layers > 1 else 0)\n",
    "        fc_in_dim = hidden_dim * 2 if bidirectional else hidden_dim\n",
    "        self.fc = nn.Linear(fc_in_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, text, text_lengths): # text_lengths can be used with pack_padded_sequence\n",
    "        embedded = self.dropout(self.embedding(text))\n",
    "\n",
    "        # Optional: Use packed sequences for efficiency (handles padding)\n",
    "        # packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        # packed_output, (hidden, cell) = self.lstm(packed_embedded)\n",
    "        # output, _ = nn.utils.rnn.pad_packed_sequence(packed_output, batch_first=True)\n",
    "        # Using padded sequence directly (simpler for this example):\n",
    "        lstm_output, (hidden, cell) = self.lstm(embedded)\n",
    "\n",
    "        # hidden shape: (n_layers * num_directions, batch_size, hidden_dim)\n",
    "        # cell shape: (n_layers * num_directions, batch_size, hidden_dim)\n",
    "        if self.lstm.bidirectional:\n",
    "            hidden_fwd = hidden[-2,:,:]\n",
    "            hidden_bwd = hidden[-1,:,:]\n",
    "            hidden_cat = torch.cat((hidden_fwd, hidden_bwd), dim=1)\n",
    "        else:\n",
    "            hidden_cat = hidden[-1,:,:]\n",
    "\n",
    "        output = self.fc(self.dropout(hidden_cat))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05c2500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. CNN Model (1D Convolution) ---\n",
    "class CNNModel(BaseModel):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, dropout, pad_idx, pretrained_embeddings=None, freeze_embeddings=False):\n",
    "        super().__init__(vocab_size, embedding_dim, output_dim, pad_idx, pretrained_embeddings, freeze_embeddings)\n",
    "        # Create multiple convolutional layers with different kernel sizes\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv1d(in_channels=embedding_dim,\n",
    "                      out_channels=n_filters,\n",
    "                      kernel_size=fs)\n",
    "            for fs in filter_sizes\n",
    "        ])\n",
    "        # The output dimension after concatenating pooled features from all kernel sizes\n",
    "        fc_in_dim = len(filter_sizes) * n_filters\n",
    "        self.fc = nn.Linear(fc_in_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, text, text_lengths=None):\n",
    "        # text: [batch size, seq len]\n",
    "        embedded = self.dropout(self.embedding(text))\n",
    "        # embedded: [batch size, seq len, emb dim]\n",
    "\n",
    "        # Conv1d expects input shape: (batch_size, channels, seq_len)\n",
    "        # So, permute dimensions: (batch_size, emb dim, seq len)\n",
    "        embedded = embedded.permute(0, 2, 1)\n",
    "\n",
    "        # Apply convolutions and pooling\n",
    "        conved = [self.relu(conv(embedded)) for conv in self.convs]\n",
    "        # conved[n]: [batch size, n filters, seq len - filter_sizes[n] + 1]\n",
    "\n",
    "        # Apply max pooling over time (sequence length dimension)\n",
    "        # Pool size should cover the entire sequence length dimension after convolution\n",
    "        pooled = [torch.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "        # pooled[n]: [batch size, n filters]\n",
    "\n",
    "        # Concatenate the pooled features from different filter sizes\n",
    "        cat = self.dropout(torch.cat(pooled, dim=1))\n",
    "        # cat: [batch size, n filters * len(filter_sizes)]\n",
    "\n",
    "        return self.fc(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4f5a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. CNN-LSTM Hybrid Model ---\n",
    "class CNNLSTMModel(BaseModel):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_size_cnn, # Single filter size for simplicity here\n",
    "                 hidden_dim_lstm, output_dim, n_layers_lstm, dropout, pad_idx,\n",
    "                 pretrained_embeddings=None, freeze_embeddings=False):\n",
    "        super().__init__(vocab_size, embedding_dim, output_dim, pad_idx, pretrained_embeddings, freeze_embeddings)\n",
    "        self.conv = nn.Conv1d(in_channels=embedding_dim, out_channels=n_filters, kernel_size=filter_size_cnn)\n",
    "        self.relu = nn.ReLU()\n",
    "        # Input to LSTM is the output channels of CNN\n",
    "        self.lstm = nn.LSTM(n_filters, # Input features = CNN output channels\n",
    "                            hidden_dim_lstm,\n",
    "                            num_layers=n_layers_lstm,\n",
    "                            bidirectional=True, # Often good to use bidirectional\n",
    "                            batch_first=True,\n",
    "                            dropout=dropout if n_layers_lstm > 1 else 0)\n",
    "        fc_in_dim = hidden_dim_lstm * 2 # Bidirectional LSTM\n",
    "        self.fc = nn.Linear(fc_in_dim, output_dim)\n",
    "        self.dropout_embed = nn.Dropout(dropout)\n",
    "        self.dropout_final = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, text, text_lengths=None):\n",
    "        # text: [batch size, seq len]\n",
    "        embedded = self.dropout_embed(self.embedding(text))\n",
    "        # embedded: [batch size, seq len, emb dim]\n",
    "\n",
    "        # --- CNN Part ---\n",
    "        # Permute for Conv1d: [batch size, emb dim, seq len]\n",
    "        embedded_permuted = embedded.permute(0, 2, 1)\n",
    "        conved = self.relu(self.conv(embedded_permuted))\n",
    "        # conved: [batch size, n filters, new seq len]\n",
    "        # Permute back for LSTM: [batch size, new seq len, n filters]\n",
    "        conved_permuted = conved.permute(0, 2, 1)\n",
    "\n",
    "        # --- LSTM Part ---\n",
    "        lstm_output, (hidden, cell) = self.lstm(conved_permuted)\n",
    "        # lstm_output: [batch size, seq len, num directions * hidden dim]\n",
    "        # hidden: [n layers * num directions, batch size, hidden dim]\n",
    "\n",
    "        # Concatenate final forward and backward hidden states\n",
    "        hidden_fwd = hidden[-2,:,:]\n",
    "        hidden_bwd = hidden[-1,:,:]\n",
    "        hidden_cat = torch.cat((hidden_fwd, hidden_bwd), dim=1)\n",
    "\n",
    "        # --- Final Output ---\n",
    "        output = self.fc(self.dropout_final(hidden_cat))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012d3c29",
   "metadata": {},
   "source": [
    "# 4. Training and Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e9cece",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, iterator, optimizer, criterion, device, grad_clip=None):\n",
    "    \"\"\"Trains the model for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    for batch_idx, (text, labels, lengths) in enumerate(iterator):\n",
    "        text, labels = text.to(device), labels.to(device)\n",
    "        lengths = lengths.to('cpu') # lengths for pack_padded_sequence must be on CPU\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        predictions = model(text, lengths) # Pass lengths if model uses them\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = criterion(predictions, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "\n",
    "        # Gradient clipping\n",
    "        if grad_clip:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        # Optional: Print batch progress\n",
    "        if batch_idx % 100 == 0:\n",
    "            logging.debug(f\"Batch {batch_idx}/{len(iterator)}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    train_time_epoch = end_time - start_time\n",
    "    return epoch_loss / len(iterator), train_time_epoch\n",
    "\n",
    "\n",
    "def evaluate(model, iterator, criterion, device):\n",
    "    \"\"\"Evaluates the model on a given dataset iterator.\"\"\"\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (text, labels, lengths) in enumerate(iterator):\n",
    "            text, labels = text.to(device), labels.to(device)\n",
    "            lengths = lengths.to('cpu')\n",
    "\n",
    "            predictions = model(text, lengths)\n",
    "            loss = criterion(predictions, labels)\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            # Get predicted labels\n",
    "            preds = torch.argmax(predictions, dim=1)\n",
    "            all_preds.extend(preds.cpu().tolist())\n",
    "            all_labels.extend(labels.cpu().tolist())\n",
    "\n",
    "    end_time = time.time()\n",
    "    eval_time = end_time - start_time\n",
    "    metrics = calculate_metrics(all_labels, all_preds)\n",
    "    avg_loss = epoch_loss / len(iterator)\n",
    "\n",
    "    conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "    return avg_loss, metrics, eval_time, conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5381328",
   "metadata": {},
   "source": [
    "# 5. Run Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f18912",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba71c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Loop through each dataset defined in the configuration ---\n",
    "for dataset_name, config in DATASETS_TO_PROCESS.items():\n",
    "    print(f\"\\n{'='*20} Processing Dataset: {dataset_name} {'='*20}\")\n",
    "    logging.info(f\"Processing Dataset: {dataset_name}\")\n",
    "\n",
    "    # 1. Load Data\n",
    "    train_df = load_data(config['train_path'])\n",
    "    val_df = load_data(config['val_path'])\n",
    "    test_df = load_data(config['test_path'])\n",
    "\n",
    "    if train_df is None or val_df is None or test_df is None:\n",
    "        logging.error(f\"Skipping dataset {dataset_name} due to data loading errors.\")\n",
    "        continue\n",
    "\n",
    "    # 2. Build or Load Vocabulary\n",
    "    if os.path.exists(config['vocab_path']):\n",
    "        vocab = joblib.load(config['vocab_path'])\n",
    "        logging.info(f\"Loaded existing vocabulary from {config['vocab_path']}\")\n",
    "        # Check if special tokens exist, add if missing (backward compatibility)\n",
    "        if '<pad>' not in vocab: vocab['<pad>'] = 0\n",
    "        if '<unk>' not in vocab: vocab['<unk>'] = 1\n",
    "    else:\n",
    "        vocab = build_vocab(train_df[TEXT_COLUMN].tolist(), min_freq=MIN_WORD_FREQ)\n",
    "        joblib.dump(vocab, config['vocab_path'])\n",
    "        logging.info(f\"Built and saved vocabulary to {config['vocab_path']}\")\n",
    "\n",
    "    vocab_size = len(vocab)\n",
    "    pad_idx = vocab['<pad>']\n",
    "\n",
    "    # 3. Create Datasets and DataLoaders\n",
    "    train_dataset = SentimentDataset(train_df[TEXT_COLUMN].tolist(), train_df[TARGET_COLUMN].tolist(), vocab)\n",
    "    val_dataset = SentimentDataset(val_df[TEXT_COLUMN].tolist(), val_df[TARGET_COLUMN].tolist(), vocab)\n",
    "    test_dataset = SentimentDataset(test_df[TEXT_COLUMN].tolist(), test_df[TARGET_COLUMN].tolist(), vocab)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_batch)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_batch)\n",
    "\n",
    "    # 4. Load Pre-trained Embeddings (if needed)\n",
    "    glove_embeddings = None\n",
    "    if os.path.exists(GLOVE_PATH):\n",
    "        glove_embeddings = load_glove_embeddings(GLOVE_PATH, vocab, EMBEDDING_DIM)\n",
    "        if glove_embeddings is None:\n",
    "            logging.warning(\"Failed to load GloVe embeddings. Models requiring them will use learned embeddings.\")\n",
    "    else:\n",
    "        logging.warning(f\"GloVe path not found: {GLOVE_PATH}. Pre-trained embeddings disabled.\")\n",
    "\n",
    "\n",
    "    # --- Define Models to Run ---\n",
    "    models_to_run = {\n",
    "        # --- Mid Level ---\n",
    "        # Name: (ModelClass, {kwargs}, use_pretrained_embed, freeze_embed)\n",
    "        \"MLP (Avg Learned Emb)\": (MLPAveraged, {'hidden_dim1': 64, 'hidden_dim2': 32, 'dropout': DROPOUT, 'embedding_dim': LEARNED_EMBEDDING_DIM}, False, False),\n",
    "        \"RNN (Learned Emb)\": (RNNModel, {'hidden_dim': HIDDEN_DIM_RNN_LSTM, 'n_layers': N_LAYERS_RNN_LSTM, 'dropout': DROPOUT, 'bidirectional': False, 'embedding_dim': LEARNED_EMBEDDING_DIM}, False, False),\n",
    "        \"LSTM (Learned Emb)\": (LSTMModel, {'hidden_dim': HIDDEN_DIM_RNN_LSTM, 'n_layers': N_LAYERS_RNN_LSTM, 'dropout': DROPOUT, 'bidirectional': False, 'embedding_dim': LEARNED_EMBEDDING_DIM}, False, False),\n",
    "        \"BiLSTM (Learned Emb)\": (LSTMModel, {'hidden_dim': HIDDEN_DIM_RNN_LSTM, 'n_layers': N_LAYERS_RNN_LSTM, 'dropout': DROPOUT, 'bidirectional': True, 'embedding_dim': LEARNED_EMBEDDING_DIM}, False, False),\n",
    "        \"CNN (Learned Emb)\": (CNNModel, {'n_filters': N_FILTERS_CNN, 'filter_sizes': FILTER_SIZES_CNN, 'dropout': DROPOUT, 'embedding_dim': LEARNED_EMBEDDING_DIM}, False, False),\n",
    "\n",
    "        # --- Advanced Level (Using Pre-trained) ---\n",
    "        # Requires GloVe embeddings to be loaded successfully\n",
    "        \"MLP (Avg GloVe Emb)\": (MLPAveraged, {'hidden_dim1': 64, 'hidden_dim2': 32, 'dropout': DROPOUT, 'embedding_dim': EMBEDDING_DIM}, True, True), # Freeze GloVe\n",
    "        \"CNN (GloVe Emb)\": (CNNModel, {'n_filters': N_FILTERS_CNN, 'filter_sizes': FILTER_SIZES_CNN, 'dropout': DROPOUT, 'embedding_dim': EMBEDDING_DIM}, True, True), # Freeze GloVe\n",
    "        \"LSTM (GloVe Emb)\": (LSTMModel, {'hidden_dim': HIDDEN_DIM_RNN_LSTM, 'n_layers': N_LAYERS_RNN_LSTM, 'dropout': DROPOUT, 'bidirectional': False, 'embedding_dim': EMBEDDING_DIM}, True, True), # Freeze GloVe\n",
    "        \"BiLSTM (GloVe Emb)\": (LSTMModel, {'hidden_dim': HIDDEN_DIM_RNN_LSTM, 'n_layers': N_LAYERS_RNN_LSTM, 'dropout': DROPOUT, 'bidirectional': True, 'embedding_dim': EMBEDDING_DIM}, True, True), # Freeze GloVe\n",
    "        \"CNN-LSTM (GloVe Emb)\": (CNNLSTMModel, {'n_filters': N_FILTERS_CNN, 'filter_size_cnn': 3, 'hidden_dim_lstm': HIDDEN_DIM_RNN_LSTM, 'n_layers_lstm': N_LAYERS_RNN_LSTM, 'dropout': DROPOUT, 'embedding_dim': EMBEDDING_DIM}, True, True), # Freeze GloVe\n",
    "    }\n",
    "\n",
    "    # --- Loop through each model configuration ---\n",
    "    for model_name, (ModelClass, model_kwargs, use_pretrained, freeze_embed) in models_to_run.items():\n",
    "\n",
    "        # Skip models requiring GloVe if loading failed\n",
    "        if use_pretrained and glove_embeddings is None:\n",
    "            logging.warning(f\"Skipping model '{model_name}' as pre-trained GloVe embeddings were not loaded.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\n--- Training Model: {model_name} ---\")\n",
    "        logging.info(f\"Starting training for {model_name} on {dataset_name}\")\n",
    "        results = {\"Dataset\": dataset_name, \"Model\": model_name}\n",
    "\n",
    "        try:\n",
    "            # Instantiate model\n",
    "            current_embedding_dim = model_kwargs['embedding_dim'] # Get dim from kwargs\n",
    "            current_pretrained_embeddings = glove_embeddings if use_pretrained else None\n",
    "\n",
    "            model = ModelClass(\n",
    "                vocab_size=vocab_size,\n",
    "                output_dim=NUM_CLASSES,\n",
    "                pad_idx=pad_idx,\n",
    "                pretrained_embeddings=current_pretrained_embeddings,\n",
    "                freeze_embeddings=freeze_embed,\n",
    "                **model_kwargs # Pass specific model architecture args\n",
    "            ).to(DEVICE)\n",
    "\n",
    "            # Count parameters\n",
    "            num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "            logging.info(f\"Model: {model_name}, Trainable Parameters: {num_params:,}\")\n",
    "\n",
    "            # Define optimizer and criterion\n",
    "            optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "            criterion = nn.CrossEntropyLoss().to(DEVICE) # Handles softmax internally\n",
    "\n",
    "            best_val_loss = float('inf')\n",
    "            total_train_time = 0\n",
    "            model_save_path = os.path.join(config['model_dir'], f\"{dataset_name.replace(' ', '_')}_{model_name.replace(' ', '_')}_best.pt\")\n",
    "\n",
    "            # Training loop\n",
    "            for epoch in range(NUM_EPOCHS):\n",
    "                start_epoch_time = time.time()\n",
    "\n",
    "                train_loss, train_time_epoch = train_epoch(model, train_loader, optimizer, criterion, DEVICE, GRADIENT_CLIP)\n",
    "                val_loss, val_metrics, _ = evaluate(model, val_loader, criterion, DEVICE)\n",
    "\n",
    "                total_train_time += train_time_epoch\n",
    "                end_epoch_time = time.time()\n",
    "                epoch_mins, epoch_secs = divmod(end_epoch_time - start_epoch_time, 60)\n",
    "\n",
    "                logging.info(f'Epoch: {epoch+1:02} | Time: {int(epoch_mins)}m {epoch_secs:.0f}s')\n",
    "                logging.info(f'\\tTrain Loss: {train_loss:.3f}')\n",
    "                logging.info(f'\\t Val. Loss: {val_loss:.3f} | Val. F1 (Macro): {val_metrics[\"F1 (Macro)\"]:.4f}')\n",
    "\n",
    "                # Save best model based on validation loss\n",
    "                if val_loss < best_val_loss:\n",
    "                    best_val_loss = val_loss\n",
    "                    torch.save(model.state_dict(), model_save_path)\n",
    "                    logging.info(f\"Saved best model to {model_save_path} (Epoch {epoch+1})\")\n",
    "\n",
    "            results[\"Train Time (Epoch, s)\"] = round(total_train_time / NUM_EPOCHS, 3) # Avg time per epoch\n",
    "\n",
    "            # Load best model and evaluate on Test set\n",
    "            model.load_state_dict(torch.load(model_save_path))\n",
    "            logging.info(f\"Loaded best model from {model_save_path} for final test evaluation.\")\n",
    "\n",
    "            test_loss, test_metrics, test_eval_time, test_conf_matrix = evaluate(model, test_loader, criterion, DEVICE)\n",
    "            results.update(test_metrics)\n",
    "            results[\"Eval Time (s)\"] = round(test_eval_time, 3)\n",
    "\n",
    "            logging.info(\"Test Set Performance:\")\n",
    "            for key, value in test_metrics.items():\n",
    "                logging.info(f\"\\t{key}: {value:.4f}\")\n",
    "            logging.info(f\"\\tTest Loss: {test_loss:.3f}\")\n",
    "            logging.info(f\"\\tEval Time: {test_eval_time:.3f}s\")\n",
    "\n",
    "            # --- Save Confusion Matrix CSV ---\n",
    "            cm_filename = f\"{dataset_name.replace(' ', '_')}_{model_name.replace(' ', '_')}_confusion_matrix.csv\" # Change extension to .csv\n",
    "            cm_save_path = os.path.join(config['result_dir'], cm_filename)\n",
    "            try:\n",
    "                # Convert numpy array to DataFrame for better CSV formatting with labels\n",
    "                cm_df = pd.DataFrame(test_conf_matrix, \n",
    "                                    index=LABEL_MAP.keys(), # Rows are True Labels\n",
    "                                    columns=LABEL_MAP.keys()) # Columns are Predicted Labels\n",
    "                cm_df.index.name = 'True Label'\n",
    "                cm_df.columns.name = 'Predicted Label'\n",
    "                \n",
    "                # Save to CSV\n",
    "                cm_df.to_csv(cm_save_path, index=True, mode='w+') # index=True to include row/column names\n",
    "                \n",
    "                logging.info(f\"Saved confusion matrix CSV to {cm_save_path}\")\n",
    "            except Exception as cm_save_e:\n",
    "                logging.error(f\"Failed to save confusion matrix CSV for {model_name}: {cm_save_e}\")\n",
    "        # --- End Save Confusion Matrix CSV ---\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"!!! An error occurred while processing {model_name} for {dataset_name}: {e}\", exc_info=True) # Log traceback\n",
    "            # Record partial results if possible\n",
    "            results[\"Accuracy\"] = np.nan\n",
    "            results[\"F1 (Macro)\"] = np.nan\n",
    "            # Fill other metrics with NaN or error messages\n",
    "            for metric in METRICS_TO_CALCULATE:\n",
    "                if metric not in results:\n",
    "                    results[metric] = np.nan if metric not in [\"Train Time (Epoch, s)\", \"Eval Time (s)\"] else 0.0\n",
    "        finally:\n",
    "            all_results.append(results)\n",
    "            # Clean up memory\n",
    "            del model\n",
    "            if 'optimizer' in locals(): del optimizer\n",
    "            if 'criterion' in locals(): del criterion   \n",
    "            gc.collect()\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "# --- Combine results into a DataFrame ---\n",
    "results_df = pd.DataFrame(all_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a46116d",
   "metadata": {},
   "source": [
    "# 6. Results Summary and Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7518b206",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\n===== Overall Deep Learning Results Summary =====\")\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1200)\n",
    "pd.set_option('display.max_colwidth', 80) # Adjust if needed\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)\n",
    "\n",
    "# Ensure all expected columns exist, fill with NaN if necessary\n",
    "for col in METRICS_TO_CALCULATE:\n",
    "    if col not in results_df.columns:\n",
    "        results_df[col] = np.nan\n",
    "\n",
    "# Reorder columns for clarity\n",
    "column_order = [\"Dataset\", \"Model\"] + METRICS_TO_CALCULATE\n",
    "# Filter out columns not present if something went wrong during creation\n",
    "column_order = [col for col in column_order if col in results_df.columns]\n",
    "results_df = results_df[column_order]\n",
    "\n",
    "\n",
    "print(results_df)\n",
    "\n",
    "# --- Save results to CSV for each dataset ---\n",
    "for dataset_name, config in DATASETS_TO_PROCESS.items():\n",
    "    dataset_results_df = results_df[results_df['Dataset'] == dataset_name]\n",
    "    if not dataset_results_df.empty:\n",
    "        results_filename = f\"{dataset_name.replace(' ', '_')}_dl_pytorch_results.csv\"\n",
    "        results_save_path = os.path.join(config['result_dir'], results_filename)\n",
    "        try:\n",
    "            dataset_results_df.to_csv(results_save_path, index=False, mode='w+')\n",
    "            print(f\"\\nResults for {dataset_name} saved to {results_save_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError saving results for {dataset_name} to {results_save_path}: {e}\")\n",
    "\n",
    "# --- Save combined results ---\n",
    "combined_results_path = os.path.join(RESULT_DIR, \"combined_dl_pytorch_results.csv\")\n",
    "try:\n",
    "    results_df.to_csv(combined_results_path, index=False, mode='w+')\n",
    "    print(f\"\\nCombined results saved to {combined_results_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nError saving combined results to {combined_results_path}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
