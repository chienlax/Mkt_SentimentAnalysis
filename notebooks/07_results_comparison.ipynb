{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a26a2788",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c31809b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_RESULT_DIR = os.path.join(\"..\", \"result\")\n",
    "\n",
    "# --- Input Subdirectories ---\n",
    "BOOK_REVIEW_RESULT_DIR = os.path.join(BASE_RESULT_DIR, \"book_reviews\")\n",
    "FINANCIAL_NEWS_RESULT_DIR = os.path.join(BASE_RESULT_DIR, \"financial_news\")\n",
    "\n",
    "# --- Input Filenames (Update if yours are different) ---\n",
    "ML_RESULTS_FN_BR = \"Book_Review_ml_tfidf_tuned_results.csv\"\n",
    "DL_RESULTS_FN_BR = \"Book_Review_dl_pytorch_results.csv\"\n",
    "LLM_RESULTS_FN_BR = \"Book_Review_llm_transformers_results.csv\"\n",
    "\n",
    "ML_RESULTS_FN_FN = \"Financial_News_ml_tfidf_tuned_results.csv\"\n",
    "DL_RESULTS_FN_FN = \"Financial_News_dl_pytorch_results.csv\"\n",
    "LLM_RESULTS_FN_FN = \"Financial_News_llm_transformers_results.csv\"\n",
    "\n",
    "# --- Output Filenames ---\n",
    "OUTPUT_COMPARISON_BR = os.path.join(BASE_RESULT_DIR, \"comparison_book_reviews.csv\")\n",
    "OUTPUT_COMPARISON_FN = os.path.join(BASE_RESULT_DIR, \"comparison_financial_news.csv\")\n",
    "OUTPUT_COMPARISON_ALL = os.path.join(BASE_RESULT_DIR, \"comparison_all_datasets.csv\")\n",
    "\n",
    "# --- Columns to keep (adjust if needed, should match generated files) ---\n",
    "# Example, assuming these were generated consistently\n",
    "EXPECTED_COLUMNS = [\n",
    "    \"Dataset\", \"Model\",\n",
    "    \"Accuracy\",\n",
    "    \"F1 (Macro)\", \"Precision (Macro)\", \"Recall (Macro)\",\n",
    "    \"F1 (Weighted)\", \"Precision (Weighted)\", \"Recall (Weighted)\",\n",
    "    \"Train Time (s)\", \"Eval Time (s)\", # Note: DL used Train Time (Epoch, s)\n",
    "    # Optional columns generated by specific scripts:\n",
    "    # \"Best Params\", # From ML script\n",
    "    # \"Train Time (Epoch, s)\" # From DL script\n",
    "]\n",
    "SORT_BY_COLUMN = \"F1 (Macro)\" # Column to sort results by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dfa155b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Helper Function to Load Results ---\n",
    "def load_results(file_path):\n",
    "    \"\"\"Loads a CSV result file into a Pandas DataFrame.\"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        logging.warning(f\"Result file not found, skipping: {file_path}\")\n",
    "        return None\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        logging.info(f\"Successfully loaded: {file_path} ({len(df)} rows)\")\n",
    "        # Handle potential variations in training time column name\n",
    "        if \"Train Time (Epoch, s)\" in df.columns and \"Train Time (s)\" not in df.columns:\n",
    "             df.rename(columns={\"Train Time (Epoch, s)\": \"Train Time (s)\"}, inplace=True)\n",
    "             logging.debug(f\"Renamed 'Train Time (Epoch, s)' to 'Train Time (s)' in {os.path.basename(file_path)}\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error loading {file_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bf45b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-10 12:22:54,877 - INFO - Starting result aggregation script...\n",
      "2025-05-10 12:22:54,880 - INFO - Successfully loaded: ..\\result\\book_reviews\\Book_Review_ml_tfidf_tuned_results.csv (5 rows)\n",
      "2025-05-10 12:22:54,882 - INFO - Successfully loaded: ..\\result\\book_reviews\\Book_Review_dl_pytorch_results.csv (10 rows)\n",
      "2025-05-10 12:22:54,885 - INFO - Successfully loaded: ..\\result\\book_reviews\\Book_Review_llm_transformers_results.csv (7 rows)\n",
      "2025-05-10 12:22:54,895 - INFO - Successfully loaded: ..\\result\\financial_news\\Financial_News_ml_tfidf_tuned_results.csv (5 rows)\n",
      "2025-05-10 12:22:54,902 - INFO - Successfully loaded: ..\\result\\financial_news\\Financial_News_dl_pytorch_results.csv (10 rows)\n",
      "2025-05-10 12:22:54,904 - INFO - Successfully loaded: ..\\result\\financial_news\\Financial_News_llm_transformers_results.csv (2 rows)\n",
      "2025-05-10 12:22:54,905 - INFO - Combining 3 result files for Book Reviews...\n",
      "2025-05-10 12:22:54,911 - INFO - Book Review comparison saved to: ..\\result\\comparison_book_reviews.csv\n",
      "2025-05-10 12:22:54,913 - INFO - Combining 3 result files for Financial News...\n",
      "2025-05-10 12:22:54,917 - INFO - Financial News comparison saved to: ..\\result\\comparison_financial_news.csv\n",
      "2025-05-10 12:22:54,918 - INFO - Combining all 6 loaded result files...\n",
      "2025-05-10 12:22:54,921 - INFO - Overall comparison saved to: ..\\result\\comparison_all_datasets.csv\n",
      "2025-05-10 12:22:54,922 - INFO - Result aggregation finished.\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"Starting result aggregation script...\")\n",
    "\n",
    "# --- Load Book Review Results ---\n",
    "br_ml_df = load_results(os.path.join(BOOK_REVIEW_RESULT_DIR, ML_RESULTS_FN_BR))\n",
    "br_dl_df = load_results(os.path.join(BOOK_REVIEW_RESULT_DIR, DL_RESULTS_FN_BR))\n",
    "br_llm_df = load_results(os.path.join(BOOK_REVIEW_RESULT_DIR, LLM_RESULTS_FN_BR))\n",
    "\n",
    "# --- Load Financial News Results ---\n",
    "fn_ml_df = load_results(os.path.join(FINANCIAL_NEWS_RESULT_DIR, ML_RESULTS_FN_FN))\n",
    "fn_dl_df = load_results(os.path.join(FINANCIAL_NEWS_RESULT_DIR, DL_RESULTS_FN_FN))\n",
    "fn_llm_df = load_results(os.path.join(FINANCIAL_NEWS_RESULT_DIR, LLM_RESULTS_FN_FN))\n",
    "\n",
    "# List of loaded dataframes for easier handling\n",
    "all_dfs = [df for df in [br_ml_df, br_dl_df, br_llm_df, fn_ml_df, fn_dl_df, fn_llm_df] if df is not None]\n",
    "\n",
    "if not all_dfs:\n",
    "    logging.error(\"No result files were loaded successfully. Exiting.\")\n",
    "    exit()\n",
    "\n",
    "# --- Combine and Save Book Review Comparison ---\n",
    "book_review_dfs = [df for df in [br_ml_df, br_dl_df, br_llm_df] if df is not None]\n",
    "if book_review_dfs:\n",
    "    logging.info(f\"Combining {len(book_review_dfs)} result files for Book Reviews...\")\n",
    "    combined_br_df = pd.concat(book_review_dfs, ignore_index=True)\n",
    "\n",
    "    # Select and reorder columns gracefully\n",
    "    cols_to_use = [col for col in EXPECTED_COLUMNS if col in combined_br_df.columns]\n",
    "    combined_br_df = combined_br_df[cols_to_use]\n",
    "\n",
    "    # Sort results\n",
    "    if SORT_BY_COLUMN in combined_br_df.columns:\n",
    "        combined_br_df = combined_br_df.sort_values(by=SORT_BY_COLUMN, ascending=False)\n",
    "\n",
    "    try:\n",
    "        combined_br_df.to_csv(OUTPUT_COMPARISON_BR, index=False)\n",
    "        logging.info(f\"Book Review comparison saved to: {OUTPUT_COMPARISON_BR}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to save Book Review comparison: {e}\")\n",
    "else:\n",
    "    logging.warning(\"No Book Review result files found to combine.\")\n",
    "\n",
    "\n",
    "# --- Combine and Save Financial News Comparison ---\n",
    "financial_news_dfs = [df for df in [fn_ml_df, fn_dl_df, fn_llm_df] if df is not None]\n",
    "if financial_news_dfs:\n",
    "    logging.info(f\"Combining {len(financial_news_dfs)} result files for Financial News...\")\n",
    "    combined_fn_df = pd.concat(financial_news_dfs, ignore_index=True)\n",
    "\n",
    "    # Select and reorder columns gracefully\n",
    "    cols_to_use = [col for col in EXPECTED_COLUMNS if col in combined_fn_df.columns]\n",
    "    combined_fn_df = combined_fn_df[cols_to_use]\n",
    "\n",
    "    # Sort results\n",
    "    if SORT_BY_COLUMN in combined_fn_df.columns:\n",
    "        combined_fn_df = combined_fn_df.sort_values(by=SORT_BY_COLUMN, ascending=False)\n",
    "\n",
    "    try:\n",
    "        combined_fn_df.to_csv(OUTPUT_COMPARISON_FN, index=False)\n",
    "        logging.info(f\"Financial News comparison saved to: {OUTPUT_COMPARISON_FN}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to save Financial News comparison: {e}\")\n",
    "else:\n",
    "    logging.warning(\"No Financial News result files found to combine.\")\n",
    "\n",
    "\n",
    "# --- Combine and Save Overall Comparison ---\n",
    "logging.info(f\"Combining all {len(all_dfs)} loaded result files...\")\n",
    "combined_all_df = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "# Select and reorder columns gracefully\n",
    "cols_to_use = [col for col in EXPECTED_COLUMNS if col in combined_all_df.columns]\n",
    "# Add back any extra columns that might exist (like Best Params) but weren't in EXPECTED_COLUMNS\n",
    "extra_cols = [col for col in combined_all_df.columns if col not in cols_to_use]\n",
    "final_cols_order = cols_to_use + extra_cols\n",
    "combined_all_df = combined_all_df[final_cols_order]\n",
    "\n",
    "\n",
    "# Sort results (e.g., by Dataset, then by the chosen metric)\n",
    "if SORT_BY_COLUMN in combined_all_df.columns and \"Dataset\" in combined_all_df.columns:\n",
    "    combined_all_df = combined_all_df.sort_values(by=[\"Dataset\", SORT_BY_COLUMN], ascending=[True, False])\n",
    "elif \"Dataset\" in combined_all_df.columns:\n",
    "    combined_all_df = combined_all_df.sort_values(by=[\"Dataset\"])\n",
    "\n",
    "\n",
    "try:\n",
    "    combined_all_df.to_csv(OUTPUT_COMPARISON_ALL, index=False)\n",
    "    logging.info(f\"Overall comparison saved to: {OUTPUT_COMPARISON_ALL}\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Failed to save overall comparison: {e}\")\n",
    "\n",
    "logging.info(\"Result aggregation finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ebf9334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting confusion matrix aggregation...\n",
      "  Reading: Book_Review_BERT_Feature_Extractor__LR_confusion_matrix.csv (Domain: Book Reviews, Model: BERT_Feature_Extractor__LR)\n",
      "  Reading: Book_Review_BERT_Full_FT_confusion_matrix.csv (Domain: Book Reviews, Model: BERT_Full_FT)\n",
      "  Reading: Book_Review_BERT_LoRA_FT_confusion_matrix.csv (Domain: Book Reviews, Model: BERT_LoRA_FT)\n",
      "  Reading: Book_Review_BiLSTM_(GloVe_Emb)_confusion_matrix.csv (Domain: Book Reviews, Model: BiLSTM (GloVe_Emb))\n",
      "  Reading: Book_Review_BiLSTM_(Learned_Emb)_confusion_matrix.csv (Domain: Book Reviews, Model: BiLSTM (Learned_Emb))\n",
      "  Reading: Book_Review_CNN-LSTM_(GloVe_Emb)_confusion_matrix.csv (Domain: Book Reviews, Model: CNN-LSTM (GloVe_Emb))\n",
      "  Reading: Book_Review_CNN_(GloVe_Emb)_confusion_matrix.csv (Domain: Book Reviews, Model: CNN (GloVe_Emb))\n",
      "  Reading: Book_Review_CNN_(Learned_Emb)_confusion_matrix.csv (Domain: Book Reviews, Model: CNN (Learned_Emb))\n",
      "  Reading: Book_Review_DistilBERT_Feature_Extractor__LR_confusion_matrix.csv (Domain: Book Reviews, Model: DistilBERT_Feature_Extractor__LR)\n",
      "  Reading: Book_Review_DistilBERT_Full_FT_confusion_matrix.csv (Domain: Book Reviews, Model: DistilBERT_Full_FT)\n",
      "  Reading: Book_Review_LightGBM_confusion_matrix.csv (Domain: Book Reviews, Model: LightGBM)\n",
      "  Reading: Book_Review_Linear_SVM_confusion_matrix.csv (Domain: Book Reviews, Model: Linear_SVM)\n",
      "  Reading: Book_Review_Logistic_Regression_confusion_matrix.csv (Domain: Book Reviews, Model: Logistic_Regression)\n",
      "  Reading: Book_Review_LSTM_(GloVe_Emb)_confusion_matrix.csv (Domain: Book Reviews, Model: LSTM (GloVe_Emb))\n",
      "  Reading: Book_Review_LSTM_(Learned_Emb)_confusion_matrix.csv (Domain: Book Reviews, Model: LSTM (Learned_Emb))\n",
      "  Reading: Book_Review_MLP_(Avg_GloVe_Emb)_confusion_matrix.csv (Domain: Book Reviews, Model: MLP (Avg_GloVe_Emb))\n",
      "  Reading: Book_Review_MLP_(Avg_Learned_Emb)_confusion_matrix.csv (Domain: Book Reviews, Model: MLP (Avg_Learned_Emb))\n",
      "  Reading: Book_Review_Naive_Bayes_confusion_matrix.csv (Domain: Book Reviews, Model: Naive_Bayes)\n",
      "  Reading: Book_Review_Random_Forest_confusion_matrix.csv (Domain: Book Reviews, Model: Random_Forest)\n",
      "  Reading: Book_Review_RNN_(Learned_Emb)_confusion_matrix.csv (Domain: Book Reviews, Model: RNN (Learned_Emb))\n",
      "  Reading: Book_Review_RoBERTa_Full_FT_confusion_matrix.csv (Domain: Book Reviews, Model: RoBERTa_Full_FT)\n",
      "  Reading: Book_Review_RoBERTa_LoRA_FT_confusion_matrix.csv (Domain: Book Reviews, Model: RoBERTa_LoRA_FT)\n",
      "  Reading: Financial_News_BERT_Feature_Extractor__LR_confusion_matrix.csv (Domain: Financial News, Model: BERT_Feature_Extractor__LR)\n",
      "  Reading: Financial_News_BERT_Full_FT_confusion_matrix.csv (Domain: Financial News, Model: BERT_Full_FT)\n",
      "  Reading: Financial_News_BERT_LoRA_FT_confusion_matrix.csv (Domain: Financial News, Model: BERT_LoRA_FT)\n",
      "  Reading: Financial_News_BiLSTM_(GloVe_Emb)_confusion_matrix.csv (Domain: Financial News, Model: BiLSTM (GloVe_Emb))\n",
      "  Reading: Financial_News_BiLSTM_(Learned_Emb)_confusion_matrix.csv (Domain: Financial News, Model: BiLSTM (Learned_Emb))\n",
      "  Reading: Financial_News_CNN-LSTM_(GloVe_Emb)_confusion_matrix.csv (Domain: Financial News, Model: CNN-LSTM (GloVe_Emb))\n",
      "  Reading: Financial_News_CNN_(GloVe_Emb)_confusion_matrix.csv (Domain: Financial News, Model: CNN (GloVe_Emb))\n",
      "  Reading: Financial_News_CNN_(Learned_Emb)_confusion_matrix.csv (Domain: Financial News, Model: CNN (Learned_Emb))\n",
      "  Reading: Financial_News_DistilBERT_Feature_Extractor__LR_confusion_matrix.csv (Domain: Financial News, Model: DistilBERT_Feature_Extractor__LR)\n",
      "  Reading: Financial_News_DistilBERT_Full_FT_confusion_matrix.csv (Domain: Financial News, Model: DistilBERT_Full_FT)\n",
      "  Reading: Financial_News_FinBERT_Full_FT_confusion_matrix.csv (Domain: Financial News, Model: FinBERT_Full_FT)\n",
      "  Reading: Financial_News_LightGBM_confusion_matrix.csv (Domain: Financial News, Model: LightGBM)\n",
      "  Reading: Financial_News_Linear_SVM_confusion_matrix.csv (Domain: Financial News, Model: Linear_SVM)\n",
      "  Reading: Financial_News_Logistic_Regression_confusion_matrix.csv (Domain: Financial News, Model: Logistic_Regression)\n",
      "  Reading: Financial_News_LSTM_(GloVe_Emb)_confusion_matrix.csv (Domain: Financial News, Model: LSTM (GloVe_Emb))\n",
      "  Reading: Financial_News_LSTM_(Learned_Emb)_confusion_matrix.csv (Domain: Financial News, Model: LSTM (Learned_Emb))\n",
      "  Reading: Financial_News_MLP_(Avg_GloVe_Emb)_confusion_matrix.csv (Domain: Financial News, Model: MLP (Avg_GloVe_Emb))\n",
      "  Reading: Financial_News_MLP_(Avg_Learned_Emb)_confusion_matrix.csv (Domain: Financial News, Model: MLP (Avg_Learned_Emb))\n",
      "  Reading: Financial_News_Naive_Bayes_confusion_matrix.csv (Domain: Financial News, Model: Naive_Bayes)\n",
      "  Reading: Financial_News_Random_Forest_confusion_matrix.csv (Domain: Financial News, Model: Random_Forest)\n",
      "  Reading: Financial_News_RNN_(Learned_Emb)_confusion_matrix.csv (Domain: Financial News, Model: RNN (Learned_Emb))\n",
      "  Reading: Financial_News_RoBERTa_Full_FT_confusion_matrix.csv (Domain: Financial News, Model: RoBERTa_Full_FT)\n",
      "  Reading: Financial_News_RoBERTa_LoRA_FT_confusion_matrix.csv (Domain: Financial News, Model: RoBERTa_LoRA_FT)\n",
      "\n",
      "Successfully aggregated approximately 45 confusion matrices.\n",
      "Total rows in aggregated file: 405\n",
      "\n",
      "Sample of aggregated data:\n",
      "             Domain    Model_Configuration Actual_Label Predicted_Label  Count\n",
      "149    Book Reviews  MLP (Avg_Learned_Emb)      neutral        positive   2797\n",
      "129    Book Reviews     LSTM (Learned_Emb)      neutral        negative    928\n",
      "46     Book Reviews   CNN-LSTM (GloVe_Emb)     negative         neutral    596\n",
      "394  Financial News        RoBERTa_Full_FT     positive         neutral     30\n",
      "167    Book Reviews          Random_Forest      neutral        positive   1597\n",
      "324  Financial News       LSTM (GloVe_Emb)     negative        negative      0\n",
      "373  Financial News          Random_Forest      neutral         neutral    381\n",
      "223  Financial News           BERT_LoRA_FT     positive         neutral     32\n",
      "126    Book Reviews     LSTM (Learned_Emb)     negative        negative   3278\n",
      "104    Book Reviews             Linear_SVM      neutral        positive   1466\n",
      "\n",
      "Aggregated confusion matrices saved to: ../result\\comparison\\all_confusion_matrices_aggregated.csv\n",
      "\n",
      "Aggregation script finished.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Aggregate Confusion Matrices from Multiple Experiments (Revised for Specific CSV Format)\n",
    "\n",
    "This script reads individual confusion matrix CSV files where the first row contains\n",
    "predicted labels and the first column (after header) contains actual labels.\n",
    "It parses domain and model info from filenames, standardizes their format,\n",
    "and combines them into a single comprehensive CSV.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "# Ignore warnings for cleaner output (optional)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# %% [markdown]\n",
    "# # 1. Configuration\n",
    "\n",
    "# %%\n",
    "# --- Paths ---\n",
    "BASE_RESULTS_DIR = \"../result\"\n",
    "OUTPUT_DIR = os.path.join(BASE_RESULTS_DIR, \"comparison\")\n",
    "AGGREGATED_CM_FILE = os.path.join(OUTPUT_DIR, \"all_confusion_matrices_aggregated.csv\") # New output\n",
    "\n",
    "# --- Domain Mapping ---\n",
    "DOMAIN_PREFIX_MAP = {\n",
    "    \"book_review\": \"Book Reviews\",\n",
    "    \"book_reviews\": \"Book Reviews\",\n",
    "    \"financial_news\": \"Financial News\",\n",
    "    # Add more if you have other domain prefixes\n",
    "}\n",
    "\n",
    "# --- Expected Labels (Order is important for mapping if CSV uses numeric indices) ---\n",
    "# This also defines the order of labels in the output, assuming a 3x3 matrix\n",
    "EXPECTED_LABELS_IN_ORDER = ['negative', 'neutral', 'positive']\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# %% [markdown]\n",
    "# # 2. Helper Function to Parse Filename for Domain and Model\n",
    "\n",
    "# %%\n",
    "def parse_filename_for_domain_and_model(filename):\n",
    "    \"\"\"\n",
    "    Extracts the domain and model configuration name from the confusion matrix filename.\n",
    "    Example filename: \"Book_Review_BERT_Full_FT_confusion_matrix.csv\"\n",
    "    Returns: (domain_name, model_config_name) or (None, None) if not parsable.\n",
    "    \"\"\"\n",
    "    original_filename = filename\n",
    "    filename_lower = filename.lower()\n",
    "    extracted_domain = None\n",
    "    remaining_filename_part = filename # Initialize with full filename\n",
    "\n",
    "    longest_match_len = 0\n",
    "    for prefix_key, domain_name_val in DOMAIN_PREFIX_MAP.items():\n",
    "        # Ensure the prefix_key from the map is also lowercased for comparison\n",
    "        current_prefix_in_filename = prefix_key.lower() + \"_\"\n",
    "        if filename_lower.startswith(current_prefix_in_filename):\n",
    "            if len(prefix_key) > longest_match_len:\n",
    "                extracted_domain = domain_name_val\n",
    "                remaining_filename_part = filename[len(prefix_key) + 1:]\n",
    "                longest_match_len = len(prefix_key)\n",
    "\n",
    "    if not extracted_domain:\n",
    "        # Fallback: Try to infer domain if not in subfolder and not caught by prefix map\n",
    "        # This part might need adjustment if your structure is strict\n",
    "        print(f\"    Warning: Could not determine domain from prefix for {original_filename}. Trying to infer.\")\n",
    "        # A simple heuristic could be to take the first part of the filename before an underscore\n",
    "        # but this is less robust. DOMAIN_PREFIX_MAP is preferred.\n",
    "        # For now, we'll stick to prefix map logic.\n",
    "        return None, None\n",
    "\n",
    "\n",
    "    suffix_to_remove = \"_confusion_matrix.csv\"\n",
    "    if remaining_filename_part.lower().endswith(suffix_to_remove):\n",
    "        model_config_name = remaining_filename_part[:-len(suffix_to_remove)]\n",
    "    else:\n",
    "        if \"dl_pytorch_results\" in original_filename.lower() or \\\n",
    "           \"ml_tfidf_tuned_results\" in original_filename.lower() or \\\n",
    "           \"llm_transformers_results\" in original_filename.lower():\n",
    "            return None, None # Not a specific model's CM\n",
    "        model_config_name = remaining_filename_part.replace(\".csv\", \"\")\n",
    "\n",
    "    model_config_name = model_config_name.replace(\"_(\" , \" (\").replace(\")_\", \") \")\n",
    "    model_config_name = model_config_name.replace(\"_+\", \" + \")\n",
    "    return extracted_domain, model_config_name.strip()\n",
    "\n",
    "# %% [markdown]\n",
    "# # 3. Main Aggregation Loop\n",
    "\n",
    "# %%\n",
    "all_matrices_data = []\n",
    "\n",
    "print(\"Starting confusion matrix aggregation...\")\n",
    "\n",
    "for root_dir, _, files in os.walk(BASE_RESULTS_DIR):\n",
    "    if os.path.basename(root_dir).lower() == \"comparison\":\n",
    "        continue\n",
    "\n",
    "    for filename in files:\n",
    "        if filename.endswith(\".csv\") and \"confusion_matrix\" in filename.lower():\n",
    "            file_path = os.path.join(root_dir, filename)\n",
    "            domain_name, model_config_name = parse_filename_for_domain_and_model(filename)\n",
    "\n",
    "            if domain_name is None or model_config_name is None:\n",
    "                # print(f\"  Skipping (unparsable/summary file): {filename}\")\n",
    "                continue\n",
    "\n",
    "            print(f\"  Reading: {filename} (Domain: {domain_name}, Model: {model_config_name})\")\n",
    "\n",
    "            try:\n",
    "                # Read the CSV. The first row is header (Predicted Labels).\n",
    "                # The first column of data (after header) is Actual Labels.\n",
    "                cm_df_raw = pd.read_csv(file_path)\n",
    "\n",
    "                # Check if the first column name is 'True Label' or similar (as in your example)\n",
    "                # or if it's unnamed (often the case if index was written)\n",
    "                if cm_df_raw.columns[0].lower() in ['true label', 'actual', 'unnamed: 0']:\n",
    "                    actual_labels_from_file = cm_df_raw.iloc[:, 0].astype(str).tolist()\n",
    "                    # Predicted labels are the column names from the second column onwards\n",
    "                    predicted_labels_from_file = cm_df_raw.columns[1:].astype(str).tolist()\n",
    "                    # The actual counts are in the remaining columns\n",
    "                    counts_matrix = cm_df_raw.iloc[:, 1:].values\n",
    "                else:\n",
    "                    # A simpler case: Assume first col is index after reading, header is predicted\n",
    "                    # This might occur if pandas infers an index during read if first col unnamed and unique\n",
    "                    temp_df = pd.read_csv(file_path, index_col=0)\n",
    "                    if temp_df.shape[0] == temp_df.shape[1] and temp_df.applymap(np.isreal).all().all():\n",
    "                        actual_labels_from_file = temp_df.index.astype(str).tolist()\n",
    "                        predicted_labels_from_file = temp_df.columns.astype(str).tolist()\n",
    "                        counts_matrix = temp_df.values\n",
    "                    else:\n",
    "                        print(f\"    Warning: Could not reliably parse label structure for {filename}. Skipping.\")\n",
    "                        continue\n",
    "\n",
    "\n",
    "                # Validate dimensions (assuming 3x3 for Negative, Neutral, Positive)\n",
    "                # This part needs to be flexible if your number of classes can vary\n",
    "                # For now, let's assume 3x3 and map to EXPECTED_LABELS_IN_ORDER\n",
    "                if counts_matrix.shape[0] != len(EXPECTED_LABELS_IN_ORDER) or \\\n",
    "                   counts_matrix.shape[1] != len(EXPECTED_LABELS_IN_ORDER):\n",
    "                    print(f\"    Warning: Matrix dimensions ({counts_matrix.shape}) for {filename} do not match expected \"\n",
    "                          f\"({len(EXPECTED_LABELS_IN_ORDER)}x{len(EXPECTED_LABELS_IN_ORDER)}). \"\n",
    "                          f\"Attempting to map based on found labels, but be cautious.\")\n",
    "                    # If dimensions don't match, we'll use the labels found in the file\n",
    "                    # and the output will reflect that.\n",
    "                    current_actual_labels = actual_labels_from_file\n",
    "                    current_predicted_labels = predicted_labels_from_file\n",
    "                else:\n",
    "                    # If dimensions match, we assume the order in the file corresponds to EXPECTED_LABELS_IN_ORDER\n",
    "                    current_actual_labels = EXPECTED_LABELS_IN_ORDER\n",
    "                    current_predicted_labels = EXPECTED_LABELS_IN_ORDER\n",
    "\n",
    "\n",
    "                for i, actual_label in enumerate(current_actual_labels):\n",
    "                    # Ensure we don't go out of bounds if matrix was smaller than expected\n",
    "                    if i >= counts_matrix.shape[0]: break\n",
    "                    for j, predicted_label in enumerate(current_predicted_labels):\n",
    "                        if j >= counts_matrix.shape[1]: break\n",
    "                        count = counts_matrix[i, j]\n",
    "                        all_matrices_data.append({\n",
    "                            \"Domain\": domain_name,\n",
    "                            \"Model_Configuration\": model_config_name,\n",
    "                            \"Actual_Label\": actual_label,\n",
    "                            \"Predicted_Label\": predicted_label,\n",
    "                            \"Count\": count\n",
    "                        })\n",
    "            except Exception as e:\n",
    "                print(f\"    Error processing file {filename}: {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# # 4. Create and Save Aggregated DataFrame\n",
    "\n",
    "# %%\n",
    "if all_matrices_data:\n",
    "    aggregated_df = pd.DataFrame(all_matrices_data)\n",
    "    # Calculate num_classes based on the most common matrix size found\n",
    "    if not aggregated_df.empty:\n",
    "        num_actual_labels = aggregated_df.groupby(['Domain', 'Model_Configuration'])['Actual_Label'].nunique()\n",
    "        common_num_classes = num_actual_labels.mode()[0] if not num_actual_labels.empty else len(EXPECTED_LABELS_IN_ORDER)\n",
    "        num_aggregated_matrices = len(aggregated_df) // (common_num_classes**2)\n",
    "    else:\n",
    "        num_aggregated_matrices = 0\n",
    "\n",
    "    print(f\"\\nSuccessfully aggregated approximately {num_aggregated_matrices} confusion matrices.\")\n",
    "    print(f\"Total rows in aggregated file: {len(aggregated_df)}\")\n",
    "\n",
    "    print(\"\\nSample of aggregated data:\")\n",
    "    print(aggregated_df.sample(min(10, len(aggregated_df))).to_string())\n",
    "\n",
    "    try:\n",
    "        aggregated_df.to_csv(AGGREGATED_CM_FILE, index=False)\n",
    "        print(f\"\\nAggregated confusion matrices saved to: {AGGREGATED_CM_FILE}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError saving aggregated file: {e}\")\n",
    "else:\n",
    "    print(\"\\nNo confusion matrices were processed. Output file not created.\")\n",
    "\n",
    "print(\"\\nAggregation script finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9949a063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded ..//result//comparison_all_datasets.csv with 45 rows.\n",
      "\n",
      "Processing dataset: Book Review\n",
      "Saved plot: ..//result//result_visualizations\\Book_Review_Performance_Metrics.png\n",
      "Saved plot: ..//result//result_visualizations\\Book_Review_Time_Metrics.png\n",
      "\n",
      "Processing dataset: Financial News\n",
      "Saved plot: ..//result//result_visualizations\\Financial_News_Performance_Metrics.png\n",
      "Saved plot: ..//result//result_visualizations\\Financial_News_Time_Metrics.png\n",
      "\n",
      "All visualizations saved to: ..//result//result_visualizations\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# --- Configuration ---\n",
    "CSV_FILE_PATH = \"..//result//comparison_all_datasets.csv\"\n",
    "OUTPUT_DIR = \"..//result//result_visualizations\"\n",
    "PRIMARY_METRICS = [\"F1 (Macro)\", \"Accuracy\", \"Precision (Macro)\", \"Recall (Macro)\"]\n",
    "TIME_METRICS = [\"Train Time (s)\", \"Eval Time (s)\"]\n",
    "MODEL_COLUMN = \"Model\"\n",
    "DATASET_COLUMN = \"Dataset\"\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "def plot_metrics_for_dataset(df_dataset, dataset_name, metrics_to_plot, y_label, title_suffix, output_dir):\n",
    "    \"\"\"\n",
    "    Generates and saves a bar plot for specified metrics for a given dataset.\n",
    "    \"\"\"\n",
    "    if df_dataset.empty:\n",
    "        print(f\"No data to plot for {dataset_name} - {title_suffix}.\")\n",
    "        return\n",
    "\n",
    "    num_metrics = len(metrics_to_plot)\n",
    "    num_models = len(df_dataset[MODEL_COLUMN].unique())\n",
    "\n",
    "    plt.figure(figsize=(max(12, num_models * 0.8), 6 + num_metrics * 1)) # Adjust figure size\n",
    "    \n",
    "    # Sort by the first metric in the list for consistent plotting order (optional)\n",
    "    df_dataset_sorted = df_dataset.sort_values(by=metrics_to_plot[0], ascending=False)\n",
    "\n",
    "    for i, metric in enumerate(metrics_to_plot):\n",
    "        if metric not in df_dataset_sorted.columns:\n",
    "            print(f\"Warning: Metric '{metric}' not found in data for dataset '{dataset_name}'. Skipping this metric.\")\n",
    "            continue\n",
    "        \n",
    "        # For multiple metrics, we can plot them side-by-side or group them.\n",
    "        # Here, we'll use seaborn's barplot which handles grouping well if data is melted,\n",
    "        # or plot them individually if preferred. For simplicity, let's plot them as grouped bars.\n",
    "\n",
    "    df_melted = df_dataset_sorted.melt(id_vars=[MODEL_COLUMN], value_vars=metrics_to_plot, var_name='Metric', value_name='Score')\n",
    "\n",
    "    sns.barplot(x=MODEL_COLUMN, y='Score', hue='Metric', data=df_melted, palette='viridis')\n",
    "\n",
    "    plt.title(f'{dataset_name} - {title_suffix}', fontsize=16)\n",
    "    plt.xlabel(MODEL_COLUMN, fontsize=12)\n",
    "    plt.ylabel(y_label, fontsize=12)\n",
    "    plt.xticks(rotation=45, ha='right', fontsize=10)\n",
    "    plt.yticks(fontsize=10)\n",
    "    plt.legend(title='Metric')\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plot_filename = f\"{dataset_name.replace(' ', '_')}_{title_suffix.replace(' ', '_')}.png\"\n",
    "    plt.savefig(os.path.join(output_dir, plot_filename))\n",
    "    print(f\"Saved plot: {os.path.join(output_dir, plot_filename)}\")\n",
    "    plt.close()\n",
    "\n",
    "def main():\n",
    "    # --- Load Data ---\n",
    "    try:\n",
    "        df_all_results = pd.read_csv(CSV_FILE_PATH)\n",
    "        print(f\"Successfully loaded {CSV_FILE_PATH} with {len(df_all_results)} rows.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: {CSV_FILE_PATH} not found. Please ensure the file exists at the correct path.\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {CSV_FILE_PATH}: {e}\")\n",
    "        return\n",
    "\n",
    "    # Convert metric columns to numeric, coercing errors\n",
    "    for metric_list in [PRIMARY_METRICS, TIME_METRICS]:\n",
    "        for col in metric_list:\n",
    "            if col in df_all_results.columns:\n",
    "                df_all_results[col] = pd.to_numeric(df_all_results[col], errors='coerce')\n",
    "            else:\n",
    "                print(f\"Warning: Column '{col}' not found in the CSV. It will be skipped.\")\n",
    "    \n",
    "    if DATASET_COLUMN not in df_all_results.columns:\n",
    "        print(f\"Error: Dataset column '{DATASET_COLUMN}' not found in the CSV. Cannot proceed.\")\n",
    "        return\n",
    "    if MODEL_COLUMN not in df_all_results.columns:\n",
    "        print(f\"Error: Model column '{MODEL_COLUMN}' not found in the CSV. Cannot proceed.\")\n",
    "        return\n",
    "\n",
    "    unique_datasets = df_all_results[DATASET_COLUMN].unique()\n",
    "\n",
    "    for dataset_name in unique_datasets:\n",
    "        print(f\"\\nProcessing dataset: {dataset_name}\")\n",
    "        df_dataset = df_all_results[df_all_results[DATASET_COLUMN] == dataset_name].copy()\n",
    "\n",
    "        # Plot Performance Metrics\n",
    "        plot_metrics_for_dataset(df_dataset, dataset_name, PRIMARY_METRICS, 'Score', 'Performance Metrics', OUTPUT_DIR)\n",
    "\n",
    "        # Plot Time Metrics\n",
    "        plot_metrics_for_dataset(df_dataset, dataset_name, TIME_METRICS, 'Time (seconds)', 'Time Metrics', OUTPUT_DIR)\n",
    "\n",
    "    print(f\"\\nAll visualizations saved to: {OUTPUT_DIR}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7fd96135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting misclassification analysis...\n",
      "Successfully loaded ../result/comparison/all_confusion_matrices_aggregated.csv with 405 rows.\n",
      "\n",
      "Analyzing: Book Reviews - BERT_Feature_Extractor__LR\n",
      "  Class counts: {'negative': 5292, 'neutral': 3814, 'positive': 35894}\n",
      "  Correct classification rates:\n",
      "    71.26% of actual negative reviews were correctly classified.\n",
      "    54.01% of actual neutral reviews were correctly classified.\n",
      "    74.32% of actual positive reviews were correctly classified.\n",
      "  Misclassification rates:\n",
      "    21.71% of actual negative reviews were predicted as neutral.\n",
      "    7.03% of actual negative reviews were predicted as positive.\n",
      "    24.15% of actual neutral reviews were predicted as negative.\n",
      "    21.84% of actual neutral reviews were predicted as positive.\n",
      "    7.99% of actual positive reviews were predicted as negative.\n",
      "    17.69% of actual positive reviews were predicted as neutral.\n",
      "\n",
      "Analyzing: Book Reviews - BERT_Full_FT\n",
      "  Class counts: {'negative': 5292, 'neutral': 3814, 'positive': 35894}\n",
      "  Correct classification rates:\n",
      "    78.04% of actual negative reviews were correctly classified.\n",
      "    48.22% of actual neutral reviews were correctly classified.\n",
      "    96.79% of actual positive reviews were correctly classified.\n",
      "  Misclassification rates:\n",
      "    12.83% of actual negative reviews were predicted as neutral.\n",
      "    9.13% of actual negative reviews were predicted as positive.\n",
      "    16.26% of actual neutral reviews were predicted as negative.\n",
      "    35.53% of actual neutral reviews were predicted as positive.\n",
      "    0.82% of actual positive reviews were predicted as negative.\n",
      "    2.39% of actual positive reviews were predicted as neutral.\n",
      "\n",
      "Analyzing: Book Reviews - BERT_LoRA_FT\n",
      "  Class counts: {'negative': 5292, 'neutral': 3814, 'positive': 35894}\n",
      "  Correct classification rates:\n",
      "    70.60% of actual negative reviews were correctly classified.\n",
      "    26.98% of actual neutral reviews were correctly classified.\n",
      "    96.90% of actual positive reviews were correctly classified.\n",
      "  Misclassification rates:\n",
      "    9.94% of actual negative reviews were predicted as neutral.\n",
      "    19.46% of actual negative reviews were predicted as positive.\n",
      "    18.98% of actual neutral reviews were predicted as negative.\n",
      "    54.04% of actual neutral reviews were predicted as positive.\n",
      "    1.62% of actual positive reviews were predicted as negative.\n",
      "    1.48% of actual positive reviews were predicted as neutral.\n",
      "\n",
      "Analyzing: Book Reviews - BiLSTM (GloVe_Emb)\n",
      "  Class counts: {'negative': 5292, 'neutral': 3814, 'positive': 35894}\n",
      "  Correct classification rates:\n",
      "    71.56% of actual negative reviews were correctly classified.\n",
      "    28.89% of actual neutral reviews were correctly classified.\n",
      "    96.70% of actual positive reviews were correctly classified.\n",
      "  Misclassification rates:\n",
      "    9.15% of actual negative reviews were predicted as neutral.\n",
      "    19.29% of actual negative reviews were predicted as positive.\n",
      "    20.50% of actual neutral reviews were predicted as negative.\n",
      "    50.60% of actual neutral reviews were predicted as positive.\n",
      "    1.49% of actual positive reviews were predicted as negative.\n",
      "    1.81% of actual positive reviews were predicted as neutral.\n",
      "\n",
      "Analyzing: Book Reviews - BiLSTM (Learned_Emb)\n",
      "  Class counts: {'negative': 5292, 'neutral': 3814, 'positive': 35894}\n",
      "  Correct classification rates:\n",
      "    59.15% of actual negative reviews were correctly classified.\n",
      "    11.54% of actual neutral reviews were correctly classified.\n",
      "    98.62% of actual positive reviews were correctly classified.\n",
      "  Misclassification rates:\n",
      "    7.07% of actual negative reviews were predicted as neutral.\n",
      "    33.79% of actual negative reviews were predicted as positive.\n",
      "    17.07% of actual neutral reviews were predicted as negative.\n",
      "    71.39% of actual neutral reviews were predicted as positive.\n",
      "    0.90% of actual positive reviews were predicted as negative.\n",
      "    0.48% of actual positive reviews were predicted as neutral.\n",
      "\n",
      "Analyzing: Book Reviews - CNN-LSTM (GloVe_Emb)\n",
      "  Class counts: {'negative': 5292, 'neutral': 3814, 'positive': 35894}\n",
      "  Correct classification rates:\n",
      "    66.02% of actual negative reviews were correctly classified.\n",
      "    28.63% of actual neutral reviews were correctly classified.\n",
      "    97.33% of actual positive reviews were correctly classified.\n",
      "  Misclassification rates:\n",
      "    11.26% of actual negative reviews were predicted as neutral.\n",
      "    22.71% of actual negative reviews were predicted as positive.\n",
      "    15.73% of actual neutral reviews were predicted as negative.\n",
      "    55.64% of actual neutral reviews were predicted as positive.\n",
      "    1.08% of actual positive reviews were predicted as negative.\n",
      "    1.59% of actual positive reviews were predicted as neutral.\n",
      "\n",
      "Analyzing: Book Reviews - CNN (GloVe_Emb)\n",
      "  Class counts: {'negative': 5292, 'neutral': 3814, 'positive': 35894}\n",
      "  Correct classification rates:\n",
      "    37.91% of actual negative reviews were correctly classified.\n",
      "    0.71% of actual neutral reviews were correctly classified.\n",
      "    99.35% of actual positive reviews were correctly classified.\n",
      "  Misclassification rates:\n",
      "    0.11% of actual negative reviews were predicted as neutral.\n",
      "    61.98% of actual negative reviews were predicted as positive.\n",
      "    11.59% of actual neutral reviews were predicted as negative.\n",
      "    87.70% of actual neutral reviews were predicted as positive.\n",
      "    0.62% of actual positive reviews were predicted as negative.\n",
      "    0.03% of actual positive reviews were predicted as neutral.\n",
      "\n",
      "Analyzing: Book Reviews - CNN (Learned_Emb)\n",
      "  Class counts: {'negative': 5292, 'neutral': 3814, 'positive': 35894}\n",
      "  Correct classification rates:\n",
      "    61.41% of actual negative reviews were correctly classified.\n",
      "    11.82% of actual neutral reviews were correctly classified.\n",
      "    98.12% of actual positive reviews were correctly classified.\n",
      "  Misclassification rates:\n",
      "    2.31% of actual negative reviews were predicted as neutral.\n",
      "    36.28% of actual negative reviews were predicted as positive.\n",
      "    20.53% of actual neutral reviews were predicted as negative.\n",
      "    67.65% of actual neutral reviews were predicted as positive.\n",
      "    1.43% of actual positive reviews were predicted as negative.\n",
      "    0.45% of actual positive reviews were predicted as neutral.\n",
      "\n",
      "Analyzing: Book Reviews - DistilBERT_Feature_Extractor__LR\n",
      "  Class counts: {'negative': 5292, 'neutral': 3814, 'positive': 35894}\n",
      "  Correct classification rates:\n",
      "    73.54% of actual negative reviews were correctly classified.\n",
      "    56.82% of actual neutral reviews were correctly classified.\n",
      "    74.27% of actual positive reviews were correctly classified.\n",
      "  Misclassification rates:\n",
      "    19.48% of actual negative reviews were predicted as neutral.\n",
      "    6.97% of actual negative reviews were predicted as positive.\n",
      "    23.34% of actual neutral reviews were predicted as negative.\n",
      "    19.85% of actual neutral reviews were predicted as positive.\n",
      "    7.72% of actual positive reviews were predicted as negative.\n",
      "    18.01% of actual positive reviews were predicted as neutral.\n",
      "\n",
      "Analyzing: Book Reviews - DistilBERT_Full_FT\n",
      "  Class counts: {'negative': 5292, 'neutral': 3814, 'positive': 35894}\n",
      "  Correct classification rates:\n",
      "    77.82% of actual negative reviews were correctly classified.\n",
      "    42.55% of actual neutral reviews were correctly classified.\n",
      "    96.68% of actual positive reviews were correctly classified.\n",
      "  Misclassification rates:\n",
      "    10.94% of actual negative reviews were predicted as neutral.\n",
      "    11.24% of actual negative reviews were predicted as positive.\n",
      "    17.80% of actual neutral reviews were predicted as negative.\n",
      "    39.64% of actual neutral reviews were predicted as positive.\n",
      "    1.14% of actual positive reviews were predicted as negative.\n",
      "    2.18% of actual positive reviews were predicted as neutral.\n",
      "\n",
      "Analyzing: Book Reviews - LightGBM\n",
      "  Class counts: {'negative': 5292, 'neutral': 3814, 'positive': 35894}\n",
      "  Correct classification rates:\n",
      "    72.94% of actual negative reviews were correctly classified.\n",
      "    49.69% of actual neutral reviews were correctly classified.\n",
      "    90.26% of actual positive reviews were correctly classified.\n",
      "  Misclassification rates:\n",
      "    13.83% of actual negative reviews were predicted as neutral.\n",
      "    13.23% of actual negative reviews were predicted as positive.\n",
      "    18.96% of actual neutral reviews were predicted as negative.\n",
      "    31.36% of actual neutral reviews were predicted as positive.\n",
      "    3.64% of actual positive reviews were predicted as negative.\n",
      "    6.10% of actual positive reviews were predicted as neutral.\n",
      "\n",
      "Analyzing: Book Reviews - Linear_SVM\n",
      "  Class counts: {'negative': 5292, 'neutral': 3814, 'positive': 35894}\n",
      "  Correct classification rates:\n",
      "    72.05% of actual negative reviews were correctly classified.\n",
      "    40.38% of actual neutral reviews were correctly classified.\n",
      "    92.69% of actual positive reviews were correctly classified.\n",
      "  Misclassification rates:\n",
      "    11.98% of actual negative reviews were predicted as neutral.\n",
      "    15.97% of actual negative reviews were predicted as positive.\n",
      "    21.19% of actual neutral reviews were predicted as negative.\n",
      "    38.44% of actual neutral reviews were predicted as positive.\n",
      "    3.12% of actual positive reviews were predicted as negative.\n",
      "    4.19% of actual positive reviews were predicted as neutral.\n",
      "\n",
      "Analyzing: Book Reviews - Logistic_Regression\n",
      "  Class counts: {'negative': 5292, 'neutral': 3814, 'positive': 35894}\n",
      "  Correct classification rates:\n",
      "    71.96% of actual negative reviews were correctly classified.\n",
      "    39.85% of actual neutral reviews were correctly classified.\n",
      "    92.63% of actual positive reviews were correctly classified.\n",
      "  Misclassification rates:\n",
      "    12.04% of actual negative reviews were predicted as neutral.\n",
      "    16.01% of actual negative reviews were predicted as positive.\n",
      "    21.34% of actual neutral reviews were predicted as negative.\n",
      "    38.80% of actual neutral reviews were predicted as positive.\n",
      "    2.99% of actual positive reviews were predicted as negative.\n",
      "    4.38% of actual positive reviews were predicted as neutral.\n",
      "\n",
      "Analyzing: Book Reviews - LSTM (GloVe_Emb)\n",
      "  Class counts: {'negative': 5292, 'neutral': 3814, 'positive': 35894}\n",
      "  Correct classification rates:\n",
      "    66.70% of actual negative reviews were correctly classified.\n",
      "    0.00% of actual neutral reviews were correctly classified.\n",
      "    97.53% of actual positive reviews were correctly classified.\n",
      "  Misclassification rates:\n",
      "    0.00% of actual negative reviews were predicted as neutral.\n",
      "    33.30% of actual negative reviews were predicted as positive.\n",
      "    28.97% of actual neutral reviews were predicted as negative.\n",
      "    71.03% of actual neutral reviews were predicted as positive.\n",
      "    2.47% of actual positive reviews were predicted as negative.\n",
      "    0.00% of actual positive reviews were predicted as neutral.\n",
      "\n",
      "Analyzing: Book Reviews - LSTM (Learned_Emb)\n",
      "  Class counts: {'negative': 5292, 'neutral': 3814, 'positive': 35894}\n",
      "  Correct classification rates:\n",
      "    61.94% of actual negative reviews were correctly classified.\n",
      "    0.24% of actual neutral reviews were correctly classified.\n",
      "    98.84% of actual positive reviews were correctly classified.\n",
      "  Misclassification rates:\n",
      "    0.32% of actual negative reviews were predicted as neutral.\n",
      "    37.74% of actual negative reviews were predicted as positive.\n",
      "    24.33% of actual neutral reviews were predicted as negative.\n",
      "    75.43% of actual neutral reviews were predicted as positive.\n",
      "    1.14% of actual positive reviews were predicted as negative.\n",
      "    0.01% of actual positive reviews were predicted as neutral.\n",
      "\n",
      "Analyzing: Book Reviews - MLP (Avg_GloVe_Emb)\n",
      "  Class counts: {'negative': 5292, 'neutral': 3814, 'positive': 35894}\n",
      "  Correct classification rates:\n",
      "    22.88% of actual negative reviews were correctly classified.\n",
      "    0.00% of actual neutral reviews were correctly classified.\n",
      "    98.70% of actual positive reviews were correctly classified.\n",
      "  Misclassification rates:\n",
      "    0.00% of actual negative reviews were predicted as neutral.\n",
      "    77.12% of actual negative reviews were predicted as positive.\n",
      "    6.50% of actual neutral reviews were predicted as negative.\n",
      "    93.50% of actual neutral reviews were predicted as positive.\n",
      "    1.30% of actual positive reviews were predicted as negative.\n",
      "    0.00% of actual positive reviews were predicted as neutral.\n",
      "\n",
      "Analyzing: Book Reviews - MLP (Avg_Learned_Emb)\n",
      "  Class counts: {'negative': 5292, 'neutral': 3814, 'positive': 35894}\n",
      "  Correct classification rates:\n",
      "    62.07% of actual negative reviews were correctly classified.\n",
      "    4.06% of actual neutral reviews were correctly classified.\n",
      "    97.82% of actual positive reviews were correctly classified.\n",
      "  Misclassification rates:\n",
      "    1.98% of actual negative reviews were predicted as neutral.\n",
      "    35.94% of actual negative reviews were predicted as positive.\n",
      "    22.60% of actual neutral reviews were predicted as negative.\n",
      "    73.34% of actual neutral reviews were predicted as positive.\n",
      "    1.87% of actual positive reviews were predicted as negative.\n",
      "    0.30% of actual positive reviews were predicted as neutral.\n",
      "\n",
      "Analyzing: Book Reviews - Naive_Bayes\n",
      "  Class counts: {'negative': 5292, 'neutral': 3814, 'positive': 35894}\n",
      "  Correct classification rates:\n",
      "    29.65% of actual negative reviews were correctly classified.\n",
      "    2.99% of actual neutral reviews were correctly classified.\n",
      "    99.53% of actual positive reviews were correctly classified.\n",
      "  Misclassification rates:\n",
      "    0.81% of actual negative reviews were predicted as neutral.\n",
      "    69.54% of actual negative reviews were predicted as positive.\n",
      "    7.79% of actual neutral reviews were predicted as negative.\n",
      "    89.22% of actual neutral reviews were predicted as positive.\n",
      "    0.37% of actual positive reviews were predicted as negative.\n",
      "    0.10% of actual positive reviews were predicted as neutral.\n",
      "\n",
      "Analyzing: Book Reviews - Random_Forest\n",
      "  Class counts: {'negative': 5292, 'neutral': 3814, 'positive': 35894}\n",
      "  Correct classification rates:\n",
      "    65.93% of actual negative reviews were correctly classified.\n",
      "    37.10% of actual neutral reviews were correctly classified.\n",
      "    90.49% of actual positive reviews were correctly classified.\n",
      "  Misclassification rates:\n",
      "    8.22% of actual negative reviews were predicted as neutral.\n",
      "    25.85% of actual negative reviews were predicted as positive.\n",
      "    21.03% of actual neutral reviews were predicted as negative.\n",
      "    41.87% of actual neutral reviews were predicted as positive.\n",
      "    5.21% of actual positive reviews were predicted as negative.\n",
      "    4.30% of actual positive reviews were predicted as neutral.\n",
      "\n",
      "Analyzing: Book Reviews - RNN (Learned_Emb)\n",
      "  Class counts: {'negative': 5292, 'neutral': 3814, 'positive': 35894}\n",
      "  Correct classification rates:\n",
      "    0.00% of actual negative reviews were correctly classified.\n",
      "    0.00% of actual neutral reviews were correctly classified.\n",
      "    100.00% of actual positive reviews were correctly classified.\n",
      "  Misclassification rates:\n",
      "    0.00% of actual negative reviews were predicted as neutral.\n",
      "    100.00% of actual negative reviews were predicted as positive.\n",
      "    0.00% of actual neutral reviews were predicted as negative.\n",
      "    100.00% of actual neutral reviews were predicted as positive.\n",
      "    0.00% of actual positive reviews were predicted as negative.\n",
      "    0.00% of actual positive reviews were predicted as neutral.\n",
      "\n",
      "Analyzing: Book Reviews - RoBERTa_Full_FT\n",
      "  Class counts: {'negative': 5292, 'neutral': 3814, 'positive': 35894}\n",
      "  Correct classification rates:\n",
      "    81.16% of actual negative reviews were correctly classified.\n",
      "    46.80% of actual neutral reviews were correctly classified.\n",
      "    97.16% of actual positive reviews were correctly classified.\n",
      "  Misclassification rates:\n",
      "    11.55% of actual negative reviews were predicted as neutral.\n",
      "    7.29% of actual negative reviews were predicted as positive.\n",
      "    16.99% of actual neutral reviews were predicted as negative.\n",
      "    36.21% of actual neutral reviews were predicted as positive.\n",
      "    0.77% of actual positive reviews were predicted as negative.\n",
      "    2.06% of actual positive reviews were predicted as neutral.\n",
      "\n",
      "Analyzing: Book Reviews - RoBERTa_LoRA_FT\n",
      "  Class counts: {'negative': 5292, 'neutral': 3814, 'positive': 35894}\n",
      "  Correct classification rates:\n",
      "    80.52% of actual negative reviews were correctly classified.\n",
      "    33.40% of actual neutral reviews were correctly classified.\n",
      "    97.21% of actual positive reviews were correctly classified.\n",
      "  Misclassification rates:\n",
      "    8.58% of actual negative reviews were predicted as neutral.\n",
      "    10.90% of actual negative reviews were predicted as positive.\n",
      "    22.94% of actual neutral reviews were predicted as negative.\n",
      "    43.65% of actual neutral reviews were predicted as positive.\n",
      "    1.15% of actual positive reviews were predicted as negative.\n",
      "    1.64% of actual positive reviews were predicted as neutral.\n",
      "\n",
      "Analyzing: Financial News - BERT_Feature_Extractor__LR\n",
      "  Class counts: {'negative': 91, 'neutral': 432, 'positive': 204}\n",
      "  Correct classification rates:\n",
      "    80.22% of actual negative reviews were correctly classified.\n",
      "    74.77% of actual neutral reviews were correctly classified.\n",
      "    71.08% of actual positive reviews were correctly classified.\n",
      "  Misclassification rates:\n",
      "    7.69% of actual negative reviews were predicted as neutral.\n",
      "    12.09% of actual negative reviews were predicted as positive.\n",
      "    8.10% of actual neutral reviews were predicted as negative.\n",
      "    17.13% of actual neutral reviews were predicted as positive.\n",
      "    10.29% of actual positive reviews were predicted as negative.\n",
      "    18.63% of actual positive reviews were predicted as neutral.\n",
      "\n",
      "Analyzing: Financial News - BERT_Full_FT\n",
      "  Class counts: {'negative': 91, 'neutral': 432, 'positive': 204}\n",
      "  Correct classification rates:\n",
      "    86.81% of actual negative reviews were correctly classified.\n",
      "    86.57% of actual neutral reviews were correctly classified.\n",
      "    81.37% of actual positive reviews were correctly classified.\n",
      "  Misclassification rates:\n",
      "    7.69% of actual negative reviews were predicted as neutral.\n",
      "    5.49% of actual negative reviews were predicted as positive.\n",
      "    4.17% of actual neutral reviews were predicted as negative.\n",
      "    9.26% of actual neutral reviews were predicted as positive.\n",
      "    1.96% of actual positive reviews were predicted as negative.\n",
      "    16.67% of actual positive reviews were predicted as neutral.\n",
      "\n",
      "Analyzing: Financial News - BERT_LoRA_FT\n",
      "  Class counts: {'negative': 91, 'neutral': 432, 'positive': 204}\n",
      "  Correct classification rates:\n",
      "    90.11% of actual negative reviews were correctly classified.\n",
      "    83.80% of actual neutral reviews were correctly classified.\n",
      "    80.88% of actual positive reviews were correctly classified.\n",
      "  Misclassification rates:\n",
      "    6.59% of actual negative reviews were predicted as neutral.\n",
      "    3.30% of actual negative reviews were predicted as positive.\n",
      "    5.09% of actual neutral reviews were predicted as negative.\n",
      "    11.11% of actual neutral reviews were predicted as positive.\n",
      "    3.43% of actual positive reviews were predicted as negative.\n",
      "    15.69% of actual positive reviews were predicted as neutral.\n",
      "\n",
      "Analyzing: Financial News - BiLSTM (GloVe_Emb)\n",
      "  Class counts: {'negative': 91, 'neutral': 432, 'positive': 204}\n",
      "  Correct classification rates:\n",
      "    30.77% of actual negative reviews were correctly classified.\n",
      "    90.97% of actual neutral reviews were correctly classified.\n",
      "    53.43% of actual positive reviews were correctly classified.\n",
      "  Misclassification rates:\n",
      "    30.77% of actual negative reviews were predicted as neutral.\n",
      "    38.46% of actual negative reviews were predicted as positive.\n",
      "    2.78% of actual neutral reviews were predicted as negative.\n",
      "    6.25% of actual neutral reviews were predicted as positive.\n",
      "    5.88% of actual positive reviews were predicted as negative.\n",
      "    40.69% of actual positive reviews were predicted as neutral.\n",
      "\n",
      "Analyzing: Financial News - BiLSTM (Learned_Emb)\n",
      "  Class counts: {'negative': 91, 'neutral': 432, 'positive': 204}\n",
      "  Correct classification rates:\n",
      "    51.65% of actual negative reviews were correctly classified.\n",
      "    87.04% of actual neutral reviews were correctly classified.\n",
      "    54.41% of actual positive reviews were correctly classified.\n",
      "  Misclassification rates:\n",
      "    21.98% of actual negative reviews were predicted as neutral.\n",
      "    26.37% of actual negative reviews were predicted as positive.\n",
      "    3.01% of actual neutral reviews were predicted as negative.\n",
      "    9.95% of actual neutral reviews were predicted as positive.\n",
      "    6.86% of actual positive reviews were predicted as negative.\n",
      "    38.73% of actual positive reviews were predicted as neutral.\n",
      "\n",
      "Analyzing: Financial News - CNN-LSTM (GloVe_Emb)\n",
      "  Class counts: {'negative': 91, 'neutral': 432, 'positive': 204}\n",
      "  Correct classification rates:\n",
      "    35.16% of actual negative reviews were correctly classified.\n",
      "    89.35% of actual neutral reviews were correctly classified.\n",
      "    50.98% of actual positive reviews were correctly classified.\n",
      "  Misclassification rates:\n",
      "    27.47% of actual negative reviews were predicted as neutral.\n",
      "    37.36% of actual negative reviews were predicted as positive.\n",
      "    2.78% of actual neutral reviews were predicted as negative.\n",
      "    7.87% of actual neutral reviews were predicted as positive.\n",
      "    5.88% of actual positive reviews were predicted as negative.\n",
      "    43.14% of actual positive reviews were predicted as neutral.\n",
      "\n",
      "Analyzing: Financial News - CNN (GloVe_Emb)\n",
      "  Class counts: {'negative': 91, 'neutral': 432, 'positive': 204}\n",
      "  Correct classification rates:\n",
      "    63.74% of actual negative reviews were correctly classified.\n",
      "    91.90% of actual neutral reviews were correctly classified.\n",
      "    50.49% of actual positive reviews were correctly classified.\n",
      "  Misclassification rates:\n",
      "    27.47% of actual negative reviews were predicted as neutral.\n",
      "    8.79% of actual negative reviews were predicted as positive.\n",
      "    2.78% of actual neutral reviews were predicted as negative.\n",
      "    5.32% of actual neutral reviews were predicted as positive.\n",
      "    5.88% of actual positive reviews were predicted as negative.\n",
      "    43.63% of actual positive reviews were predicted as neutral.\n",
      "\n",
      "Analyzing: Financial News - CNN (Learned_Emb)\n",
      "  Class counts: {'negative': 91, 'neutral': 432, 'positive': 204}\n",
      "  Correct classification rates:\n",
      "    53.85% of actual negative reviews were correctly classified.\n",
      "    87.96% of actual neutral reviews were correctly classified.\n",
      "    52.94% of actual positive reviews were correctly classified.\n",
      "  Misclassification rates:\n",
      "    35.16% of actual negative reviews were predicted as neutral.\n",
      "    10.99% of actual negative reviews were predicted as positive.\n",
      "    3.24% of actual neutral reviews were predicted as negative.\n",
      "    8.80% of actual neutral reviews were predicted as positive.\n",
      "    5.39% of actual positive reviews were predicted as negative.\n",
      "    41.67% of actual positive reviews were predicted as neutral.\n",
      "\n",
      "Analyzing: Financial News - DistilBERT_Feature_Extractor__LR\n",
      "  Class counts: {'negative': 91, 'neutral': 432, 'positive': 204}\n",
      "  Correct classification rates:\n",
      "    84.62% of actual negative reviews were correctly classified.\n",
      "    75.69% of actual neutral reviews were correctly classified.\n",
      "    67.65% of actual positive reviews were correctly classified.\n",
      "  Misclassification rates:\n",
      "    7.69% of actual negative reviews were predicted as neutral.\n",
      "    7.69% of actual negative reviews were predicted as positive.\n",
      "    7.41% of actual neutral reviews were predicted as negative.\n",
      "    16.90% of actual neutral reviews were predicted as positive.\n",
      "    10.78% of actual positive reviews were predicted as negative.\n",
      "    21.57% of actual positive reviews were predicted as neutral.\n",
      "\n",
      "Analyzing: Financial News - DistilBERT_Full_FT\n",
      "  Class counts: {'negative': 91, 'neutral': 432, 'positive': 204}\n",
      "  Correct classification rates:\n",
      "    90.11% of actual negative reviews were correctly classified.\n",
      "    85.42% of actual neutral reviews were correctly classified.\n",
      "    78.43% of actual positive reviews were correctly classified.\n",
      "  Misclassification rates:\n",
      "    5.49% of actual negative reviews were predicted as neutral.\n",
      "    4.40% of actual negative reviews were predicted as positive.\n",
      "    5.32% of actual neutral reviews were predicted as negative.\n",
      "    9.26% of actual neutral reviews were predicted as positive.\n",
      "    2.94% of actual positive reviews were predicted as negative.\n",
      "    18.63% of actual positive reviews were predicted as neutral.\n",
      "\n",
      "Analyzing: Financial News - FinBERT_Full_FT\n",
      "  Class counts: {'negative': 91, 'neutral': 432, 'positive': 204}\n",
      "  Correct classification rates:\n",
      "    87.91% of actual negative reviews were correctly classified.\n",
      "    87.04% of actual neutral reviews were correctly classified.\n",
      "    86.76% of actual positive reviews were correctly classified.\n",
      "  Misclassification rates:\n",
      "    8.79% of actual negative reviews were predicted as neutral.\n",
      "    3.30% of actual negative reviews were predicted as positive.\n",
      "    3.70% of actual neutral reviews were predicted as negative.\n",
      "    9.26% of actual neutral reviews were predicted as positive.\n",
      "    1.47% of actual positive reviews were predicted as negative.\n",
      "    11.76% of actual positive reviews were predicted as neutral.\n",
      "\n",
      "Analyzing: Financial News - LightGBM\n",
      "  Class counts: {'negative': 91, 'neutral': 432, 'positive': 204}\n",
      "  Correct classification rates:\n",
      "    68.13% of actual negative reviews were correctly classified.\n",
      "    82.87% of actual neutral reviews were correctly classified.\n",
      "    62.75% of actual positive reviews were correctly classified.\n",
      "  Misclassification rates:\n",
      "    16.48% of actual negative reviews were predicted as neutral.\n",
      "    15.38% of actual negative reviews were predicted as positive.\n",
      "    5.32% of actual neutral reviews were predicted as negative.\n",
      "    11.81% of actual neutral reviews were predicted as positive.\n",
      "    7.35% of actual positive reviews were predicted as negative.\n",
      "    29.90% of actual positive reviews were predicted as neutral.\n",
      "\n",
      "Analyzing: Financial News - Linear_SVM\n",
      "  Class counts: {'negative': 91, 'neutral': 432, 'positive': 204}\n",
      "  Correct classification rates:\n",
      "    63.74% of actual negative reviews were correctly classified.\n",
      "    82.41% of actual neutral reviews were correctly classified.\n",
      "    57.84% of actual positive reviews were correctly classified.\n",
      "  Misclassification rates:\n",
      "    20.88% of actual negative reviews were predicted as neutral.\n",
      "    15.38% of actual negative reviews were predicted as positive.\n",
      "    4.40% of actual neutral reviews were predicted as negative.\n",
      "    13.19% of actual neutral reviews were predicted as positive.\n",
      "    6.86% of actual positive reviews were predicted as negative.\n",
      "    35.29% of actual positive reviews were predicted as neutral.\n",
      "\n",
      "Analyzing: Financial News - Logistic_Regression\n",
      "  Class counts: {'negative': 91, 'neutral': 432, 'positive': 204}\n",
      "  Correct classification rates:\n",
      "    65.93% of actual negative reviews were correctly classified.\n",
      "    83.56% of actual neutral reviews were correctly classified.\n",
      "    58.33% of actual positive reviews were correctly classified.\n",
      "  Misclassification rates:\n",
      "    20.88% of actual negative reviews were predicted as neutral.\n",
      "    13.19% of actual negative reviews were predicted as positive.\n",
      "    4.17% of actual neutral reviews were predicted as negative.\n",
      "    12.27% of actual neutral reviews were predicted as positive.\n",
      "    6.37% of actual positive reviews were predicted as negative.\n",
      "    35.29% of actual positive reviews were predicted as neutral.\n",
      "\n",
      "Analyzing: Financial News - LSTM (GloVe_Emb)\n",
      "  Class counts: {'negative': 91, 'neutral': 432, 'positive': 204}\n",
      "  Correct classification rates:\n",
      "    0.00% of actual negative reviews were correctly classified.\n",
      "    86.11% of actual neutral reviews were correctly classified.\n",
      "    38.73% of actual positive reviews were correctly classified.\n",
      "  Misclassification rates:\n",
      "    40.66% of actual negative reviews were predicted as neutral.\n",
      "    59.34% of actual negative reviews were predicted as positive.\n",
      "    0.00% of actual neutral reviews were predicted as negative.\n",
      "    13.89% of actual neutral reviews were predicted as positive.\n",
      "    0.00% of actual positive reviews were predicted as negative.\n",
      "    61.27% of actual positive reviews were predicted as neutral.\n",
      "\n",
      "Analyzing: Financial News - LSTM (Learned_Emb)\n",
      "  Class counts: {'negative': 91, 'neutral': 432, 'positive': 204}\n",
      "  Correct classification rates:\n",
      "    0.00% of actual negative reviews were correctly classified.\n",
      "    81.94% of actual neutral reviews were correctly classified.\n",
      "    65.20% of actual positive reviews were correctly classified.\n",
      "  Misclassification rates:\n",
      "    18.68% of actual negative reviews were predicted as neutral.\n",
      "    81.32% of actual negative reviews were predicted as positive.\n",
      "    0.00% of actual neutral reviews were predicted as negative.\n",
      "    18.06% of actual neutral reviews were predicted as positive.\n",
      "    0.00% of actual positive reviews were predicted as negative.\n",
      "    34.80% of actual positive reviews were predicted as neutral.\n",
      "\n",
      "Analyzing: Financial News - MLP (Avg_GloVe_Emb)\n",
      "  Class counts: {'negative': 91, 'neutral': 432, 'positive': 204}\n",
      "  Correct classification rates:\n",
      "    34.07% of actual negative reviews were correctly classified.\n",
      "    86.11% of actual neutral reviews were correctly classified.\n",
      "    47.55% of actual positive reviews were correctly classified.\n",
      "  Misclassification rates:\n",
      "    24.18% of actual negative reviews were predicted as neutral.\n",
      "    41.76% of actual negative reviews were predicted as positive.\n",
      "    4.63% of actual neutral reviews were predicted as negative.\n",
      "    9.26% of actual neutral reviews were predicted as positive.\n",
      "    6.37% of actual positive reviews were predicted as negative.\n",
      "    46.08% of actual positive reviews were predicted as neutral.\n",
      "\n",
      "Analyzing: Financial News - MLP (Avg_Learned_Emb)\n",
      "  Class counts: {'negative': 91, 'neutral': 432, 'positive': 204}\n",
      "  Correct classification rates:\n",
      "    0.00% of actual negative reviews were correctly classified.\n",
      "    85.65% of actual neutral reviews were correctly classified.\n",
      "    50.00% of actual positive reviews were correctly classified.\n",
      "  Misclassification rates:\n",
      "    28.57% of actual negative reviews were predicted as neutral.\n",
      "    71.43% of actual negative reviews were predicted as positive.\n",
      "    0.00% of actual neutral reviews were predicted as negative.\n",
      "    14.35% of actual neutral reviews were predicted as positive.\n",
      "    0.00% of actual positive reviews were predicted as negative.\n",
      "    50.00% of actual positive reviews were predicted as neutral.\n",
      "\n",
      "Analyzing: Financial News - Naive_Bayes\n",
      "  Class counts: {'negative': 91, 'neutral': 432, 'positive': 204}\n",
      "  Correct classification rates:\n",
      "    9.89% of actual negative reviews were correctly classified.\n",
      "    97.45% of actual neutral reviews were correctly classified.\n",
      "    29.90% of actual positive reviews were correctly classified.\n",
      "  Misclassification rates:\n",
      "    57.14% of actual negative reviews were predicted as neutral.\n",
      "    32.97% of actual negative reviews were predicted as positive.\n",
      "    0.00% of actual neutral reviews were predicted as negative.\n",
      "    2.55% of actual neutral reviews were predicted as positive.\n",
      "    0.00% of actual positive reviews were predicted as negative.\n",
      "    70.10% of actual positive reviews were predicted as neutral.\n",
      "\n",
      "Analyzing: Financial News - Random_Forest\n",
      "  Class counts: {'negative': 91, 'neutral': 432, 'positive': 204}\n",
      "  Correct classification rates:\n",
      "    65.93% of actual negative reviews were correctly classified.\n",
      "    88.19% of actual neutral reviews were correctly classified.\n",
      "    44.61% of actual positive reviews were correctly classified.\n",
      "  Misclassification rates:\n",
      "    27.47% of actual negative reviews were predicted as neutral.\n",
      "    6.59% of actual negative reviews were predicted as positive.\n",
      "    6.48% of actual neutral reviews were predicted as negative.\n",
      "    5.32% of actual neutral reviews were predicted as positive.\n",
      "    11.76% of actual positive reviews were predicted as negative.\n",
      "    43.63% of actual positive reviews were predicted as neutral.\n",
      "\n",
      "Analyzing: Financial News - RNN (Learned_Emb)\n",
      "  Class counts: {'negative': 91, 'neutral': 432, 'positive': 204}\n",
      "  Correct classification rates:\n",
      "    0.00% of actual negative reviews were correctly classified.\n",
      "    99.77% of actual neutral reviews were correctly classified.\n",
      "    0.98% of actual positive reviews were correctly classified.\n",
      "  Misclassification rates:\n",
      "    100.00% of actual negative reviews were predicted as neutral.\n",
      "    0.00% of actual negative reviews were predicted as positive.\n",
      "    0.00% of actual neutral reviews were predicted as negative.\n",
      "    0.23% of actual neutral reviews were predicted as positive.\n",
      "    0.00% of actual positive reviews were predicted as negative.\n",
      "    99.02% of actual positive reviews were predicted as neutral.\n",
      "\n",
      "Analyzing: Financial News - RoBERTa_Full_FT\n",
      "  Class counts: {'negative': 91, 'neutral': 432, 'positive': 204}\n",
      "  Correct classification rates:\n",
      "    93.41% of actual negative reviews were correctly classified.\n",
      "    84.95% of actual neutral reviews were correctly classified.\n",
      "    84.80% of actual positive reviews were correctly classified.\n",
      "  Misclassification rates:\n",
      "    5.49% of actual negative reviews were predicted as neutral.\n",
      "    1.10% of actual negative reviews were predicted as positive.\n",
      "    4.17% of actual neutral reviews were predicted as negative.\n",
      "    10.88% of actual neutral reviews were predicted as positive.\n",
      "    0.49% of actual positive reviews were predicted as negative.\n",
      "    14.71% of actual positive reviews were predicted as neutral.\n",
      "\n",
      "Analyzing: Financial News - RoBERTa_LoRA_FT\n",
      "  Class counts: {'negative': 91, 'neutral': 432, 'positive': 204}\n",
      "  Correct classification rates:\n",
      "    94.51% of actual negative reviews were correctly classified.\n",
      "    84.26% of actual neutral reviews were correctly classified.\n",
      "    78.92% of actual positive reviews were correctly classified.\n",
      "  Misclassification rates:\n",
      "    4.40% of actual negative reviews were predicted as neutral.\n",
      "    1.10% of actual negative reviews were predicted as positive.\n",
      "    4.63% of actual neutral reviews were predicted as negative.\n",
      "    11.11% of actual neutral reviews were predicted as positive.\n",
      "    1.96% of actual positive reviews were predicted as negative.\n",
      "    19.12% of actual positive reviews were predicted as neutral.\n",
      "\n",
      "Saved misclassification analysis to: ../result/misclassification_analysis\\misclassification_analysis_summary.csv\n",
      "\n",
      "--- Domain-Level Misclassification Analysis ---\n",
      "\n",
      "Book Reviews (averaged across 22 models):\n",
      "  7.91% of actual negative reviews were predicted as neutral.\n",
      "  30.49% of actual negative reviews were predicted as positive.\n",
      "  18.12% of actual neutral reviews were predicted as negative.\n",
      "  56.22% of actual neutral reviews were predicted as positive.\n",
      "  2.22% of actual positive reviews were predicted as negative.\n",
      "  3.14% of actual positive reviews were predicted as neutral.\n",
      "  Saved heatmap visualization to: ../result/misclassification_analysis\\Book_Reviews_avg_classification_heatmap.png\n",
      "\n",
      "  Most common misclassifications:\n",
      "    negative  positive: 30.49%\n",
      "    neutral  positive: 56.22%\n",
      "    positive  neutral: 3.14%\n",
      "\n",
      "Financial News (averaged across 23 models):\n",
      "  23.98% of actual negative reviews were predicted as neutral.\n",
      "  21.64% of actual negative reviews were predicted as positive.\n",
      "  3.57% of actual neutral reviews were predicted as negative.\n",
      "  10.18% of actual neutral reviews were predicted as positive.\n",
      "  4.43% of actual positive reviews were predicted as negative.\n",
      "  36.96% of actual positive reviews were predicted as neutral.\n",
      "  Saved heatmap visualization to: ../result/misclassification_analysis\\Financial_News_avg_classification_heatmap.png\n",
      "\n",
      "  Most common misclassifications:\n",
      "    negative  neutral: 23.98%\n",
      "    neutral  positive: 10.18%\n",
      "    positive  neutral: 36.96%\n",
      "\n",
      "--- 'Neutral' Class Analysis ---\n",
      "\n",
      "Book Reviews:\n",
      "  Neutral class is misclassified as:\n",
      "    Negative: 18.12%\n",
      "    Positive: 56.22%\n",
      "  Other classes misclassified as Neutral:\n",
      "    Negative  Neutral: 7.91%\n",
      "    Positive  Neutral: 3.14%\n",
      "  Neutral class is being 'eaten' by other classes (Net loss: 63.27%)\n",
      "\n",
      "Financial News:\n",
      "  Neutral class is misclassified as:\n",
      "    Negative: 3.57%\n",
      "    Positive: 10.18%\n",
      "  Other classes misclassified as Neutral:\n",
      "    Negative  Neutral: 23.98%\n",
      "    Positive  Neutral: 36.96%\n",
      "  Neutral class is 'eating' other classes (Net gain: 47.19%)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# --- Configuration ---\n",
    "FILE_PATH = \"../result/comparison/all_confusion_matrices_aggregated.csv\"\n",
    "OUTPUT_DIR = \"../result/misclassification_analysis\"\n",
    "CLASSES = ['negative', 'neutral', 'positive']  # Expected class labels\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "def analyze_misclassifications(df_subset, domain, model):\n",
    "    \"\"\"\n",
    "    Analyze misclassification patterns in a confusion matrix.\n",
    "    \n",
    "    Args:\n",
    "        df_subset: DataFrame containing confusion matrix data for a specific domain and model\n",
    "        domain: The domain name\n",
    "        model: The model configuration name\n",
    "        \n",
    "    Returns:\n",
    "        A dictionary containing misclassification statistics\n",
    "    \"\"\"\n",
    "    results = {\n",
    "        \"Domain\": domain,\n",
    "        \"Model\": model,\n",
    "        \"ClassCounts\": {},\n",
    "        \"MisclassificationRates\": {},\n",
    "        \"CorrectClassificationRates\": {}\n",
    "    }\n",
    "    \n",
    "    # Get total counts for each actual class\n",
    "    for actual_class in CLASSES:\n",
    "        # Get data for this actual class (case insensitive matching)\n",
    "        class_data = df_subset[df_subset['Actual_Label'].str.lower() == actual_class.lower()]\n",
    "        \n",
    "        if not class_data.empty:\n",
    "            total_count = class_data['Count'].sum()\n",
    "            results[\"ClassCounts\"][actual_class] = total_count\n",
    "            \n",
    "            # Calculate correct classification rate\n",
    "            correct_count = class_data[class_data['Predicted_Label'].str.lower() == actual_class.lower()]['Count'].sum()\n",
    "            correct_rate = (correct_count / total_count) * 100 if total_count > 0 else 0\n",
    "            results[\"CorrectClassificationRates\"][actual_class] = correct_rate\n",
    "            \n",
    "            # Calculate misclassification rates to other classes\n",
    "            for predicted_class in CLASSES:\n",
    "                if predicted_class.lower() != actual_class.lower():\n",
    "                    misclassified_count = class_data[\n",
    "                        class_data['Predicted_Label'].str.lower() == predicted_class.lower()\n",
    "                    ]['Count'].sum()\n",
    "                    \n",
    "                    misclassification_rate = (misclassified_count / total_count) * 100 if total_count > 0 else 0\n",
    "                    key = f\"{actual_class}_as_{predicted_class}\"\n",
    "                    results[\"MisclassificationRates\"][key] = misclassification_rate\n",
    "    \n",
    "    return results\n",
    "\n",
    "def main():\n",
    "    print(\"Starting misclassification analysis...\")\n",
    "    \n",
    "    # Load the aggregated confusion matrix data\n",
    "    try:\n",
    "        cm_df = pd.read_csv(FILE_PATH)\n",
    "        print(f\"Successfully loaded {FILE_PATH} with {len(cm_df)} rows.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: {FILE_PATH} not found. Please ensure the file exists at the correct path.\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {FILE_PATH}: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Normalize class labels for consistency (lowercase)\n",
    "    cm_df['Actual_Label'] = cm_df['Actual_Label'].str.lower()\n",
    "    cm_df['Predicted_Label'] = cm_df['Predicted_Label'].str.lower()\n",
    "    \n",
    "    # Get unique combinations of domain and model\n",
    "    domain_model_pairs = cm_df[['Domain', 'Model_Configuration']].drop_duplicates()\n",
    "    \n",
    "    # Initialize list to store all analysis results\n",
    "    all_results = []\n",
    "    \n",
    "    # Analyze each domain-model combination\n",
    "    for _, row in domain_model_pairs.iterrows():\n",
    "        domain = row['Domain']\n",
    "        model = row['Model_Configuration']\n",
    "        \n",
    "        print(f\"\\nAnalyzing: {domain} - {model}\")\n",
    "        \n",
    "        # Get subset of data for this domain and model\n",
    "        subset = cm_df[\n",
    "            (cm_df['Domain'] == domain) & \n",
    "            (cm_df['Model_Configuration'] == model)\n",
    "        ]\n",
    "        \n",
    "        if subset.empty:\n",
    "            print(f\"  No data found for {domain} - {model}\")\n",
    "            continue\n",
    "        \n",
    "        # Analyze misclassifications\n",
    "        results = analyze_misclassifications(subset, domain, model)\n",
    "        all_results.append(results)\n",
    "        \n",
    "        # Print summary statistics for this model\n",
    "        print(f\"  Class counts: {results['ClassCounts']}\")\n",
    "        \n",
    "        print(f\"  Correct classification rates:\")\n",
    "        for cls, rate in results['CorrectClassificationRates'].items():\n",
    "            print(f\"    {rate:.2f}% of actual {cls} reviews were correctly classified.\")\n",
    "        \n",
    "        print(f\"  Misclassification rates:\")\n",
    "        for key, rate in results['MisclassificationRates'].items():\n",
    "            actual_class, predicted_class = key.split('_as_')\n",
    "            print(f\"    {rate:.2f}% of actual {actual_class} reviews were predicted as {predicted_class}.\")\n",
    "    \n",
    "    # Create a consolidated DataFrame for all results\n",
    "    def extract_row_from_result(result):\n",
    "        row = {\n",
    "            \"Domain\": result[\"Domain\"],\n",
    "            \"Model\": result[\"Model\"]\n",
    "        }\n",
    "        \n",
    "        # Add class counts\n",
    "        for cls, count in result[\"ClassCounts\"].items():\n",
    "            row[f\"{cls}_count\"] = count\n",
    "        \n",
    "        # Add correct classification rates\n",
    "        for cls, rate in result[\"CorrectClassificationRates\"].items():\n",
    "            row[f\"{cls}_correct_rate\"] = rate\n",
    "        \n",
    "        # Add misclassification rates\n",
    "        for key, rate in result[\"MisclassificationRates\"].items():\n",
    "            row[key] = rate\n",
    "        \n",
    "        return row\n",
    "    \n",
    "    results_rows = [extract_row_from_result(result) for result in all_results]\n",
    "    results_df = pd.DataFrame(results_rows)\n",
    "    \n",
    "    # Save the consolidated results\n",
    "    output_file = os.path.join(OUTPUT_DIR, \"misclassification_analysis_summary.csv\")\n",
    "    results_df.to_csv(output_file, index=False)\n",
    "    print(f\"\\nSaved misclassification analysis to: {output_file}\")\n",
    "    \n",
    "    # Calculate domain-level average misclassification rates\n",
    "    print(\"\\n--- Domain-Level Misclassification Analysis ---\")\n",
    "    for domain in results_df['Domain'].unique():\n",
    "        domain_df = results_df[results_df['Domain'] == domain]\n",
    "        print(f\"\\n{domain} (averaged across {len(domain_df)} models):\")\n",
    "        \n",
    "        # Calculate average misclassification rates for this domain\n",
    "        misclass_columns = [col for col in domain_df.columns if '_as_' in col]\n",
    "        for col in misclass_columns:\n",
    "            avg_rate = domain_df[col].mean()\n",
    "            actual_class, predicted_class = col.split('_as_')\n",
    "            print(f\"  {avg_rate:.2f}% of actual {actual_class} reviews were predicted as {predicted_class}.\")\n",
    "        \n",
    "        # Create visualization of average misclassification patterns\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        \n",
    "        # Create confusion-matrix-like structure for visualization\n",
    "        confusion_data = np.zeros((len(CLASSES), len(CLASSES)))\n",
    "        class_indices = {cls: i for i, cls in enumerate(CLASSES)}\n",
    "        \n",
    "        # Fill in correct classification rates\n",
    "        for cls in CLASSES:\n",
    "            i = class_indices[cls]\n",
    "            confusion_data[i, i] = domain_df[f\"{cls}_correct_rate\"].mean()\n",
    "        \n",
    "        # Fill in misclassification rates\n",
    "        for col in misclass_columns:\n",
    "            actual_class, predicted_class = col.split('_as_')\n",
    "            i = class_indices[actual_class]\n",
    "            j = class_indices[predicted_class]\n",
    "            confusion_data[i, j] = domain_df[col].mean()\n",
    "        \n",
    "        # Plot heatmap\n",
    "        ax = sns.heatmap(confusion_data, annot=True, fmt=\".2f\", cmap=\"YlGnBu\",\n",
    "                    xticklabels=CLASSES, yticklabels=CLASSES)\n",
    "        plt.title(f\"Average Classification Rates (%) for {domain}\")\n",
    "        plt.xlabel(\"Predicted Class\")\n",
    "        plt.ylabel(\"Actual Class\")\n",
    "        \n",
    "        # Save the figure\n",
    "        heatmap_file = os.path.join(OUTPUT_DIR, f\"{domain.replace(' ', '_')}_avg_classification_heatmap.png\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(heatmap_file)\n",
    "        plt.close()\n",
    "        print(f\"  Saved heatmap visualization to: {heatmap_file}\")\n",
    "        \n",
    "        # Find most common misclassifications\n",
    "        highest_misclass = {}\n",
    "        for cls in CLASSES:\n",
    "            misclass_cols = [col for col in misclass_columns if col.startswith(f\"{cls}_as_\")]\n",
    "            if misclass_cols:\n",
    "                avg_rates = [domain_df[col].mean() for col in misclass_cols]\n",
    "                max_col = misclass_cols[np.argmax(avg_rates)]\n",
    "                highest_misclass[cls] = (max_col, max(avg_rates))\n",
    "        \n",
    "        print(\"\\n  Most common misclassifications:\")\n",
    "        for actual_class, (misclass_col, rate) in highest_misclass.items():\n",
    "            _, predicted_class = misclass_col.split('_as_')\n",
    "            print(f\"    {actual_class}  {predicted_class}: {rate:.2f}%\")\n",
    "    \n",
    "    # Check if neutral is getting \"eaten\" by other classes\n",
    "    print(\"\\n--- 'Neutral' Class Analysis ---\")\n",
    "    for domain in results_df['Domain'].unique():\n",
    "        domain_df = results_df[results_df['Domain'] == domain]\n",
    "        neutral_as_neg = domain_df['neutral_as_negative'].mean()\n",
    "        neutral_as_pos = domain_df['neutral_as_positive'].mean()\n",
    "        neg_as_neutral = domain_df['negative_as_neutral'].mean()\n",
    "        pos_as_neutral = domain_df['positive_as_neutral'].mean()\n",
    "        \n",
    "        print(f\"\\n{domain}:\")\n",
    "        print(f\"  Neutral class is misclassified as:\")\n",
    "        print(f\"    Negative: {neutral_as_neg:.2f}%\")\n",
    "        print(f\"    Positive: {neutral_as_pos:.2f}%\")\n",
    "        print(f\"  Other classes misclassified as Neutral:\")\n",
    "        print(f\"    Negative  Neutral: {neg_as_neutral:.2f}%\")\n",
    "        print(f\"    Positive  Neutral: {pos_as_neutral:.2f}%\")\n",
    "        \n",
    "        # Determine if neutral is being \"eaten\" or \"eating\" other classes\n",
    "        neutral_outflow = neutral_as_neg + neutral_as_pos\n",
    "        neutral_inflow = neg_as_neutral + pos_as_neutral\n",
    "        \n",
    "        if neutral_outflow > neutral_inflow:\n",
    "            print(f\"  Neutral class is being 'eaten' by other classes (Net loss: {neutral_outflow - neutral_inflow:.2f}%)\")\n",
    "        else:\n",
    "            print(f\"  Neutral class is 'eating' other classes (Net gain: {neutral_inflow - neutral_outflow:.2f}%)\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
